{"meta":{"title":"vetchçš„å°å°ä¸–ç•Œ","subtitle":null,"description":"é™Œä¸ŠèŠ±å¼€ï¼Œå¯ç¼“ç¼“å½’çŸ£","author":"Weiquan Fan","url":"http://weiquanfan.xyz","root":"/"},"pages":[{"title":"404 Not Foundï¼šè¯¥é¡µæ— æ³•æ˜¾ç¤º","date":"2020-05-03T16:06:52.229Z","updated":"2019-08-02T02:17:12.000Z","comments":false,"path":"/404.html","permalink":"http://weiquanfan.xyz//404.html","excerpt":"","text":""},{"title":"Books","date":"2020-05-03T16:35:07.806Z","updated":"2020-05-03T16:35:07.806Z","comments":false,"path":"books/index.html","permalink":"http://weiquanfan.xyz/books/index.html","excerpt":"","text":""},{"title":"About","date":"2020-05-03T16:34:43.608Z","updated":"2020-05-03T16:34:43.608Z","comments":false,"path":"about/index.html","permalink":"http://weiquanfan.xyz/about/index.html","excerpt":"","text":"æˆ‘æ˜¯è°æˆ‘åœ¨å“ªæˆ‘è¦å»å“ªé‡Œ"},{"title":"Links","date":"2020-05-03T16:35:31.293Z","updated":"2020-05-03T16:35:31.293Z","comments":false,"path":"links/index.html","permalink":"http://weiquanfan.xyz/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2020-05-03T16:06:52.302Z","updated":"2019-08-02T02:17:12.000Z","comments":false,"path":"repository/index.html","permalink":"http://weiquanfan.xyz/repository/index.html","excerpt":"","text":""},{"title":"Tags","date":"2020-05-03T16:35:25.551Z","updated":"2020-05-03T16:35:25.551Z","comments":false,"path":"tags/index.html","permalink":"http://weiquanfan.xyz/tags/index.html","excerpt":"","text":""},{"title":"Categories","date":"2020-05-03T16:35:38.847Z","updated":"2020-05-03T16:35:38.847Z","comments":false,"path":"categories/index.html","permalink":"http://weiquanfan.xyz/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"nvidiaé©±åŠ¨é‡è£…","slug":"nvidia-driver","date":"2021-08-22T14:10:15.000Z","updated":"2021-08-22T14:11:42.146Z","comments":true,"path":"2021/08/22/nvidia-driver/","link":"","permalink":"http://weiquanfan.xyz/2021/08/22/nvidia-driver/","excerpt":"","text":"åœ¨é‡å¯æœåŠ¡å™¨çš„æ—¶å€™ï¼Œå‘ç°nvidiaé©±åŠ¨è‡ªåŠ¨å‡çº§ï¼Œä½¿ç”¨ nvidia-smi å‘½ä»¤ä¼šæŠ¥é”™å¦‚ä¸‹ï¼Œæ•…é‡è£…nvidiaé©±åŠ¨ï¼Œå‚è€ƒUbuntu18.04çš„é©±åŠ¨nvidiaé©±åŠ¨å‡çº§ä¸º450ç‰ˆæœ¬åï¼Œsshé€Ÿåº¦å¾ˆæ…¢çš„è§£å†³æ–¹æ¡ˆ NVIDIA-SMI has failed because it couldn&#39;t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running. å¸è½½æ—§é©±åŠ¨sudo apt-get --purge remove nvidia* sudo apt autoremove é‡å¯ï¼Œä½¿å¾—æ‰€æœ‰nvidiaæ®‹ä½™è¿›ç¨‹è¢«æ€æ‰ï¼Œå¦åˆ™æ— æ³•å®‰è£… sudo shutdown -r now ä¸‹è½½å®‰è£…é©±åŠ¨å®éªŒè¯æ˜440.100ç‰ˆæœ¬é©±åŠ¨å¯¹18.04ååˆ†é€‚åˆï¼Œè¦ç‰ˆæœ¬è¯·è‡ªè¡ŒæŸ¥è¯¢ã€‚ wget https://cn.download.nvidia.com/XFree86/Linux-x86_64/440.100/NVIDIA-Linux-x86_64-440.100.run sudo chmod a+x NVIDIA-Linux-x86_64-440.100.run sudo ./NVIDIA-Linux-x86_64-440.100.run -no-x-check -no-nouveau-check -no-opengl-files å®‰è£…è¿‡ç¨‹The distribution-provided pre-install script failed! Are you sure you want to continue? é€‰æ‹© yes ç»§ç»­ã€‚Would you like to register the kernel module souces with DKMS? This will allow DKMS to automatically build a new module, if you install a different kernel later? é€‰æ‹© No ç»§ç»­ã€‚Would you like to run the nvidia-xconfigutility to automatically update your x configuration so that the NVIDIA x driver will be used when you restart x? Any pre-existing x confile will be backed up. é€‰æ‹©No é‡å¯sudo shutdown -r now æå‡nvidia-smiè¿è¡Œé€Ÿåº¦æ–¹æ³•1ï¼š sudo /usr/bin/nvidia-persistenced --verbose ä¹Ÿå¯ç›´æ¥æŠŠè¯¥å‘½ä»¤æ”¾åˆ°å¼€æœºè‡ªåŠ¨è¿è¡Œ echo &quot;/usr/bin/nvidia-persistenced --verbose&quot; | sudo tee -a /etc/init.d/rc.local æ–¹æ³•2ï¼šè®¾ç½®æŒä¹…æ¨¡å¼ï¼š0/DISABLED,1/ENABLED sudo nvidia-smi -pm 1 å®Œæˆ","categories":[],"tags":[]},{"title":"è¯­éŸ³ç‰¹å¾å°ç»“","slug":"audio-features","date":"2021-08-22T12:36:20.000Z","updated":"2021-08-22T14:03:23.565Z","comments":true,"path":"2021/08/22/audio-features/","link":"","permalink":"http://weiquanfan.xyz/2021/08/22/audio-features/","excerpt":"","text":"å‰è¨€æœ¬æ–‡æ±‡æ€»äº†ä¸€äº›å¸¸è§æˆ–ä¸å¸¸è§çš„è¯­éŸ³ç‰¹å¾ï¼ŒæŒç»­æ›´æ–°ä¸­ã€‚ ç‰¹å¾æ±‡æ€»éŸµå¾‹ç‰¹å¾ï¼ˆprosodic featureï¼‰åŒ…å«è¯­éŸ³ä¸­éŸ³é«˜ã€è¯­è°ƒã€èƒ½é‡ã€èŠ‚å¥å˜åŒ–ç­‰é‡è¦ä¿¡æ¯ï¼Œè¡¨ç°ä¸ºäººæ˜•è§‰ç³»ç»Ÿæ„ŸçŸ¥åˆ°çš„â€œæŠ‘æ‰¬é¡¿æŒ«â€ï¼Œåœ¨è¯­éŸ³ä¿¡å·å¤„ç†çš„è®¸å¤šé¢†åŸŸéƒ½æœ‰åº”ç”¨ã€‚åŸºéŸ³é¢‘ç‡ã€è¯­é€Ÿã€èƒ½é‡ç­‰éƒ½æ˜¯å¸¸ç”¨çš„éŸµå¾‹å­¦ç‰¹å¾ã€‚ åŸºéŸ³é¢‘ç‡ï¼ˆfundamental frequency, F0ï¼‰æ˜¯æŒ‡å‘æµŠéŸ³æ—¶å£°å¸¦æŒ¯åŠ¨çš„é¢‘ç‡ï¼Œç®€ç§°åŸºé¢‘ã€‚äººå‘å£°è¿‡ç¨‹ä¸­æ¥è‡ªè‚ºéƒ¨çš„æ°”æµå†²å‡»å£°é—¨ï¼Œå½¢æˆä¸€ç³»åˆ—å‡†å‘¨æœŸçš„æ°”æµè„‰å†²ï¼Œç»è¿‡å£°é“çš„è°æŒ¯åŠå”‡é½¿è¾å°„æœ€ç»ˆå½¢æˆè¯­éŸ³ä¿¡å·ï¼Œæ•…æµŠéŸ³æ³¢å½¢å‘ˆç°ä¸€å®šçš„å‡†å‘¨æœŸæ€§ï¼Œè¿™ä¸ªå‘¨æœŸå°±æ˜¯åŸºéŸ³å‘¨æœŸï¼Œå®ƒå’ŒåŸºé¢‘æˆå€’æ•°å…³ç³»ã€‚åŸºé¢‘å˜åŒ–èŒƒå›´å¾ˆå¤§ï¼Œå—æ€§åˆ«ã€å¹´é¾„ã€æƒ…ç»ªç­‰å¤šç§å› ç´ çš„å½±å“ã€‚ä¸€èˆ¬è€Œè¨€ï¼Œç”·æ€§çš„åŸºé¢‘èŒƒå›´æ˜¯135-185Hzï¼Œå¥³æ€§åœ¨260-350Hzä¹‹é—´ã€‚ åŸºé¢‘æ£€æµ‹æ–¹æ³•ä¸»è¦æœ‰ä¸‰ç±»ï¼š1ã€æ—¶åŸŸï¼šåŸºäºè¿‡é›¶ç‡ï¼Œè‡ªç›¸å…³ç­‰ï¼Œæœ€å¥½çš„æ˜¯YIN/PYINç®—æ³•ã€‚2ã€é¢‘åŸŸï¼šå€’è°±ï¼Œè°æ³¢ï¼Œæœ€ä½³æ¢³å¦†æ»¤æ³¢å™¨ç­‰ã€‚3ã€ç»Ÿè®¡æ–¹æ³•ï¼šæœ€å¤§ä¼¼ç„¶ï¼Œrnnï¼ŒHMMç­‰éƒ½æœ‰ã€‚ è¯­é€Ÿï¼ˆspeaking rateï¼‰ ç‰¹å¾è¡¨è¾¾äº†è®²è¯é€Ÿåº¦çš„å¿«æ…¢ï¼Œå¯ä»¥å®šä¹‰ä¸ºå•ä½æ—¶é—´å†…å‘éŸ³çš„è¯æ±‡ï¼ˆæˆ–è€…éŸ³èŠ‚ï¼‰ä¸ªæ•°ã€‚è¯­é€Ÿå—æ–‡åŒ–ã€ç¯å¢ƒã€æ€ç»´å’Œè¡¨è¾¾èƒ½åŠ›å¤šç§å› ç´ çš„å½±å“ã€‚å’Œè¯­é€Ÿå¯†åˆ‡ç›¸å…³çš„å› ç´ è¿˜æœ‰åœé¡¿ï¼Œæ˜¯å¦è€ƒè™‘è¯­æ®µä¸­çš„åœé¡¿å¯¹è¯­é€Ÿçš„è®¡ç®—æ•°å€¼æœ‰æ˜æ˜¾å½±å“ã€‚ èƒ½é‡ï¼ˆenergyï¼‰æ˜¯ä¸è¯­éŸ³éŸ³é‡ï¼ˆæˆ–è€…è¯´å¹…åº¦ï¼‰ç›¸å…³çš„å£°å­¦ç‰¹å¾ã€‚èƒ½é‡ç‰¹å¾åŒ…å«ä¸°å¯Œçš„æƒ…æ„Ÿä¿¡æ¯ï¼Œæ¯”å¦‚äººåœ¨æ‚²ä¼¤æ—¶è¯­éŸ³çš„èƒ½é‡é€šå¸¸ä¼šæ¯”è¾ƒä½ã€‚å¾ˆæ—©ä»¥å‰ vadï¼ˆvoice active detection) ä¸­æœ‰ä¸€ç§æ£€æµ‹è¯­éŸ³æ–¹æ³•ï¼šèƒ½é‡å¤§çš„æ˜¯è¯­éŸ³ï¼Œèƒ½é‡å°çš„æ˜¯å™ªå£°ã€‚å½“ç„¶ï¼Œè¿™ç§vadå±€é™æ€§éå¸¸å¤§ï¼Œç”¨é€”å¾ˆçª„ã€‚ è¿‡é›¶ç‡ (zero-crossing rate) æ ¸å¿ƒç‚¹æ˜¯è®¡ç®—ä¿¡å·è·¨è¶Šé›¶ç‚¹çš„æ¬¡æ•°ï¼Œæ—©æœŸç”¨äºvadï¼Œåˆ¤åˆ«è¯­éŸ³å’Œå™ªå£°ï¼Œå±€é™æ€§ä¹Ÿè¾ƒå¤§ã€‚ è°±ç‰¹å¾ï¼ˆspectral featureï¼‰å«ä¹‰ç›¸å¯¹å®½æ³›ï¼Œé€šå¸¸åŒ…å«äº†è¯­éŸ³ä¿¡å·çš„é¢‘è°±ã€åŠŸç‡è°±ã€å€’é¢‘è°±ã€é¢‘è°±åŒ…ç»œç­‰ç‰¹å¾ã€‚ç”±äºè¯­éŸ³æ˜¯çŸ­æ—¶å¹³ç¨³ä¿¡å·ï¼Œæ‰€ä»¥é€šå¸¸ç”¨çŸ­æ—¶å‚…é‡Œå¶å˜åŒ–å¯¹è¯­éŸ³åšåˆ†æï¼Œè¿™æ ·äº§ç”Ÿçš„ç‰¹å¾èƒ½åæ˜ è¯­éŸ³çš„çŸ­æ—¶ç‰¹æ€§ã€‚ æ¢…å°”å€’è°±ç³»æ•°ï¼ˆMel-frequency Cepstral Coefficients, MFCCï¼‰ åŸç†ï¼šæ ¹æ®äººè€³å¬è§‰æœºç†çš„ç ”ç©¶å‘ç°ï¼Œäººè€³å¯¹ä¸åŒé¢‘ç‡çš„å£°æ³¢æœ‰ä¸åŒçš„å¬è§‰æ•æ„Ÿåº¦ã€‚ä»200HZåˆ°5000HZå¯¹è¯­éŸ³çš„æ¸…æ™°åº¦å½±å“æœ€å¤§ã€‚ä¸¤ä¸ªå“åº¦ä¸ç­‰çš„å£°éŸ³ä½œç”¨äºäººè€³æ—¶ï¼Œåˆ™å“åº¦è¾ƒé«˜çš„é¢‘ç‡æˆåˆ†çš„å­˜åœ¨ä¼šå½±å“åˆ°å¯¹å“åº¦è¾ƒä½çš„é¢‘ç‡æˆåˆ†çš„æˆåˆ†ï¼Œä½¿å…¶å˜å¾—ä¸æ˜“å¯Ÿè§‰ï¼Œè¿™ç§ç°è±¡ç§°ä¸ºæ©è”½æ•ˆåº”ã€‚ç”±äºé¢‘ç‡è¾ƒä½çš„å£°éŸ³åœ¨å†…è€³èœ—åŸºåº•è†œä¸Šè¡Œæ³¢ä¼ é€’çš„è·ç¦»å¤§äºé¢‘ç‡è¾ƒé«˜çš„å£°éŸ³ï¼Œæ•…ä¸€èˆ¬æ¥è¯´ï¼Œä½éŸ³å®¹æ˜“æ©è”½é«˜éŸ³ï¼Œè€Œé«˜éŸ³æ©è”½ä½éŸ³è¾ƒå›°éš¾ã€‚åœ¨ä½é¢‘å¤„çš„å£°éŸ³æ©è”½ä¸´ç•Œå¸¦å®½è¾ƒé«˜é¢‘è¦å°ã€‚æ‰€ä»¥ä»ä½é¢‘åˆ°é«˜é¢‘è¿™ä¸€é¢‘å¸¦å†…æŒ‰ä¸´ç•Œå¸¦å®½çš„å¤§å°ç”±å¯†åˆ°ç–å®‰æ’ä¸€ç»„å¸¦é€šæ»¤æ³¢å™¨ï¼Œå¯¹è¾“å…¥ä¿¡å·è¿›è¡Œæ»¤æ³¢ã€‚å®ƒæ˜¯Melæ ‡åº¦é¢‘ç‡åŸŸæå–å‡ºæ¥çš„å€’è°±ç³»æ•°ï¼Œå¸¸ç”¨åœ¨è¯­éŸ³è¯†åˆ«å’Œè¯´è¯äººè¯†åˆ«é¢†åŸŸã€‚MFCCä½¿ç”¨ä¸€ç»„ä»ä½é¢‘åˆ°é«˜é¢‘ç”±å¯†åˆ°ç–äº¤å æ’åˆ—çš„ä¸‰è§’å½¢å¸¦é€šæ»¤æ³¢å™¨æ„å»ºç‰¹å¾ï¼Œè¿™å’Œäººè€³çš„å¬è§‰ç‰¹æ€§ç›¸ç¬¦ã€‚å‡ºäºè®¡ç®—å¤æ‚åº¦çš„è€ƒè™‘ï¼Œå®é™…ä½¿ç”¨ä¸­MFCCç³»æ•°é€šå¸¸å–12-16é˜¶ã€‚ Barkè°± (Bark Spectrogram)Barkè°±ä¸MFCCï¼ŒMelè°±éå¸¸ç›¸ä¼¼ï¼Œéƒ½æ˜¯å°†çº¿æ€§è°±æ˜ å°„åˆ°éçº¿æ€§è°±ä¸Šçš„è¡¨å¾ï¼Œè€Œä¸”éƒ½æ˜¯ä½é¢‘å¸¦å®½ä½ï¼Œé«˜é¢‘å¸¦å®½é«˜ã€‚ ä¸Šä¸–çºªï¼Œç ”ç©¶è€…å‘ç°äººè€³ç»“æ„å¯¹24ä¸ªé¢‘ç‚¹äº§ç”Ÿå…±æŒ¯ï¼Œæ ¹æ®è¿™ä¸€ç†è®ºï¼ŒEberhard Zwickeråœ¨1961å¹´é’ˆå¯¹äººè€³ç‰¹æ®Šç»“æ„æå‡ºï¼šä¿¡å·åœ¨é¢‘å¸¦ä¸Šä¹Ÿå‘ˆç°å‡º24ä¸ªä¸´ç•Œé¢‘å¸¦ï¼Œåˆ†åˆ«ä»1åˆ°24ã€‚è¿™å°±æ˜¯BarkåŸŸã€‚ CQT (Constant Q Transform)æ’Qå˜æ¢ï¼Œä¹Ÿæ˜¯ä¸€ç§éçº¿æ€§æ˜ å°„ã€‚æŒ‡ä¸­å¿ƒé¢‘ç‡æŒ‰æŒ‡æ•°è§„å¾‹åˆ†å¸ƒï¼Œæ»¤æ³¢å¸¦å®½ä¸åŒã€ä½†ä¸­å¿ƒé¢‘ç‡ä¸å¸¦å®½æ¯”ä¸ºå¸¸é‡Qçš„æ»¤æ³¢å™¨ç»„ã€‚ä¸å‚…ç«‹å¶å˜æ¢ä¸åŒï¼Œå®ƒé¢‘è°±çš„æ¨ªè½´é¢‘ç‡ä¸æ˜¯çº¿æ€§çš„ï¼Œè€Œæ˜¯åŸºäºlog2ä¸ºåº•çš„ï¼Œå¹¶ä¸”å¯ä»¥æ ¹æ®è°±çº¿é¢‘ç‡çš„ä¸åŒè¯¥æ”¹å˜æ»¤æ³¢çª—é•¿åº¦ï¼Œä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚ç”±äºç¬¦åˆä¹ç†å¸¸ç”¨åœ¨éŸ³ä¹ä¸­ã€‚ ä¹ç†é‡Œï¼Œæ‰€æœ‰çš„éŸ³éƒ½æ˜¯ç”±è‹¥å¹²å…«åº¦çš„12å¹³å‡å¾‹å…±åŒç»„æˆçš„ï¼Œ12ä¸ªåŠéŸ³ç­‰äºä¸€ä¸ªå…«åº¦ï¼Œä¸€ä¸ªå…«åº¦çš„è·¨åº¦ç­‰äºé¢‘ç‡ç¿»å€ï¼Œæ‰€ä»¥ä¸€ä¸ªåŠéŸ³ç­‰äº2^(1/12)å€é¢‘ã€‚å› æ­¤ï¼ŒéŸ³ä¹ä¸­çš„éŸ³è°ƒå‘ˆæŒ‡æ•°å‹è·¨åº¦çš„ï¼Œè€ŒCQTå°±å¾ˆå¥½çš„æ¨¡æ‹Ÿäº†è¿™ç§éçº¿æ€§åº¦ï¼Œä»¥ log2 ä¸ºåº•çš„éçº¿æ€§é¢‘è°±ã€‚ å…±æŒ¯å³°ï¼ˆformantï¼‰æ˜¯åŸºé¢‘å¯¹åº”çš„æ•´æ•°æ¬¡é¢‘ç‡æˆåˆ†ï¼Œç”¨æ¥åæ˜ äººçš„å£°é“ç‰©ç†ç‰¹æ€§ã€‚å£°é“å¯ä»¥çœ‹æˆå…·æœ‰éå‡åŒ€æˆªé¢çš„å£°ç®¡ï¼Œå½“å‡†å‘¨æœŸè„‰å†²æ¿€åŠ±è¿›å…¥å£°é“æ—¶ä¼šå¸¦åŠ¨ç©ºæ°”å…±æŒ¯ï¼Œäº§ç”Ÿä¸€ç»„å…±æŒ¯é¢‘ç‡ï¼Œç§°ä¸ºå…±æŒ¯å³°é¢‘ç‡æˆ–ç®€ç§°å…±æŒ¯å³°ã€‚å…±æŒ¯å³°ç‰¹å¾åŒ…æ‹¬å…±æŒ¯å³°é¢‘ç‡å’Œé¢‘å¸¦å®½åº¦ç­‰ã€‚å…±æŒ¯å³°ä¿¡æ¯åŒ…å«åœ¨è¯­éŸ³é¢‘è°±åŒ…ç»œä¹‹ä¸­ï¼Œåœ¨è¯­éŸ³ä¿¡å·åˆæˆã€è¯­éŸ³è¯†åˆ«ä¸­éƒ½æœ‰å¹¿æ³›åº”ç”¨ã€‚ç ”ç©¶ä¸­å¸¸ç”¨çš„é€šå¸¸æ˜¯å‰ä¸‰ä¸ªå…±æŒ¯å³°ã€‚å…±æŒ¯å³°çš„åŒ…ç»œï¼Œä½ç½®ï¼Œç›¸é‚»çš„è·ç¦»å…±åŒå½¢æˆäº†éŸ³è‰²ç‰¹å¾ã€‚å…±æŒ¯å³°ä¹‹é—´è·ç¦»è¿‘å¬èµ·æ¥åˆ™ååšç²—ï¼Œä¹‹é—´è·ç¦»è¿œå¬èµ·æ¥åæ¸…æ¾ˆã€‚åœ¨ç”·å£°å˜å¥³å£°çš„æ—¶å€™ï¼Œé™¤äº†åŸºé¢‘çš„ç§»åŠ¨ï¼Œè¿˜éœ€è¦è°ƒæ•´å…±æŒ¯å³°ï¼ŒåŒ…æ‹¬åŒ…ç»œï¼Œè·ç¦»ç­‰ã€‚å¦åˆ™å°†ä¼šä¸¢å¤±éŸ³è‰²ä¿¡æ¯ã€‚ ä¸€ä¸ªæµŠéŸ³ç”¨ä¸‰ä¸ªå…±æŒ¯å³°æ¥è¡¨ç¤ºï¼Œä¸€ä¸ªå…±æŒ¯å³°çš„é¢‘è°±ç‰¹æ€§å…¶å®å¯ä»¥ç”¨ä¸€ä¸ªGMMæ¥å»ºæ¨¡æ‹Ÿåˆçš„ï¼Œä¹Ÿå°±æ˜¯è¯´ä¸€ä¸ªæµŠéŸ³æ˜¯éœ€è¦ä¸‰ä¸ªGMMæ¥å»ºæ¨¡æ‹Ÿåˆï¼Œæ‰€ä»¥HMMéœ€è¦ä¸‰ä¸ªçŠ¶æ€ä¹Ÿæ˜¯è¿™æ ·æ¥çš„ï¼›è€Œéæ–‡æœ¬éŸ³ç´ è¦ç”¨äº”ä¸ªHMMçŠ¶æ€ï¼Œä¹Ÿæ˜¯å› ä¸ºæ¸…éŸ³æ¯”è¾ƒå¤æ‚ï¼Œéœ€è¦äº”ä¸ªå…±æŒ¯å³°æ‰èƒ½è¾ƒå¥½è¡¨ç¤ºã€‚ çº¿æ€§é¢„æµ‹ç³»æ•°ï¼ˆLinear Predictive Coefficients, LPCï¼‰ æ˜¯æŒ‡å¯¹è¯­éŸ³ä¿¡å·å€¼è¿›è¡Œçº¿æ€§é¢„æµ‹çš„ä¸€ç»„ç³»æ•°ã€‚å…·ä½“è€Œè¨€ï¼ŒLPCæ˜¯ç”¨è‹¥å¹²ä¸ªè¿‡å»å€¼çš„åŠ æƒçº¿æ€§ç»„åˆæ¥é€¼è¿‘å½“å‰å€¼ï¼Œå…¶ä¸­çš„æƒå€¼å³ä¸ºçº¿æ€§é¢„æµ‹ç³»æ•°ã€‚LPCèƒ½ç²¾ç¡®ã€ä¾¿æ·åœ°è¡¨å¾è¯­éŸ³çŸ­æ—¶èƒ½é‡çš„è°±åŒ…ç»œï¼Œå¹¶ä¸”èƒ½æœ‰æ•ˆåœ°ä¼°è®¡åŸºé¢‘ã€å…±æŒ¯å³°ç­‰è¯­éŸ³å‚æ•°ã€‚ Teagerèƒ½é‡ç®—å­ï¼ˆTeager Energy Operation, TEOï¼‰æ˜¯H.M.Teageræå‡ºçš„ç”¨ä»¥è·Ÿè¸ªä¿¡å·ç¬æ—¶èƒ½é‡çš„éçº¿æ€§ç®—å­ ã€‚TeageræŒ‡å‡ºï¼Œä¸€ä¸ªä¿¡å·çš„èƒ½é‡ä¸ä»…ä¸å®ƒçš„å¹…åº¦ç›¸å…³ï¼Œè€Œä¸”ä¸å®ƒçš„æŒ¯åŠ¨é¢‘ç‡ç›¸å…³ã€‚TEOè®¡ç®—ç®€å•ä¸”æ—¶é—´åˆ†è¾¨ç‡é«˜ï¼Œå¯¹äºè§£è°ƒä¿¡å·æ•ˆæœå¾ˆå¥½ã€‚ å£°é—¨æ³¢ï¼ˆglottal waveï¼‰ååº”äº†å£°é—¨ç‰¹æ€§ï¼Œæ˜¯ä¸€ç§æºç‰¹å¾ã€‚å£°é—¨æ³¢å¯ä»¥è·å¾—æ¯”è¾ƒå‡†ç¡®çš„å£°é“å“åº”ï¼Œå®ƒè•´å«æƒ…æ„Ÿä¿¡æ¯ï¼Œå¯¹æƒ…æ„Ÿè¯†åˆ«æœ‰ä¸€å®šä½œç”¨ã€‚ä¹Ÿæœ‰æ–‡ç« æ˜¾ç¤ºï¼Œä»å£°é—¨æ³¢çš„å¹…å€¼æå–å‡ºçš„ç‰¹å¾ï¼Œå¦‚NormalisedAmplitude Quotient (NAQ), the Quasi Open-Quotient (QOQï¼‰ç­‰ã€‚ ç‰¹å¾é›†æ±‡æ€»GeMAPSç‰¹å¾é›†GeMAPSç‰¹å¾é›†æ€»å…±62ä¸ªç‰¹å¾ï¼Œè¿™62ä¸ªéƒ½æ˜¯HSFç‰¹å¾ï¼Œæ˜¯ç”±18ä¸ªLLDç‰¹å¾è®¡ç®—å¾—åˆ°ã€‚ä¸‹é¢å…ˆä»‹ç»18ä¸ªLLDç‰¹å¾ï¼Œç„¶åä»‹ç»62ä¸ªHSFç‰¹å¾ã€‚è¿™é‡Œåªç®€å•ä»‹ç»æ¯ä¸ªç‰¹å¾çš„æ¦‚å¿µï¼Œä¸æ¶‰åŠå…·ä½“è®¡ç®—ç»†èŠ‚ã€‚ 18ä¸ªLLDç‰¹å¾åŒ…æ‹¬6ä¸ªé¢‘ç‡ç›¸å…³ç‰¹å¾ï¼Œ3ä¸ªèƒ½é‡/æŒ¯å¹…ç›¸å…³ç‰¹å¾ï¼Œ9ä¸ªè°±ç‰¹å¾ã€‚6ä¸ªé¢‘ç‡ç›¸å…³ç‰¹å¾åŒ…æ‹¬ï¼šPitchï¼ˆlog F0ï¼Œåœ¨åŠéŸ³é¢‘ç‡å°ºåº¦ä¸Šè®¡ç®—ï¼Œä»27.5Hzå¼€å§‹ï¼‰ï¼›Jitterï¼ˆå•ä¸ªè¿ç»­åŸºéŸ³å‘¨æœŸå†…çš„åå·®ï¼Œåå·®è¡¡é‡çš„æ˜¯è§‚æµ‹å˜é‡ä¸ç‰¹å®šå€¼çš„å·®ï¼Œå¦‚æœæ²¡æœ‰æŒ‡æ˜ç‰¹å®šå€¼é€šå¸¸ä½¿ç”¨çš„æ˜¯å˜é‡çš„å‡å€¼ï¼‰ï¼›å‰ä¸‰ä¸ªå…±æŒ¯å³°çš„ä¸­å¿ƒé¢‘ç‡ï¼Œç¬¬ä¸€ä¸ªå…±æŒ¯å³°çš„å¸¦å®½ã€‚3ä¸ªèƒ½é‡/æŒ¯å¹…çš„ç‰¹å¾åŒ…æ‹¬ï¼šShimmerï¼ˆç›¸é‚»åŸºéŸ³å‘¨æœŸé—´æŒ¯å¹…å³°å€¼ä¹‹å·®ï¼‰ï¼ŒLoudnessï¼ˆä»é¢‘è°±ä¸­å¾—åˆ°çš„å£°éŸ³å¼ºåº¦çš„ä¼°è®¡ï¼Œå¯ä»¥æ ¹æ®èƒ½é‡æ¥è®¡ç®—ï¼‰ï¼ŒHNRï¼ˆHarmonics-to-noiseï¼‰ä¿¡å™ªæ¯”ã€‚9ä¸ªè°±ç‰¹å¾åŒ…æ‹¬ï¼ŒAlpha Ratioï¼ˆ50-1000Hzçš„èƒ½é‡å’Œé™¤ä»¥1-5kHzçš„èƒ½é‡å’Œï¼‰ï¼ŒHammarberg Indexï¼ˆ0-2kHzçš„æœ€å¼ºèƒ½é‡å³°é™¤ä»¥2-5kHzçš„æœ€å¼ºèƒ½é‡å³°ï¼‰ï¼ŒSpectral Slope 0-500 Hz and 500-1500 Hzï¼ˆå¯¹çº¿æ€§åŠŸç‡è°±çš„ä¸¤ä¸ªåŒºåŸŸ0-500 Hzå’Œ500-1500 Hzåšçº¿æ€§å›å½’å¾—åˆ°çš„ä¸¤ä¸ªæ–œç‡ï¼‰ï¼ŒFormant 1, 2, and 3 relative energyï¼ˆå‰ä¸‰ä¸ªå…±æŒ¯å³°çš„ä¸­å¿ƒé¢‘ç‡é™¤ä»¥åŸºéŸ³çš„è°±å³°èƒ½é‡ï¼‰ï¼ŒHarmonic difference H1-H2ï¼ˆç¬¬ä¸€ä¸ªåŸºéŸ³è°æ³¢H1çš„èƒ½é‡é™¤ä»¥ç¬¬äºŒä¸ªåŸºéŸ³è°æ³¢çš„èƒ½é‡ï¼‰ï¼ŒHarmonic difference H1-A3ï¼ˆç¬¬ä¸€ä¸ªåŸºéŸ³è°æ³¢H1çš„èƒ½é‡é™¤ä»¥ç¬¬ä¸‰ä¸ªå…±æŒ¯å³°èŒƒå›´å†…çš„æœ€é«˜è°æ³¢èƒ½é‡ï¼‰ã€‚ å¯¹18ä¸ªLLDåšç»Ÿè®¡ï¼Œè®¡ç®—çš„æ—¶å€™æ˜¯å¯¹3å¸§è¯­éŸ³åšsymmetric moving averageã€‚é¦–å…ˆè®¡ç®—ç®—æœ¯å¹³å‡å’Œcoefficient of variationï¼ˆè®¡ç®—æ ‡å‡†å·®ç„¶åç”¨ç®—æœ¯å¹³å‡è§„èŒƒåŒ–ï¼‰ï¼Œå¾—åˆ°36ä¸ªç»Ÿè®¡ç‰¹å¾ã€‚ç„¶åå¯¹loudnesså’Œpitchè¿ç®—8ä¸ªå‡½æ•°ï¼Œ20ç™¾åˆ†ä½ï¼Œ50ç™¾åˆ†ä½ï¼Œ80ç™¾åˆ†ä½ï¼Œ20åˆ°80ç™¾åˆ†ä½ä¹‹é—´çš„rangeï¼Œä¸Šå‡/ä¸‹é™è¯­éŸ³ä¿¡å·çš„æ–œç‡çš„å‡å€¼å’Œæ ‡å‡†å·®ã€‚è¿™æ ·å°±å¾—åˆ°16ä¸ªç»Ÿè®¡ç‰¹å¾ã€‚ä¸Šé¢çš„å‡½æ•°éƒ½æ˜¯å¯¹voiced regionsï¼ˆéé›¶çš„F0ï¼‰åšçš„ã€‚å¯¹Alpha Ratioï¼ŒHammarberg Indexï¼ŒSpectral Slope 0-500 Hz and 500-1500 Hzåšç®—æœ¯å¹³å‡å¾—åˆ°4ä¸ªç»Ÿè®¡ç‰¹å¾ã€‚å¦å¤–è¿˜æœ‰6ä¸ªæ—¶é—´ç‰¹å¾ï¼Œæ¯ç§’loudnesså³°çš„ä¸ªæ•°ï¼Œè¿ç»­voiced regionsï¼ˆF0&gt;0ï¼‰çš„å¹³å‡é•¿åº¦å’Œæ ‡å‡†å·®ï¼Œunvoiced regionsï¼ˆF0=0ï¼‰çš„å¹³å‡é•¿åº¦å’Œæ ‡å‡†å·®ï¼Œæ¯ç§’voiced regionsçš„ä¸ªæ•°ã€‚36+16+4+6å¾—åˆ°62ä¸ªç‰¹å¾ã€‚ eGeMAPSç‰¹å¾é›†ï¼ˆ1ï¼‰eGeMAPSæ˜¯GeMAPSçš„æ‰©å±•ï¼Œåœ¨18ä¸ªLLDsçš„åŸºç¡€ä¸ŠåŠ äº†ä¸€äº›ç‰¹å¾ï¼ŒåŒ…æ‹¬5ä¸ªè°±ç‰¹å¾ï¼šMFCC1-4å’ŒSpectral fluxï¼ˆä¸¤ä¸ªç›¸é‚»å¸§çš„é¢‘è°±å·®å¼‚ï¼‰å’Œ2ä¸ªé¢‘ç‡ç›¸å…³ç‰¹å¾ï¼šç¬¬äºŒä¸ªå…±æŒ¯å³°å’Œç¬¬ä¸‰ä¸ªå…±æŒ¯å³°çš„å¸¦å®½ã€‚ï¼ˆ2ï¼‰å¯¹è¿™æ‰©å±•çš„7ä¸ªLLDsåšç®—æœ¯å¹³å‡å’Œcoefficient of variationï¼ˆè®¡ç®—æ ‡å‡†å·®ç„¶åç”¨ç®—æœ¯å¹³å‡è§„èŒƒåŒ–ï¼‰å¯ä»¥å¾—åˆ°14ä¸ªç»Ÿè®¡ç‰¹å¾ã€‚å¯¹äºå…±æŒ¯å³°å¸¦å®½åªåœ¨voiced regionåšï¼Œå¯¹äº5ä¸ªè°±ç‰¹å¾åœ¨voiced regionå’Œunvoiced regionä¸€èµ·åšã€‚ï¼ˆ3ï¼‰å¦å¤–ï¼Œåªåœ¨unvoiced regionè®¡ç®—spectral fluxçš„ç®—æœ¯å¹³å‡ï¼Œç„¶ååªåœ¨voiced regionè®¡ç®—5ä¸ªè°±ç‰¹å¾çš„ç®—æœ¯å¹³å‡å’Œcoefficient of variationï¼Œå¾—åˆ°11ä¸ªç»Ÿè®¡ç‰¹å¾ã€‚ï¼ˆ4ï¼‰å¦å¤–ï¼Œè¿˜åŠ å¤šä¸€ä¸ªequivalent sound level ã€‚ï¼ˆ5ï¼‰æ‰€ä»¥æ€»å…±å¾—åˆ°14+11+1=26ä¸ªæ‰©å±•ç‰¹å¾ï¼ŒåŠ ä¸ŠåŸGeMAPSçš„62ä¸ªç‰¹å¾ï¼Œå¾—åˆ°88ä¸ªç‰¹å¾ï¼Œè¿™88ä¸ªç‰¹å¾å°±æ˜¯eGeMAPSçš„ç‰¹å¾é›†ã€‚ ComParEç‰¹å¾é›†ï¼ˆ1ï¼‰ComParEï¼ŒComputational Paralinguistics ChallengEï¼Œæ˜¯InterSpeechä¸Šçš„ä¸€ä¸ªæŒ‘æˆ˜èµ›ï¼Œä»13å¹´è‡³ä»Šï¼ˆ2018å¹´ï¼‰ï¼Œæ¯å¹´éƒ½ä¸¾åŠï¼Œæ¯å¹´æœ‰ä¸ä¸€æ ·çš„æŒ‘æˆ˜ä»»åŠ¡ã€‚ï¼ˆ2ï¼‰ä»13å¹´å¼€å§‹è‡³ä»Šï¼ˆ2018å¹´ï¼‰ï¼ŒComParEçš„æŒ‘æˆ˜éƒ½ä¼šè¦æ±‚ä½¿ç”¨ä¸€ä¸ªè®¾è®¡å¥½çš„ç‰¹å¾é›†ï¼Œè¿™ä¸ªç‰¹å¾é›†åŒ…å«äº†6373ä¸ªé™æ€ç‰¹å¾ï¼Œæ˜¯åœ¨LLDä¸Šè®¡ç®—å„ç§å‡½æ•°å¾—åˆ°çš„ï¼Œç§°ä¸ºComParEç‰¹å¾é›†ã€‚ï¼ˆ3ï¼‰å¯ä»¥é€šè¿‡openSmileå¼€æºåŒ…æ¥è·å¾—ï¼Œå¦å¤–å‰é¢æåˆ°çš„eGeMAPSä¹Ÿå¯ä»¥ç”¨openSmileè·å¾—ã€‚äº”ï¼š2009 InterSpeechæŒ‘æˆ˜èµ›ç‰¹å¾ï¼ˆ1ï¼‰å‰é¢è¯´çš„6373ç»´ç‰¹å¾é›†ComparEæ˜¯13å¹´è‡³ä»ŠInterSpeechæŒ‘æˆ˜èµ›ä¸­ç”¨çš„ã€‚ï¼ˆ2ï¼‰æœ‰è®ºæ–‡è¿˜ç”¨äº†09å¹´InterSpeechä¸ŠEmotion Challengeæåˆ°çš„ç‰¹å¾ï¼Œæ€»å…±æœ‰384ä¸ªç‰¹å¾ï¼Œè®¡ç®—æ–¹æ³•å¦‚ä¸‹ã€‚ï¼ˆ3ï¼‰é¦–å…ˆè®¡ç®—16ä¸ªLLDï¼Œè¿‡é›¶ç‡ï¼Œèƒ½é‡å¹³æ–¹æ ¹ï¼ŒF0ï¼ŒHNRï¼ˆä¿¡å™ªæ¯”ï¼Œæœ‰äº›è®ºæ–‡ä¹Ÿå«vpï¼Œvoice probability äººå£°æ¦‚ç‡ï¼‰ï¼ŒMFCC1-12ï¼Œç„¶åè®¡ç®—è¿™16ä¸ªLLDçš„ä¸€é˜¶å·®åˆ†ï¼Œå¯ä»¥å¾—åˆ°32ä¸ªLLDã€‚ï¼ˆ4ï¼‰å¯¹è¿™32ä¸ªLLDåº”ç”¨12ä¸ªç»Ÿè®¡å‡½æ•°ï¼Œæœ€åå¾—åˆ°32x12 = 384ä¸ªç‰¹å¾ã€‚ï¼ˆ5ï¼‰åŒæ ·å¯ä»¥é€šè¿‡openSmileæ¥è·å¾—ã€‚ BoAWï¼ˆBoAWï¼Œbag-of-audio-wordsï¼Œæ˜¯ç‰¹å¾çš„è¿›ä¸€æ­¥ç»„ç»‡è¡¨ç¤ºï¼Œæ˜¯æ ¹æ®ä¸€ä¸ªcodebookå¯¹LLDsåšè®¡ç®—å¾—åˆ°çš„ã€‚è¿™ä¸ªcodebookå¯ä»¥æ˜¯k-meansçš„ç»“æœï¼Œä¹Ÿå¯ä»¥æ˜¯å¯¹LLDsçš„éšæœºé‡‡æ ·ã€‚åœ¨è®ºæ–‡ä¼šçœ‹åˆ°BoAWç‰¹å¾é›†çš„è¯´æ³•ï¼ŒæŒ‡çš„æ˜¯æŸä¸ªç‰¹å¾é›†çš„BoAWå½¢å¼ã€‚æ¯”å¦‚æ ¹æ®ä¸Šä¸‹æ–‡â€œä½¿ç”¨ç‰¹å¾é›†æœ‰ComparEå’ŒBoAWâ€ï¼Œå¯ä»¥çŸ¥é“ï¼Œè¿™æ ·çš„è¯´æ³•å…¶å®æ˜¯æŒ‡åŸæ¥çš„ç‰¹å¾é›†ComparEï¼Œå’ŒComparEç»è¿‡è®¡ç®—åå¾—åˆ°çš„BoAWè¡¨ç¤ºã€‚å¯é€šè¿‡openXBOWå¼€æºåŒ…æ¥è·å¾—BoAWè¡¨ç¤ºã€‚ YAAFEï¼šä½¿ç”¨YAAFEåº“æå–åˆ°çš„ç‰¹å¾ï¼Œå…·ä½“ç‰¹å¾è§YAAFEä¸»é¡µã€‚ å‚è€ƒhttps://www.zhihu.com/question/24190826https://blog.csdn.net/weixin_42300798/article/details/113627332","categories":[{"name":"è¯­éŸ³ç‰¹å¾","slug":"è¯­éŸ³ç‰¹å¾","permalink":"http://weiquanfan.xyz/categories/è¯­éŸ³ç‰¹å¾/"}],"tags":[]},{"title":"VSCodeçš„æœåŠ¡å™¨å’ŒgithubåŒæ­¥","slug":"vscode","date":"2021-07-28T15:27:44.000Z","updated":"2021-07-28T15:29:41.939Z","comments":true,"path":"2021/07/28/vscode/","link":"","permalink":"http://weiquanfan.xyz/2021/07/28/vscode/","excerpt":"","text":"å¼•è¨€è¿‘æœŸå‘ç°VSCodeæ˜¯ä¸€ä¸ªéå¸¸å¼ºå¤§çš„IDEï¼Œå¯ä»¥æ›¿æ¢æ‰è¯¸å¦‚xshellã€winscpç­‰å¤šæ¬¾è½¯ä»¶ï¼Œå®ç°å¾ˆå¥½çš„æœ¬åœ°ã€æœåŠ¡å™¨ã€ç”šè‡³githubçš„åŒæ­¥ã€‚ å…¬é’¥ç§é’¥é…å¯¹ä¸ç®¡æ˜¯æœ¬åœ°åˆ°æœåŠ¡å™¨ï¼Œæœ¬åœ°åˆ°githubï¼Œè¿˜æ˜¯æœåŠ¡å™¨åˆ°githubï¼Œéƒ½å¯ä»¥é€šè¿‡é…ç½®å¯†é’¥çš„æ–¹å¼ï¼Œå®ç°å…å¯†ç™»å½•ï¼Œå› æ­¤å…ˆè®²è¿°å¦‚ä½•è¿›è¡Œå¯†é’¥é…å¯¹ã€‚é…å¯¹çš„æ—¶å€™ï¼Œè¦æŠŠå…¬é’¥åˆ†ç»™è¿œç¨‹ç«¯ï¼ŒæŠŠç§é’¥åˆ†ç»™æœ¬åœ°ç«¯ï¼ˆæœåŠ¡å™¨å‘ç»™å¦ä¸€ä¸ªæœåŠ¡å™¨æ—¶ä¹Ÿå¯ä»¥è§†ä¸ºæœ¬åœ°ç«¯ï¼‰ï¼Œå…¬é’¥ç§é’¥å”¯ä¸€åŒ¹é…ï¼Œåˆ™å¯ä»¥æˆåŠŸç™»å½•ã€‚ ç”Ÿæˆæ–°çš„å¯†é’¥ï¼Œåœ¨windowsçš„cmdï¼Œæˆ–linuxå’Œmacçš„ç»ˆç«¯ä¸­ï¼Œè¾“å…¥å¦‚ä¸‹å‘½ä»¤ï¼Œç¡®è®¤åä¼šç”Ÿæˆä¸¤ä¸ªæ–‡ä»¶ï¼Œid_rsaå’Œid_rsa.pubã€‚å‰è€…æ˜¯ç§é’¥ï¼Œåè€…æ˜¯å…¬é’¥ã€‚ssh-keygen -t rsa -C &quot;email@email.com&quot; æ‰¾åˆ°ç”Ÿæˆçš„å¯†é’¥ï¼Œé»˜è®¤æ”¾ç½®åœ¨ C:/Users/lenovo/.ssh/ ï¼Œç”¨è®°äº‹æœ¬ä¹‹ç±»çš„ç¼–è¾‘å™¨æ‰“å¼€id_rsa.pubï¼Œå¤åˆ¶å†…å®¹ã€‚ æŠŠå…¬é’¥å¤åˆ¶åˆ°è¿œç¨‹ç«¯ã€‚å¯¹äºæœåŠ¡å™¨ï¼Œå°†å¤åˆ¶çš„å†…å®¹è¿½åŠ åˆ° ~/.ssh/authorized_keys ã€‚å¯¹äºgithubï¼Œæ‰“å¼€github -&gt; ç‚¹å‡»å¤´åƒ -&gt; Settings -&gt; SSH and GPG keys -&gt; New SSH key -&gt;é»è´´keyï¼Œéšä¾¿å†™ä¸ªtitle -&gt; é…ç½®æˆåŠŸã€‚ å¯¹äºgithubï¼Œéœ€è¦é¢å¤–è¿è¡Œssh-keyscan -t rsa github.com &gt;&gt; ~/.ssh/known_hosts æœ¬åœ°å’ŒæœåŠ¡å™¨çš„åŒæ­¥ åœ¨æ’ä»¶æ‰©å±•é‡Œå®‰è£…å¾®è½¯å®˜æ–¹å‘å¸ƒçš„ Remote-SSH ï¼Œå®‰è£…å®Œåå·¦ä¾§ä¼šå¤šä¸€ä¸ªè¿œç¨‹èµ„æºç®¡ç†å™¨çš„å›¾æ ‡ï¼Œå‘ˆç”µè„‘çŠ¶ã€‚ ç‚¹å‡»è¿œç¨‹å›¾æ ‡ï¼Œç‚¹å‡»SSH TARGETSæ—è¾¹çš„é½¿è½®å›¾æ ‡è¿›è¡Œé…ç½®ï¼Œå¼¹å‡ºçš„å¤šè¡Œé…ç½®æ–‡ä»¶é‡Œé€‰æ‹©ç¬¬ä¸€ä¸ªï¼Œç¡®è®¤è¿›è¡Œé…ç½®ã€‚ è¿›è¡Œå¦‚ä¸‹é…ç½®ï¼Œä¿å­˜ï¼Œä¼šåœ¨SSH TARGETSä¸‹é¢å‡ºç°åå­—ä¸ºNameçš„è¿œç¨‹æœºï¼Œä¼šä¸€ç›´å­˜åœ¨äºè¿œç¨‹èµ„æºç®¡ç†å™¨é‡Œï¼Œä»¥ååªéœ€å³é”®è¿æ¥å³å¯ã€‚Host Name HostName 1.1.1.1 # å¡«å†™è¿œç¨‹æœåŠ¡å™¨çš„IPæˆ–è€…Host User username # å¡«å†™ç™»é™†è¿œç¨‹æœåŠ¡å™¨çš„ç”¨æˆ·çš„åå­— Port 22 # å¡«å†™ç«¯å£ï¼Œé»˜è®¤ä¸º22 IdentityFile C:\\\\Users\\\\lenovo\\\\.ssh\\\\id_rsa #å¡«å†™ç§é’¥è·¯å¾„ å³é”®è¿æ¥åˆ°æœåŠ¡å™¨åï¼Œç‚¹å‡»èœå•æ çš„æ–‡ä»¶ï¼Œç‚¹å‡»æ–°å»ºæ–‡ä»¶å¤¹ï¼Œå°±å¯ç›´æ¥é€‰æ‹©æœåŠ¡å™¨ç«¯çš„æ–‡ä»¶å¤¹ï¼Œè€Œåæ–‡ä»¶å¤¹å°±æŒ‚è½½åˆ°äº†å·¦ä¾§ä¸Šè¾¹çš„ç¬¬ä¸€ä¸ªå›¾æ ‡èµ„æºç®¡ç†å™¨ï¼Œåœ¨è¿™é‡Œçš„æ›´æ”¹éƒ½ä¼šå®æ—¶åŒæ­¥å›æœåŠ¡å™¨ã€‚ å¦å¤–ï¼Œåœ¨è¿æ¥åˆ°æœåŠ¡å™¨åï¼Œå¯ä»¥ç‚¹å‡»èœå•æ çš„ç»ˆç«¯å‘¼å‡ºæ–°ç»ˆç«¯ï¼Œå°±å¯ä»¥ç›¸å½“äºxshellã€puttyç›´æ¥åœ¨vscodeä¸Šæ‰§è¡ŒæœåŠ¡å™¨ä¸Šçš„ç»ˆç«¯å‘½ä»¤äº†ã€‚ æœåŠ¡å™¨å’Œgithubçš„åŒæ­¥VSCodeé»˜è®¤æ”¯æŒäº†å¾ˆå¤šgitæ“ä½œï¼Œå°±åœ¨å·¦ä¾§çš„æºä»£ç ç®¡ç†å›¾æ ‡ä¸­ï¼Œå‘ˆåˆ†æ”¯å›¾çŠ¶ã€‚åœ¨é¦–æ¬¡å®‰è£…gitçš„æ—¶å€™ï¼Œéœ€è¦å…ˆè®¾ç½®è‡ªå·±çš„ç”¨æˆ·åå’Œé‚®ç®±ï¼ˆæ³¨å†Œgithubæ—¶çš„ç”¨æˆ·åå’Œé‚®ç®±ï¼‰ã€‚ git config --global user.name &quot;name&quot; git config --global user.email &quot;email@email.com&quot; ä¸€èˆ¬è€Œè¨€ï¼Œæœ¬åœ°å’Œgithubçš„åŒæ­¥æ“ä½œå¦‚ä¸‹ï¼š git init # æŠŠè¿™ä¸ªæ–‡ä»¶å¤¹å˜æˆGitå¯ä»¥ç®¡ç†çš„ä»“åº“ git add . # æŠŠå½“å‰æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æ–‡ä»¶æ·»åŠ åˆ°æš‚å­˜åŒº git add **.py # æŠŠå½“å‰æ–‡ä»¶å¤¹ä¸‹çš„**.pyæ·»åŠ åˆ°æš‚å­˜åŒº git status # å¯é€‰æ“ä½œï¼ŒæŸ¥çœ‹å½“å‰çŠ¶æ€ git commit -m &quot;æ³¨é‡Š&quot; # æŠŠæš‚å­˜åŒºçš„æ–‡ä»¶æäº¤åˆ°æœ¬åœ°ä»“åº“ git checkout master # åˆ‡æ¢åˆ°masteråˆ†æ”¯ git remote add origin https://github.com/name/Project.git # å…³è”githubä»“åº“ï¼Œä¸€ä¸ªé¡¹ç›®åªéœ€å…³è”ä¸€æ¬¡ git push origin main # æŠŠæœ¬åœ°ä»“åº“æ¨å‘è¿œç¨‹GitHubä»“åº“çš„mainåˆ†æ”¯ git pull origin main # æŠŠè¿œç¨‹GitHubä»“åº“çš„mainåˆ†æ”¯æ‹‰å›æœ¬åœ°ä»“åº“ è€Œåœ¨VSCodeä¸­ï¼Œè¿™äº›å‘½ä»¤å¤§å¤šæ•°å¯ä»¥é€šè¿‡æ›´æ–¹ä¾¿çš„æ–¹å¼æ¥æ›¿ä»£ã€‚æˆ‘ä»¬ä¸€æ–¹é¢å¯ä»¥é€šè¿‡è°ƒå‡ºç»ˆç«¯ï¼Œä½¿ç”¨å¦‚ä¸Šå‘½ä»¤æ¥è¿›è¡ŒåŒæ­¥ï¼Œä¹Ÿå¯ä»¥é€šè¿‡ç‚¹å‡»æºä»£ç ç®¡ç†å›¾æ ‡ï¼Œç›´è§‚åœ°å¯¹æ–‡ä»¶å¤¹ä¸­åœ°æ–‡ä»¶è¿›è¡ŒåŒæ­¥æ“ä½œã€‚å…·ä½“æ¥è¯´ï¼š git init å¯ä»¥é€šè¿‡ç‚¹å‡»æºä»£ç ç®¡ç†å›¾æ ‡é‡Œåœ°åˆå§‹åŒ–æŒ‰é’®æ›¿ä»£ã€‚ git add å¯ä»¥é€šè¿‡åœ¨æ–‡ä»¶æ—è¾¹ç‚¹å‡»+å·æ›¿ä»£ã€‚ git commit å¯ä»¥é€šè¿‡æ–‡ä»¶ä¸Šé¢åœ°æ¶ˆæ¯æ¥æ›¿ä»£ã€‚ git remote add é€šè¿‡æŒ‰Ctrl+Shift+Pè°ƒå‡ºå‘½ä»¤è¡Œï¼Œè¾“å…¥git remote addï¼Œå†è¿›ä¸€æ­¥è¾“å…¥https://github.com/name/Project.gitï¼Œå†è¾“å…¥originï¼Œå®Œæˆç»‘å®š git push é€šè¿‡æŒ‰Ctrl+Shift+Pè°ƒå‡ºå‘½ä»¤è¡Œï¼Œè¾“å…¥git push git pull é€šè¿‡æŒ‰Ctrl+Shift+Pè°ƒå‡ºå‘½ä»¤è¡Œï¼Œè¾“å…¥git pull git checkout é€šè¿‡ç‚¹å‡»å·¦ä¸‹è§’åœ°åˆ†æ”¯åå­—æ¥æ›´æ¢ å¦å¤–è¦æ³¨æ„ï¼š ä¸€èˆ¬ä¸Šä¼ æµç¨‹æ˜¯ addã€commitã€pushï¼Œåœ¨è¿™ä¹‹å‰éœ€è¦å…ˆä¸Šå»githubæ–°å»ºé¡¹ç›®ã€‚ åœ¨åŒæ­¥è¿‡ç¨‹ä¸­å¦‚æœé‡åˆ°äº†å’Œgithubç«¯å†²çªçš„é—®é¢˜ï¼Œåˆ™éœ€è¦å…ˆè§£å†³å†²çªï¼Œå†ç»§ç»­ä¸Šä¼ ã€‚ å¯¹äºæœ¬åœ°å’Œgithubçš„åŒæ­¥åˆ™åŸºæœ¬ä¸€æ ·ï¼ŒæœåŠ¡å™¨å¯ä»¥ä½œä¸ºå¦ä¸€ç§å½¢å¼çš„æœ¬åœ°ã€‚ æ€»ç»“ç›®å‰VSCodeçš„ä½¿ç”¨æ„Ÿå—è¿˜ä¸é”™ï¼ŒåŸºæœ¬å¯ä»¥æ›¿ä»£æ‰xshellå’Œwinscpï¼Œå¹¶å¯ä»¥å®ç°å¤šå¹³å°è¾ƒå¥½çš„åŒæ­¥ã€‚åœ¨ä¸githubçš„åŒæ­¥ä¸­ï¼Œéœ€è¦å°å¿ƒè°¨æ…çš„åšå¥½ç‰ˆæœ¬ç®¡ç†ï¼Œä¸è¦è¯¯åˆ æ–‡ä»¶ã€‚ä¸€èˆ¬éœ€è¦æ¯æœ‰ä¸€æ¬¡è¾ƒå¤§æ”¹åŠ¨å°±è¦pushä¸€æ¬¡ï¼Œå¹¶ä¸”è¦å……åˆ†åˆ©ç”¨å¥½branchåˆ†æ”¯åŠŸèƒ½ã€‚","categories":[{"name":"å·¥å…·ä½¿ç”¨","slug":"å·¥å…·ä½¿ç”¨","permalink":"http://weiquanfan.xyz/categories/å·¥å…·ä½¿ç”¨/"}],"tags":[{"name":"å·¥å…·ä½¿ç”¨","slug":"å·¥å…·ä½¿ç”¨","permalink":"http://weiquanfan.xyz/tags/å·¥å…·ä½¿ç”¨/"}]},{"title":"è¯­éŸ³çš„é¢„å¤„ç†--ç«¯ç‚¹æ£€æµ‹","slug":"vad","date":"2021-07-28T15:27:39.000Z","updated":"2021-07-28T15:28:48.796Z","comments":true,"path":"2021/07/28/vad/","link":"","permalink":"http://weiquanfan.xyz/2021/07/28/vad/","excerpt":"","text":"å¼•è¨€è¯­éŸ³çš„å®é™…åº”ç”¨åœºæ™¯ä¸­ï¼Œç»å¸¸æ˜¯ç»™å®šä¸€æ®µåŒ…å«å¤šå¥å¥å­çš„é•¿è¯­éŸ³ï¼Œè¿™å°±äº§ç”Ÿäº†è¯­éŸ³ç«¯ç‚¹æ£€æµ‹çš„éœ€æ±‚ï¼Œä»è€Œå®ç°å¯¹å¥å­çš„åˆ†å‰²ã€‚ç«¯ç‚¹æ£€æµ‹å¯ä»¥æ˜¯åªæ£€æµ‹é•¿è¯­éŸ³çš„å¼€å§‹å’Œç»“æŸï¼Œä¹Ÿå¯ä»¥ç»†åŒ–åˆ°æ¯ä¸€å¥å¥å­çš„å¼€å§‹å’Œç»“æŸï¼Œä»¥ä¸‹ç¤ºä¾‹ä¸ºå¥å­çº§çš„ç«¯ç‚¹æ£€æµ‹ã€‚ æ–¹æ³•1ä½¿ç”¨çŸ­æ—¶èƒ½é‡å’Œè°±è´¨å¿ƒç‰¹å¾è¿›è¡Œç«¯ç‚¹æ£€æµ‹ï¼Œåœ¨matlabä¸Šæœ‰å°è£…å¥½çš„å‡½æ•°ï¼Œä»¥ä¸‹ä¸ºpythonç‰ˆæœ¬ã€‚ #!/usr/bin/python3 # -*- coding: utf-8 -*- # @author: fan weiquan import os import numpy as np import matplotlib.pyplot as plt from scipy.io import wavfile import librosa import scipy.signal def ShortTimeEnergy(signal, windowLength, step): &quot;&quot;&quot; è®¡ç®—çŸ­æ—¶èƒ½é‡ Parameters ---------- signal : åŸå§‹ä¿¡å·. windowLength : å¸§é•¿. step : å¸§ç§». Returns ------- E : æ¯ä¸€å¸§çš„èƒ½é‡. &quot;&quot;&quot; signal = signal / np.max(signal) # å½’ä¸€åŒ– curPos = 0 L = len(signal) numOfFrames = np.asarray(np.floor((L-windowLength)/step) + 1, dtype=int) E = np.zeros((numOfFrames, 1)) for i in range(numOfFrames): window = signal[int(curPos):int(curPos+windowLength-1)]; E[i] = (1/(windowLength)) * np.sum(np.abs(window**2)); curPos = curPos + step; return E def SpectralCentroid(signal,windowLength, step, fs): &quot;&quot;&quot; è®¡ç®—è°±è´¨å¿ƒ Parameters ---------- signal : åŸå§‹ä¿¡å·. windowLength : å¸§é•¿. step : å¸§ç§». fs : é‡‡æ ·ç‡. Returns ------- C : æ¯ä¸€å¸§çš„è°±è´¨å¿ƒ. &quot;&quot;&quot; signal = signal / np.max(signal) # å½’ä¸€åŒ– curPos = 0 L = len(signal) numOfFrames = np.asarray(np.floor((L - windowLength) / step) + 1, dtype=int) H = np.hamming(windowLength) m = ((fs / (2 * windowLength)) * np.arange(1, windowLength, 1)).T C = np.zeros((numOfFrames, 1)) for i in range(numOfFrames): window = H * (signal[int(curPos) : int(curPos + windowLength)]) FFT = np.abs(np.fft.fft(window, 2 * int(windowLength))) FFT = FFT[1 : windowLength] FFT = FFT / np.max(FFT) C[i] = np.sum(m * FFT) / np.sum(FFT) if np.sum(window**2) &lt; 0.010: C[i] = 0.0 curPos = curPos + step; C = C / (fs/2) return C def findMaxima(f, step): &quot;&quot;&quot; å¯»æ‰¾å±€éƒ¨æœ€å¤§å€¼ Parameters ---------- f : è¾“å…¥åºåˆ—. step : æœå¯»çª—é•¿. Returns ------- Maxima : æœ€å¤§å€¼ç´¢å¼• æœ€å¤§å€¼ countMaxima : æœ€å¤§å€¼çš„æ•°é‡ &quot;&quot;&quot; ## STEP 1: å¯»æ‰¾æœ€å¤§å€¼ countMaxima = 0 Maxima = [] for i in range(len(f) - step - 1): # å¯¹äºåºåˆ—ä¸­çš„æ¯ä¸€ä¸ªå…ƒç´ : if i &gt;= step: if (np.mean(f[i - step : i]) &lt; f[i]) and (np.mean(f[i + 1 : i + step + 1]) &lt; f[i]): # IF the current element is larger than its neighbors (2*step window) # --&gt; keep maximum: countMaxima = countMaxima + 1 Maxima.append([i, f[i]]) else: if (np.mean(f[0 : i + 1]) &lt;= f[i]) and (np.mean(f[i + 1 : i + step + 1]) &lt; f[i]): # IF the current element is larger than its neighbors (2*step window) # --&gt; keep maximum: countMaxima = countMaxima + 1 Maxima.append([i, f[i]]) ## STEP 2: å¯¹æœ€å¤§å€¼è¿›è¡Œè¿›ä¸€æ­¥å¤„ç† MaximaNew = [] countNewMaxima = 0 i = 0 while i &lt; countMaxima: # get current maximum: curMaxima = Maxima[i][0] curMavVal = Maxima[i][1] tempMax = [Maxima[i][0]] tempVals = [Maxima[i][1]] i = i + 1 # search for &quot;neighbourh maxima&quot;: while (i &lt; countMaxima) and (Maxima[i][0] - tempMax[len(tempMax) - 1] &lt; step / 2): tempMax.append(Maxima[i][0]) tempVals.append(Maxima[i][1]) i = i + 1 MM = np.max(tempVals) MI = np.argmax(tempVals) if MM &gt; 0.02 * np.mean(f): # if the current maximum is &quot;large&quot; enough: # keep the maximum of all maxima in the region: MaximaNew.append([tempMax[MI], f[tempMax[MI]]]) countNewMaxima = countNewMaxima + 1 # add maxima Maxima = MaximaNew countMaxima = countNewMaxima return Maxima, countMaxima def VAD(signal, fs): win = 0.05 step = 0.05 Eor = ShortTimeEnergy(signal, int(win * fs), int(step * fs)); Cor = SpectralCentroid(signal, int(win * fs), int(step * fs), fs); E = scipy.signal.medfilt(Eor[:, 0], 5) E = scipy.signal.medfilt(E, 5) C = scipy.signal.medfilt(Cor[:, 0], 5) C = scipy.signal.medfilt(C, 5) E_mean = np.mean(E); Z_mean = np.mean(C); Weight = 100 # é˜ˆå€¼ä¼°è®¡çš„å‚æ•° # å¯»æ‰¾çŸ­æ—¶èƒ½é‡çš„é˜ˆå€¼ Hist = np.histogram(E, bins=10) # è®¡ç®—ç›´æ–¹å›¾ HistE = Hist[0] X_E = Hist[1] MaximaE, countMaximaE = findMaxima(HistE, 3) # å¯»æ‰¾ç›´æ–¹å›¾çš„å±€éƒ¨æœ€å¤§å€¼ if len(MaximaE) &gt;= 2: # å¦‚æœæ‰¾åˆ°äº†ä¸¤ä¸ªä»¥ä¸Šå±€éƒ¨æœ€å¤§å€¼ T_E = (Weight*X_E[MaximaE[0][0]] + X_E[MaximaE[1][0]]) / (Weight + 1) else: T_E = E_mean / 2 # å¯»æ‰¾è°±è´¨å¿ƒçš„é˜ˆå€¼ Hist = np.histogram(C, bins=10) HistC = Hist[0] X_C = Hist[1] MaximaC, countMaximaC = findMaxima(HistC, 3) if len(MaximaC)&gt;=2: T_C = (Weight*X_C[MaximaC[0][0]]+X_C[MaximaC[1][0]]) / (Weight+1) else: T_C = Z_mean / 2 # é˜ˆå€¼åˆ¤æ–­ Flags1 = (E&gt;=T_E) Flags2 = (C&gt;=T_C) flags = np.array(Flags1 &amp; Flags2, dtype=int) ## æå–è¯­éŸ³ç‰‡æ®µ count = 1 segments = [] while count &lt; len(flags): # å½“è¿˜æœ‰æœªå¤„ç†çš„å¸§æ—¶ # åˆå§‹åŒ– curX = [] countTemp = 1 while ((flags[count - 1] == 1) and (count &lt; len(flags))): if countTemp == 1: # å¦‚æœæ˜¯è¯¥è¯­éŸ³æ®µçš„ç¬¬ä¸€å¸§ Limit1 = np.round((count-1)*step*fs)+1 # è®¾ç½®è¯¥è¯­éŸ³æ®µçš„å¼€å§‹è¾¹ç•Œ if Limit1 &lt; 1: Limit1 = 1 count = count + 1 # è®¡æ•°å™¨åŠ ä¸€ countTemp = countTemp + 1 # å½“å‰è¯­éŸ³æ®µçš„è®¡æ•°å™¨åŠ ä¸€ if countTemp &gt; 1: # å¦‚æœå½“å‰å¾ªç¯ä¸­æœ‰è¯­éŸ³æ®µ Limit2 = np.round((count - 1) * step * fs) # è®¾ç½®è¯¥è¯­éŸ³æ®µçš„ç»“æŸè¾¹ç•Œ if Limit2 &gt; len(signal): Limit2 = len(signal) # å°†è¯¥è¯­éŸ³æ®µçš„é¦–å°¾ä½ç½®åŠ å…¥åˆ°segmentsçš„æœ€åä¸€è¡Œ segments.append([int(Limit1), int(Limit2)]) count = count + 1 # åˆå¹¶è¯­éŸ³æ®µ i = 0 while i &lt; len(segments)-1: # for i in range(len(segments) - 1): # å¯¹æ¯ä¸€ä¸ªè¯­éŸ³æ®µè¿›è¡Œå¤„ç† if segments[i][1] &gt;= segments[i + 1][0] - fs//2: segments[i][1] = segments[i + 1][1] # segments[i + 1, :] = [] del segments[i+1] i -= 1 i += 1 # åˆ é™¤è¯­éŸ³æ®µ i = 0 while i &lt; len(segments): if segments[i][1] - segments[i][0] &lt; fs//2: del segments[i] i += 1 # seg_tuple = () # for i in range(len(segments)): seg_tuple+=tuple(segments[i][:]) return segments if __name__ == &quot;__main__&quot;: path_audio = &#39;test.wav&#39; signal, fs = librosa.load(path_audio, mono=True) segments = VAD(signal, fs) # ç«¯ç‚¹æ£€æµ‹ print(segments) # for i, seg in enumerate(segments): # wavfile.write(str(i)+&#39;.wav&#39;, fs, signal[seg[0]:seg[1]]) æ–¹æ³•2åŸºäºwebrtcvadçš„ç«¯ç‚¹æ£€æµ‹ï¼Œé€å¸§åˆ¤æ–­æ˜¯å¦æ˜¯å¦é™éŸ³ï¼Œå¹¶é€šè¿‡å¹³æ»‘æ‰©å¼ ç­‰æ“ä½œè¿›ä¸€æ­¥è°ƒæ•´ç«¯ç‚¹ã€‚ from scipy.ndimage.morphology import binary_dilation import librosa import numpy as np import struct import webrtcvad import soundfile as sf # ** açš„bæ¬¡æ–¹ 32767 int16_max = (2 ** 15) - 1 #è¾“å…¥ wav, sr = librosa.load(&quot;test.wav&quot;, sr=None) # è®¡ç®—è¯­éŸ³æ£€æµ‹çª—å£å¤§å° #ä¸ºæ•´é™¤ 30ç§’X16000=æ€»å¸§é•¿ samples_per_window = (30 * 16000) // 1000 # ä¿®å‰ªéŸ³é¢‘çš„ç»“å°¾ï¼Œä½¿å…¶å…·æœ‰çª—å£å¤§å°çš„å€æ•°ã€‚ä½¿wavçš„é•¿åº¦èƒ½è¢« samples_per_windowæ•´é™¤ wav = wav[:len(wav) - (len(wav) % samples_per_window)] # æµ®ç‚¹æ•°æ³¢å½¢è½¬æ¢ä¸º16ä½å•å£°é“PCM *ï¼šæ¥æ”¶åˆ°çš„å‚æ•°ä¼šå½¢æˆä¸€ä¸ªå…ƒç»„ï¼Œ**ï¼šæ¥æ”¶åˆ°çš„å‚æ•°ä¼šå½¢æˆä¸€ä¸ªå­—å…¸ã€‚å¦‚ä¸‹ä»£ç ã€‚ # webrtcvad çš„ is_speech æ¥æ”¶çš„æ˜¯buf æ‰€ä»¥è¿™é‡Œéœ€è¦è½¬æ¢ pcm_wave = struct.pack(&quot;%dh&quot; % len(wav), *(np.round(wav * int16_max)).astype(np.int16)) # æ‰§è¡Œè¯­éŸ³æ¿€æ´»æ£€æµ‹ # timestamps = [] # flag = False voice_flags = [] # è¿™é‡Œå…±æœ‰ä¸‰ç§å¸§é•¿å¯ä»¥ç”¨åˆ°ï¼Œåˆ†åˆ«æ˜¯80/10msï¼Œ160/20msï¼Œ240/30msã€‚å…¶å®ƒé‡‡æ ·ç‡ # çš„48kï¼Œ32kï¼Œ24kï¼Œ16kä¼šé‡é‡‡æ ·åˆ°8kæ¥è®¡ç®—VADã€‚ä¹‹æ‰€ä»¥é€‰æ‹©ä¸Šè¿°ä¸‰ç§å¸§é•¿åº¦ï¼Œæ˜¯å› ä¸ºè¯­ # éŸ³ä¿¡å·æ˜¯çŸ­æ—¶å¹³ç¨³ä¿¡å·ï¼Œå…¶åœ¨10ms~30msä¹‹é—´å¯çœ‹æˆå¹³ç¨³ä¿¡å·ï¼Œé«˜æ–¯é©¬å°”ç§‘å¤«ç­‰æ¯”è¾ƒ # çš„ä¿¡å·å¤„ç†æ–¹æ³•åŸºäºçš„å‰ææ˜¯ä¿¡å·æ˜¯å¹³ç¨³çš„ï¼Œåœ¨10ms~30msï¼Œå¹³ç¨³ä¿¡å·å¤„ç†æ–¹æ³•æ˜¯å¯ # ä»¥ä½¿ç”¨çš„ã€‚ # ä»vadçš„ä»£ç ä¸­å¯ä»¥çœ‹å‡ºï¼Œå®é™…ä¸Šï¼Œç³»ç»Ÿåªå¤„ç†é»˜è®¤10ms,20ms,30msé•¿åº¦çš„æ•°æ®ï¼Œ # å…¶å®ƒé•¿åº¦çš„æ•°æ®æ²¡æœ‰æ”¯æŒï¼Œç¬”è€…ä¿®æ”¹è¿‡å¯ä»¥æ”¯æŒå…¶å®ƒåœ¨10ms-30msä¹‹é—´é•¿åº¦çš„å¸§é•¿åº¦ # å‘ç°ä¹Ÿæ˜¯å¯ä»¥çš„ã€‚ # vadæ£€æµ‹å…±å››ç§æ¨¡å¼ï¼Œç”¨æ•°å­—0~3æ¥åŒºåˆ†ï¼Œæ¿€è¿›ç¨‹åº¦ä¸æ•°å€¼å¤§å°æ­£ç›¸å…³ã€‚ # 0: Normalï¼Œ1ï¼šlow Bitrateï¼Œ 2ï¼šAggressiveï¼›3ï¼šVery Aggressive å¯ä»¥æ ¹æ®å®é™…çš„ä½¿ç”¨ vad = webrtcvad.Vad(mode=0) for window_start in range(0, len(wav), samples_per_window): window_end = window_start + samples_per_window # append è¿›æ¥çš„éƒ½æ˜¯Boolean è¿™é‡Œä»¥samples_per_windowx2 çš„é•¿åº¦å»æ£€æµ‹æ˜¯å¦ä¸ºäººå£° isspeech_bool = vad.is_speech(pcm_wave[window_start * 2:window_end * 2], sample_rate=16000) voice_flags.append(isspeech_bool) # if flag ^ isspeech_bool: # timestamps.append(window_start) # flag = isspeech_bool # for i in range(0, len(timestamps), 2): # tmp = wav[timestamps[i]:timestamps[i+1]] # sf.write(str(i)+&quot;.wav&quot;, tmp.astype(np.float32), sr, subtype=&#39;PCM_24&#39;) voice_flags = np.array(voice_flags) # ğ‘£_ğ‘ğ‘–ğ‘ğ‘ ğ‘’ğ‘‘ğ‘¡=ğ‘£ğ‘¡/(1âˆ’ğ›½ğ‘¡) # æ»‘åŠ¨å¹³å‡è®¡ç®— def moving_average(array, width): # æ‹¼æ¥ bool äºŒå€¼åŒ– # width æ‰§è¡Œæ»‘åŠ¨å¹³å‡å¹³æ»‘æ—¶ï¼Œå¸§çš„å¹³å‡æ•°ã€‚ # è¯¥å€¼è¶Šå¤§ï¼ŒVADå˜åŒ–å¿…é¡»è¶Šå¤§æ‰èƒ½å¹³æ»‘ã€‚ array_padded = np.concatenate((np.zeros((width - 1) // 2), array, np.zeros(width // 2))) # ä¸€ç»´æ•°ç»„ç´¯åŠ  ret = np.cumsum(array_padded, dtype=float) ret[width:] = ret[width:] - ret[:-width] return ret[width - 1:] / width #æ»‘åŠ¨å¹³å‡è®¡ç®— audio_mask = moving_average(voice_flags, 8) #å°†å¹³å‡æ•°å››èˆäº”å…¥ è½¬bool audio_mask = np.round(audio_mask).astype(np.bool) # æ‰©å¼ æµŠéŸ³åŒº ä½¿ç”¨å¤šç»´äºŒå…ƒè†¨èƒ€ æ˜¯æ•°å­¦å½¢æ€å­¦çš„æ–¹æ³• ç±»ä¼¼opencv ä¹Ÿæœ‰å¼€é—­è¿ç®— è…èš€è†¨èƒ€ audio_mask = binary_dilation(audio_mask, np.ones(6 + 1)) #ä½¿å…¶ä¸wavä¸€æ ·å¤§å° audio_mask = np.repeat(audio_mask, samples_per_window) timestamps = [] flag = False for i, t in enumerate(audio_mask): if flag ^ t: timestamps.append(i) flag = t for i in range(0, len(timestamps)-1, 2): res = wav[timestamps[i]:timestamps[i+1]] sf.write(str(i)+&quot;.wav&quot;, res.astype(np.float32), sr, subtype=&#39;PCM_24&#39;) # #é€šè¿‡è¿™ä¸ªé®ç½©æ‰£æ‰æ²¡æœ‰å£°éŸ³é‚£éƒ¨åˆ† # res=wav[audio_mask == True] # sf.write(&quot;out.wav&quot;, res.astype(np.float32), sr, subtype=&#39;PCM_24&#39;) æ€»ç»“ç«¯ç‚¹æ£€æµ‹æ–¹æ³•éå¸¸å¤šï¼Œé™¤è¿™ä¹‹å¤–è¿˜æœ‰æ¯”è¾ƒç»å…¸çš„åŒé—¨é™æ³•ã€‚å®é™…æµ‹è¯•ä¸­ï¼Œè¿™äº›æ–¹æ³•åœ¨å¹²å‡€çš„è¯­éŸ³ä¸­æ•ˆæœéå¸¸å¥½ï¼Œåœ¨ç°å®å¸¦å™ªåœºæ™¯ä¸­ï¼Œå¯èƒ½å®¹æ˜“å‡ºç°è¯¯åˆ†æˆå¾ˆå¤šå­æ®µçš„ç°è±¡ï¼Œä¸ºæ­¤ï¼Œå¯ä»¥é€šè¿‡å¢åŠ æ—¶é—´è§„åˆ™ï¼Œå¯¹åˆ†å‰²åçš„æ—¶é—´æ®µå’Œä¸Šä¸‹æ®µçš„è¿æ¥æ®µåˆ¤æ–­æ˜¯å¦åˆç†ï¼Œæ¥ç²¾ç®€æ£€æµ‹ç»“æœã€‚ å‚è€ƒhttps://blog.csdn.net/qq_42688495/article/details/109333598https://blog.csdn.net/weixin_43928944/article/details/108378413","categories":[{"name":"è¯­éŸ³é¢„å¤„ç†","slug":"è¯­éŸ³é¢„å¤„ç†","permalink":"http://weiquanfan.xyz/categories/è¯­éŸ³é¢„å¤„ç†/"}],"tags":[{"name":"è¯­éŸ³é¢„å¤„ç†","slug":"è¯­éŸ³é¢„å¤„ç†","permalink":"http://weiquanfan.xyz/tags/è¯­éŸ³é¢„å¤„ç†/"}]},{"title":"è¯­éŸ³çš„é¢„å¤„ç†--å»å™ª","slug":"denose","date":"2021-07-27T15:50:34.000Z","updated":"2021-07-28T15:20:40.577Z","comments":true,"path":"2021/07/27/denose/","link":"","permalink":"http://weiquanfan.xyz/2021/07/27/denose/","excerpt":"","text":"å¼•è¨€åœ¨äººå·¥æ™ºèƒ½ä¸­ï¼Œç®—æ³•å›ºç„¶å¾ˆé‡è¦ï¼Œä½†è¯­éŸ³çš„é¢„å¤„ç†å´ç›´æ¥åœ°å†³å®šäº†ç®—æ³•çš„æ€§èƒ½ä¸Šé™ï¼Œå› æ­¤æœ‰å¿…è¦å¯¹è¯­éŸ³è¿›è¡Œå»å™ªå¤„ç†ã€‚ æ–¹æ³•1é€šè¿‡æˆªå–éŸ³é¢‘ä¸­çš„å·²çŸ¥å™ªéŸ³éƒ¨åˆ†ï¼Œæ ¹æ®è¯¥å™ªéŸ³æ ·æœ¬å¯¹æ•´ä¸ªéŸ³é¢‘è¿›è¡Œé™å™ªã€‚æˆªå–å™ªéŸ³ä½¿ç”¨ffmpegï¼Œé™å™ªä½¿ç”¨soxã€‚ 1. å°†éŸ³é¢‘æµå’Œè§†é¢‘æµæ‹†åˆ†ä¸º2ä¸ªä¸åŒçš„æ–‡ä»¶: è§†é¢‘: ffmpeg -i input.mp4 -vcodec copy -an tmpvid.mp4 éŸ³é¢‘: ffmpeg -i input.mp4 -acodec pcm_s16le -ar 128k -vn tmpaud.wav 2. ä»ä¸Šä¸€æ­¥çš„éŸ³é¢‘ç»“æœæ–‡ä»¶ä¸­å‰ªåˆ‡ä¸€ä¸ªå™ªå£°æ ·æœ¬: ffmpeg -i itmpaud.wav -ss 00:00:00.0 -t 00:00:00.5 noiseaud.wav -ss: ä»å¼€å§‹çš„æ—¶é—´åç§». (h: m: s.ms). -t duration: è¡¨ç¤ºè¦å‰ªåˆ‡çš„éŸ³é¢‘æ®µçš„æŒç»­æ—¶é—´ï¼ˆh: m: s.msï¼‰ï¼Œä»¥ä¾¿ä¸‹ä¸€æ­¥ç”¨æ¥ä½œä¸ºå™ªå£°æ–‡ä»¶ã€‚ é€‰æ‹©ä¸€æ®µæ²¡æœ‰è¯­éŸ³ã€åªæœ‰å™ªéŸ³çš„éŸ³é¢‘ï¼ˆä¾‹å¦‚ï¼Œè®²è¯è€…é™éŸ³æ—¶çš„é‚£ä¸€ç§’é’Ÿï¼‰ã€‚ 3. ä½¿ç”¨soxç”Ÿæˆå™ªéŸ³profile: sox noiseaud.wav -n noiseprof noise.prof 4. æ¸…é™¤éŸ³é¢‘æµä¸­çš„å™ªå£°æ ·æœ¬ï¼š sox tmpaud.wav tmpaud-clean.wav noisered noise.prof 0.21 æ›´æ”¹0.21ä»¥è°ƒæ•´é‡‡æ ·ç‡çš„çµæ•åº¦çº§åˆ«ï¼ˆ0.2-0.3é€šå¸¸æä¾›æœ€ä½³ç»“æœï¼‰ã€‚ 5. ä½¿ç”¨ffmpegå°†æ–°çš„éŸ³é¢‘å’Œè§†é¢‘æµåˆå¹¶åˆ°ä¸€èµ·: ffmpeg -i tmpvid.mp4 -i tmpaud-clean.wav -map 0:v -map 1:a -c:v copy -c:a aac -b:a 128k out.mp4 å¦‚æœåªæ˜¯è¦ç®€å•çš„å®ç°è¯­éŸ³å»å™ªï¼Œé‚£ä¹ˆç›´æ¥è¿›è¡Œ3ã€4æ­¥çš„æ“ä½œï¼Œå°†æ•´æ®µå™ªå£°è¯­éŸ³ä½œä¸ºå™ªå£°æ–‡ä»¶ä¹Ÿå¯ã€‚ sox tmpaud.wav -n noiseprof noise.prof sox tmpaud.wav tmpaud-clean.wav noisered noise.prof 0.21 æ–¹æ³•2è°±å‡æ³•ï¼šè°±å‡ç®—æ³•ä¸ºæœ€æ—©çš„è¯­éŸ³é™å™ªç®—æ³•ä¹‹ä¸€ï¼Œå®ƒçš„æå‡ºï¼ŒåŸºäºä¸€ä¸ªç®€å•çš„åŸç†ï¼šå‡è®¾è¯­éŸ³ä¸­çš„å™ªå£°åªæœ‰åŠ æ€§å™ªå£°ï¼Œåªè¦å°†å¸¦å™ªè¯­éŸ³è°±å‡å»å™ªå£°è°±ï¼Œå°±å¯ä»¥å¾—åˆ°çº¯å‡€è¯­éŸ³å¹…åº¦ã€‚è¿™ä¹ˆåšçš„å‰ææ˜¯å™ªå£°ä¿¡å·æ˜¯å¹³ç¨³çš„æˆ–è€…ç¼“æ…¢å˜åŒ–çš„ã€‚ #!/usr/bin/env python import numpy as np import wave import math import ctypes as ct class FloatBits(ct.Structure): _fields_ = [ (&#39;M&#39;, ct.c_uint, 23), (&#39;E&#39;, ct.c_uint, 8), (&#39;S&#39;, ct.c_uint, 1) ] class Float(ct.Union): _anonymous_ = (&#39;bits&#39;,) _fields_ = [ (&#39;value&#39;, ct.c_float), (&#39;bits&#39;, FloatBits) ] def nextpow2(x): if x &lt; 0: x = -x if x == 0: return 0 d = Float() d.value = x if d.M == 0: return d.E - 127 return d.E - 127 + 1 # æ‰“å¼€WAVæ–‡æ¡£ f = wave.open(&quot;input.wav&quot;) # è¯»å–æ ¼å¼ä¿¡æ¯ # (nchannels, sampwidth, framerate, nframes, comptype, compname) params = f.getparams() nchannels, sampwidth, framerate, nframes = params[:4] fs = framerate # è¯»å–æ³¢å½¢æ•°æ® str_data = f.readframes(nframes) f.close() # å°†æ³¢å½¢æ•°æ®è½¬æ¢ä¸ºæ•°ç»„ x = np.fromstring(str_data, dtype=np.short) # è®¡ç®—å‚æ•° len_ = 20 * fs // 1000 # æ ·æœ¬ä¸­å¸§çš„å¤§å° PERC = 50 # çª—å£é‡å å å¸§çš„ç™¾åˆ†æ¯” len1 = len_ * PERC // 100 # é‡å çª—å£ len2 = len_ - len1 # éé‡å çª—å£ # è®¾ç½®é»˜è®¤å‚æ•° Thres = 3 Expnt = 2.0 beta = 0.002 G = 0.9 # åˆå§‹åŒ–æ±‰æ˜çª— win = np.hamming(len_) # normalization gain for overlap+add with 50% overlap winGain = len2 / sum(win) # Noise magnitude calculations - assuming that the first 5 frames is noise/silence nFFT = 2 * 2 ** (nextpow2(len_)) noise_mean = np.zeros(nFFT) j = 0 for k in range(1, 6): noise_mean = noise_mean + abs(np.fft.fft(win * x[j:j + len_], nFFT)) j = j + len_ noise_mu = noise_mean / 5 # --- allocate memory and initialize various variables k = 1 img = 1j x_old = np.zeros(len1) Nframes = len(x) // len2 - 1 xfinal = np.zeros(Nframes * len2) # ========================= Start Processing =============================== for n in range(0, Nframes): # Windowing insign = win * x[k-1:k + len_ - 1] # compute fourier transform of a frame spec = np.fft.fft(insign, nFFT) # compute the magnitude sig = abs(spec) # save the noisy phase information theta = np.angle(spec) SNRseg = 10 * np.log10(np.linalg.norm(sig, 2) ** 2 / np.linalg.norm(noise_mu, 2) ** 2) def berouti(SNR): if -5.0 &lt;= SNR &lt;= 20.0: a = 4 - SNR * 3 / 20 else: if SNR &lt; -5.0: a = 5 if SNR &gt; 20: a = 1 return a def berouti1(SNR): if -5.0 &lt;= SNR &lt;= 20.0: a = 3 - SNR * 2 / 20 else: if SNR &lt; -5.0: a = 4 if SNR &gt; 20: a = 1 return a if Expnt == 1.0: # å¹…åº¦è°± alpha = berouti1(SNRseg) else: # åŠŸç‡è°± alpha = berouti(SNRseg) ############# sub_speech = sig ** Expnt - alpha * noise_mu ** Expnt; # å½“çº¯å‡€ä¿¡å·å°äºå™ªå£°ä¿¡å·çš„åŠŸç‡æ—¶ diffw = sub_speech - beta * noise_mu ** Expnt # beta negative components def find_index(x_list): index_list = [] for i in range(len(x_list)): if x_list[i] &lt; 0: index_list.append(i) return index_list z = find_index(diffw) if len(z) &gt; 0: # ç”¨ä¼°è®¡å‡ºæ¥çš„å™ªå£°ä¿¡å·è¡¨ç¤ºä¸‹é™å€¼ sub_speech[z] = beta * noise_mu[z] ** Expnt # --- implement a simple VAD detector -------------- if SNRseg &lt; Thres: # Update noise spectrum noise_temp = G * noise_mu ** Expnt + (1 - G) * sig ** Expnt # å¹³æ»‘å¤„ç†å™ªå£°åŠŸç‡è°± noise_mu = noise_temp ** (1 / Expnt) # æ–°çš„å™ªå£°å¹…åº¦è°± # flipudå‡½æ•°å®ç°çŸ©é˜µçš„ä¸Šä¸‹ç¿»è½¬ï¼Œæ˜¯ä»¥çŸ©é˜µçš„â€œæ°´å¹³ä¸­çº¿â€ä¸ºå¯¹ç§°è½´ # äº¤æ¢ä¸Šä¸‹å¯¹ç§°å…ƒç´  sub_speech[nFFT // 2 + 1:nFFT] = np.flipud(sub_speech[1:nFFT // 2]) x_phase = (sub_speech ** (1 / Expnt)) * (np.array([math.cos(x) for x in theta]) + img * (np.array([math.sin(x) for x in theta]))) # take the IFFT xi = np.fft.ifft(x_phase).real # --- Overlap and add --------------- xfinal[k-1:k + len2 - 1] = x_old + xi[0:len1] x_old = xi[0 + len1:len_] k = k + len2 # ä¿å­˜æ–‡ä»¶ wf = wave.open(&#39;output.wav&#39;, &#39;wb&#39;) # è®¾ç½®å‚æ•° wf.setparams(params) # è®¾ç½®æ³¢å½¢æ–‡ä»¶ .tostring()å°†arrayè½¬æ¢ä¸ºdata wave_data = (winGain * xfinal).astype(np.short) wf.writeframes(wave_data.tostring()) wf.close() æ€»ç»“ä¸ªäººæ„Ÿè§‰è°±å‡æ³•æ›´åŠ è€—æ—¶ï¼Œä¸”é€‚ç”¨åœºæ™¯ç›¸å¯¹æœ‰é™ã€‚åˆ©ç”¨soxæ¥å»å™ªå¯èƒ½æ˜¯ä¸€ç§ç›¸å¯¹æ›´æˆç†Ÿçš„æ–¹æ³•ã€‚ å‚è€ƒhttp://www.zoharbabin.com/how-to-do-noise-reduction-using-ffmpeg-and-sox/https://github.com/itaa/soja-box/tree/master/enhance_speach","categories":[{"name":"è¯­éŸ³é¢„å¤„ç†","slug":"è¯­éŸ³é¢„å¤„ç†","permalink":"http://weiquanfan.xyz/categories/è¯­éŸ³é¢„å¤„ç†/"}],"tags":[{"name":"è¯­éŸ³é¢„å¤„ç†","slug":"è¯­éŸ³é¢„å¤„ç†","permalink":"http://weiquanfan.xyz/tags/è¯­éŸ³é¢„å¤„ç†/"}]},{"title":"kaldiçš„å®‰è£…å’Œä½¿ç”¨æ¡ˆä¾‹(librispeech)","slug":"kaldi-librispeech","date":"2021-04-22T14:21:43.000Z","updated":"2021-04-22T15:53:33.865Z","comments":true,"path":"2021/04/22/kaldi-librispeech/","link":"","permalink":"http://weiquanfan.xyz/2021/04/22/kaldi-librispeech/","excerpt":"","text":"1. kaldiçš„å®‰è£…æŒ‰ç…§å®˜ç½‘æ•™ç¨‹ï¼Œkaldiçš„å®‰è£…é¦–å…ˆé€šè¿‡gitè·å–é¡¹ç›®ï¼Œå†è¿›è¡Œç¼–è¯‘ã€‚ git clone https://github.com/kaldi-asr/kaldi.git cd kaldi/tools/; make; cd ../src; ./configure; make å¦‚æœæŠ¥é”™ï¼Œåˆ™å¯èƒ½æ˜¯ç›¸å…³çš„ä¾èµ–é¡¹æ²¡æœ‰å®‰è£…ï¼Œå¯æŒ‰ç…§æç¤ºä¸€æ­¥æ­¥å®‰è£…(éœ€è¦rootæƒé™)ã€‚ sudo apt-get install zlib1g-dev automake autoconf sox subversion sudo bash extras/install_mkl.sh 2. kaldiçš„ä½¿ç”¨2.1 librispeechçš„ASRæ¨¡å‹è®­ç»ƒegsç›®å½•ä¸‹æ”¾ç€å„ä¸ªæ•°æ®åº“çš„æ ·ä¾‹ä»£ç ï¼Œä¸€ä¸ªæ–‡ä»¶å¤¹å°±æ˜¯ä¸€ä¸ªæ•°æ®åº“ï¼Œéå¸¸å…¨é¢ã€‚è¿›å…¥egs/librispeech/s5/.æ¯ä¸ªä»£ç é‡Œè¾¹éƒ½ä¼šæœ‰ä¸€ä»½cmd.sh(å¼•å…¥å•æœºå¤šå¡run.plæˆ–è€…å¤šæœºå¤šå¡quene.plæ¨¡å¼), path.sh(å¼•å…¥å„ç§kaldiçš„è·¯å¾„), run.sh(è®­ç»ƒåŠæµ‹è¯•çš„æ•´ä¸ªä¸»æµç¨‹)ã€‚ä»¥ä¸‹ä¸»è¦ç»†çœ‹run.shï¼Œæ•´ä½“æµç¨‹ä¸º å¯¼å…¥å‚æ•°-&gt;ä¸‹è½½éƒ¨åˆ†æ•°æ®å¹¶é¢„å¤„ç†-&gt;å‡†å¤‡å¹¶åˆ›å»ºè¯­è¨€æ¨¡å‹-&gt;æå–ç‰¹å¾-&gt;è®­ç»ƒéƒ¨åˆ†æ•°æ®é›†-&gt;è®­ç»ƒå•å› ç´ ã€ä¸‰éŸ³ç´ æ¨¡å‹å¹¶å˜æ¢è®­ç»ƒ-&gt;åŠ å…¥æ›´å¤šæ•°æ®é›†-&gt;å˜æ¢è®­ç»ƒ-&gt;åŠ å…¥å…¨éƒ¨æ•°æ®é›†-&gt;å˜æ¢è®­ç»ƒ-&gt;è§£ç -&gt;è®­ç»ƒtdnnæ¨¡å‹ã€‚å…·ä½“å¦‚ä¸‹ï¼š #!/usr/bin/env bash ## å¯¼å…¥å‚æ•° data=/home/fwq/Project/kaldi/kaldi/data data_url=www.openslr.org/resources/12 lm_url=www.openslr.org/resources/11 mfccdir=mfcc stage=1 . ./cmd.sh . ./path.sh . parse_options.sh set -e ## ä¸‹è½½æ•°æ® if [ $stage -le 1 ]; then for part in dev-clean test-clean dev-other test-other train-clean-100; do local/download_and_untar.sh $data $data_url $part done local/download_lm.sh $lm_url data/local/lm fi ## ç”Ÿæˆå„ç§æ•°æ®çš„å„ç§æ–‡ä»¶ï¼Œå¦‚wav.scpï¼Œtextï¼Œutt2spkï¼Œspk2genderï¼Œutt2dur if [ $stage -le 2 ]; then for part in dev-clean test-clean dev-other test-other train-clean-100; do local/data_prep.sh $data/LibriSpeech/$part data/$(echo $part | sed s/-/_/g) done fi ## å‡†å¤‡è¯­è¨€æ¨¡å‹ï¼Œå‡†å¤‡å­—å…¸(local/prepare_dict_sh)ï¼Œå‡†å¤‡è¯­è¨€ç›¸å…³æ•°æ®(utils/prepare_lang.sh)ï¼Œæ ¼å¼åŒ–æ•°æ®(local/format_lms.sh) if [ $stage -le 3 ]; then local/prepare_dict.sh --stage 3 --nj 30 --cmd &quot;$train_cmd&quot; \\ data/local/lm data/local/lm data/local/dict_nosp utils/prepare_lang.sh data/local/dict_nosp \\ &quot;&lt;UNK&gt;&quot; data/local/lang_tmp_nosp data/lang_nosp local/format_lms.sh --src-dir data/lang_nosp data/local/lm fi ## ç”¨3-gramå’Œ4-gramè¯­è¨€æ¨¡å‹åˆ›å»ºConstArpaLmæ ¼å¼è¯­è¨€æ¨¡å‹ if [ $stage -le 4 ]; then utils/build_const_arpa_lm.sh data/local/lm/lm_tglarge.arpa.gz \\ data/lang_nosp data/lang_nosp_test_tglarge utils/build_const_arpa_lm.sh data/local/lm/lm_fglarge.arpa.gz \\ data/lang_nosp data/lang_nosp_test_fglarge fi ## æ•°æ®ç‰¹å¾æå–ï¼Œæå–mfccï¼Œè®¡ç®—æ¯æ¡wavæ–‡ä»¶çš„å‡å€¼æ–¹å·® if [ $stage -le 5 ]; then if [[ $(hostname -f) == *.clsp.jhu.edu ]]; then utils/create_split_dir.pl /export/b{02,11,12,13}/$USER/kaldi-data/egs/librispeech/s5/$mfcc/storage \\ $mfccdir/storage fi fi if [ $stage -le 6 ]; then for part in dev_clean test_clean dev_other test_other train_clean_100; do steps/make_mfcc.sh --cmd &quot;$train_cmd&quot; --nj 40 data/$part exp/make_mfcc/$part $mfccdir steps/compute_cmvn_stats.sh data/$part exp/make_mfcc/$part $mfccdir done fi ## è®­ç»ƒ100å°æ—¶çš„å°æ•°æ®é›† if [ $stage -le 7 ]; then utils/subset_data_dir.sh --shortest data/train_clean_100 2000 data/train_2kshort utils/subset_data_dir.sh data/train_clean_100 5000 data/train_5k utils/subset_data_dir.sh data/train_clean_100 10000 data/train_10k fi ## è®­ç»ƒå•éŸ³ç´ æ¨¡å‹(mono) if [ $stage -le 8 ]; then steps/train_mono.sh --boost-silence 1.25 --nj 20 --cmd &quot;$train_cmd&quot; \\ data/train_2kshort data/lang_nosp exp/mono fi ## å¯¹é½ï¼Œè®­ç»ƒä¸‰éŸ³ç´ æ¨¡å‹(tri1) if [ $stage -le 9 ]; then steps/align_si.sh --boost-silence 1.25 --nj 10 --cmd &quot;$train_cmd&quot; \\ data/train_5k data/lang_nosp exp/mono exp/mono_ali_5k steps/train_deltas.sh --boost-silence 1.25 --cmd &quot;$train_cmd&quot; \\ 2000 10000 data/train_5k data/lang_nosp exp/mono_ali_5k exp/tri1 fi ## å¯¹é½ï¼Œå¯¹ä¸‰éŸ³ç´ åšLDA+MLLTå˜æ¢(tri2b) if [ $stage -le 10 ]; then steps/align_si.sh --nj 10 --cmd &quot;$train_cmd&quot; \\ data/train_10k data/lang_nosp exp/tri1 exp/tri1_ali_10k steps/train_lda_mllt.sh --cmd &quot;$train_cmd&quot; \\ --splice-opts &quot;--left-context=3 --right-context=3&quot; 2500 15000 \\ data/train_10k data/lang_nosp exp/tri1_ali_10k exp/tri2b fi ## å¯¹é½ï¼Œå¯¹ä¸‰éŸ³ç´ åšLDA+MLLT+SATå˜æ¢(tri3b) if [ $stage -le 11 ]; then steps/align_si.sh --nj 10 --cmd &quot;$train_cmd&quot; --use-graphs true \\ data/train_10k data/lang_nosp exp/tri2b exp/tri2b_ali_10k steps/train_sat.sh --cmd &quot;$train_cmd&quot; 2500 15000 \\ data/train_10k data/lang_nosp exp/tri2b_ali_10k exp/tri3b fi ## å¯¹é½ï¼Œå¯¹ä¸‰éŸ³ç´ åšLDA+MLLT+SATå˜æ¢(tri4b) if [ $stage -le 12 ]; then steps/align_fmllr.sh --nj 20 --cmd &quot;$train_cmd&quot; \\ data/train_clean_100 data/lang_nosp \\ exp/tri3b exp/tri3b_ali_clean_100 steps/train_sat.sh --cmd &quot;$train_cmd&quot; 4200 40000 \\ data/train_clean_100 data/lang_nosp \\ exp/tri3b_ali_clean_100 exp/tri4b fi ## ä»è®­ç»ƒæ•°æ®ä¸­è®¡ç®—å‘éŸ³å’Œé™éŸ³æ¦‚ç‡ï¼Œå¹¶é‡æ–°åˆ›å»ºlangç›®å½• if [ $stage -le 13 ]; then steps/get_prons.sh --cmd &quot;$train_cmd&quot; \\ data/train_clean_100 data/lang_nosp exp/tri4b utils/dict_dir_add_pronprobs.sh --max-normalize true \\ data/local/dict_nosp \\ exp/tri4b/pron_counts_nowb.txt exp/tri4b/sil_counts_nowb.txt \\ exp/tri4b/pron_bigram_counts_nowb.txt data/local/dict utils/prepare_lang.sh data/local/dict \\ &quot;&lt;UNK&gt;&quot; data/local/lang_tmp data/lang local/format_lms.sh --src-dir data/lang data/local/lm utils/build_const_arpa_lm.sh \\ data/local/lm/lm_tglarge.arpa.gz data/lang data/lang_test_tglarge utils/build_const_arpa_lm.sh \\ data/local/lm/lm_fglarge.arpa.gz data/lang data/lang_test_fglarge fi ## å¯¹é½ï¼Œè®­ç»ƒnnet2æ¨¡å‹ï¼Œç°åœ¨å·²ç»ä¸è¿™ä¹ˆç”¨äº†ï¼Œæ‰€ä»¥andäº†ä¸ªfalse if [ $stage -le 14 ] &amp;&amp; false; then steps/align_fmllr.sh --nj 30 --cmd &quot;$train_cmd&quot; \\ data/train_clean_100 data/lang exp/tri4b exp/tri4b_ali_clean_100 local/nnet2/run_5a_clean_100.sh fi ## åˆå¹¶360å°æ—¶çš„æ•°æ®ï¼Œå˜æˆ460å°æ—¶ if [ $stage -le 15 ]; then local/download_and_untar.sh $data $data_url train-clean-360 local/data_prep.sh \\ $data/LibriSpeech/train-clean-360 data/train_clean_360 steps/make_mfcc.sh --cmd &quot;$train_cmd&quot; --nj 40 data/train_clean_360 \\ exp/make_mfcc/train_clean_360 $mfccdir steps/compute_cmvn_stats.sh \\ data/train_clean_360 exp/make_mfcc/train_clean_360 $mfccdir utils/combine_data.sh \\ data/train_clean_460 data/train_clean_100 data/train_clean_360 fi ## å¯¹é½ï¼ŒåšLDA+MLLT+SATå˜æ¢(tri5b) if [ $stage -le 16 ]; then steps/align_fmllr.sh --nj 40 --cmd &quot;$train_cmd&quot; \\ data/train_clean_460 data/lang exp/tri4b exp/tri4b_ali_clean_460 steps/train_sat.sh --cmd &quot;$train_cmd&quot; 5000 100000 \\ data/train_clean_460 data/lang exp/tri4b_ali_clean_460 exp/tri5b fi #local/nnet2/run_6a_clean_460.sh ## åˆå¹¶500å°æ—¶çš„æ•°æ®ï¼Œå˜æˆ960å°æ—¶ if [ $stage -le 17 ]; then local/download_and_untar.sh $data $data_url train-other-500 local/data_prep.sh \\ $data/LibriSpeech/train-other-500 data/train_other_500 steps/make_mfcc.sh --cmd &quot;$train_cmd&quot; --nj 40 data/train_other_500 \\ exp/make_mfcc/train_other_500 $mfccdir steps/compute_cmvn_stats.sh \\ data/train_other_500 exp/make_mfcc/train_other_500 $mfccdir utils/combine_data.sh \\ data/train_960 data/train_clean_460 data/train_other_500 fi ## å¯¹é½ï¼ŒåšLDA+MLLT+SATå˜æ¢(tri6b)ï¼Œè§£ç  if [ $stage -le 18 ]; then steps/align_fmllr.sh --nj 40 --cmd &quot;$train_cmd&quot; \\ data/train_960 data/lang exp/tri5b exp/tri5b_ali_960 steps/train_quick.sh --cmd &quot;$train_cmd&quot; \\ 7000 150000 data/train_960 data/lang exp/tri5b_ali_960 exp/tri6b utils/mkgraph.sh data/lang_test_tgsmall \\ exp/tri6b exp/tri6b/graph_tgsmall for test in test_clean test_other dev_clean dev_other; do steps/decode_fmllr.sh --nj 20 --cmd &quot;$decode_cmd&quot; \\ exp/tri6b/graph_tgsmall data/$test exp/tri6b/decode_tgsmall_$test steps/lmrescore.sh --cmd &quot;$decode_cmd&quot; data/lang_test_{tgsmall,tgmed} \\ data/$test exp/tri6b/decode_{tgsmall,tgmed}_$test steps/lmrescore_const_arpa.sh \\ --cmd &quot;$decode_cmd&quot; data/lang_test_{tgsmall,tglarge} \\ data/$test exp/tri6b/decode_{tgsmall,tglarge}_$test steps/lmrescore_const_arpa.sh \\ --cmd &quot;$decode_cmd&quot; data/lang_test_{tgsmall,fglarge} \\ data/$test exp/tri6b/decode_{tgsmall,fglarge}_$test done fi ## åˆ’åˆ†â€œå¥½â€çš„æ•°æ®æ¥è®­ç»ƒæ•°æ®ï¼ˆtri6b_cleanedï¼‰ if [ $stage -le 19 ]; then local/run_cleanup_segmentation.sh fi ## è®­ç»ƒå’Œæµ‹è¯•nnet3 tdnnæ¨¡å‹ if [ $stage -le 20 ]; then local/chain/run_tdnn.sh fi 2.2 ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æµ‹è¯•è‡ªå·±çš„æ•°æ®é›†é¦–å…ˆï¼Œæ–°å»ºè‡ªå·±æ•°æ®åº“çš„æ–‡ä»¶å¤¹ï¼Œå¹¶è®¾ç½®stepsã€utilsã€rnnlmçš„è½¯é“¾æ¥ã€‚ ln -s /home/fwq/Project/kaldi/kaldi/egs/wsj/s5/utils utils ln -s /home/fwq/Project/kaldi/kaldi/egs/wsj/s5/steps steps ln -s /home/fwq/Project/kaldi/kaldi/scripts/rnnlm rnnlm ç„¶åå¼€å§‹å‡†å¤‡è‡ªå·±çš„æ•°æ®åº“ï¼Œkaldiéœ€è¦çš„æ–‡ä»¶å¦‚ä¸‹ï¼Œè¿™éƒ¨åˆ†éœ€è¦æ ¹æ®è‡ªå·±çš„æ•°æ®åº“æ ¼å¼æ¥ç¼–å†™ç”Ÿæˆï¼Œæ”¾ç½®åœ¨data/corpus_name/é‡Œï¼Œä»¥ä¸‹corpuså‘½åä¸ºtestã€‚ wav.scpï¼šæ­¤åˆ—è¡¨åŒ…å«ç³»ç»Ÿä¸­çš„è¯­éŸ³IDå’Œç›¸åº”çš„WAVä½ç½® utt2spkï¼šè¯è¯­IDå’Œç›¸åº”çš„è¯´è¯è€…IDçš„åˆ—è¡¨ã€‚å¦‚æœæ‚¨æ²¡æœ‰å‘è¨€äººä¿¡æ¯ï¼Œåˆ™å¯ä»¥å°†utt-idå¤åˆ¶ä¸ºspk-idã€‚ textï¼šè¯è¯­çš„è½¬å½•ã€‚è¿™å°†éœ€è¦å¯¹æ‚¨çš„è§£ç è¾“å‡ºè¿›è¡Œè¯„åˆ†ã€‚ å†å¯¹æ•°æ®è¿›è¡Œæ’åºã€å¤åˆ¶ç­‰å¤„ç†ã€‚ utils/fix_data_dir.sh data/test utils/utt2spk_to_spk2utt.pl data/test/utt2spk &gt; data/test/spk2utt for datadir in test; do utils/copy_data_dir.sh data/$datadir data/${datadir}_hires done æœ‰äº†æ•°æ®ï¼Œå°±è¦å‡†å¤‡ç”Ÿæˆmfccç‰¹å¾ï¼Œéœ€è¦æ–°å»ºä¸€ä¸ªconfæ–‡ä»¶å¤¹ï¼Œå¹¶æ–°å»ºconf/mfcc_hires.confçš„é…ç½®æ–‡ä»¶ï¼Œæ·»åŠ å¦‚ä¸‹ï¼š -use-energy=false # use average of log energy, not energy. --num-mel-bins=40 # similar to Google&#39;s setup. --num-ceps=40 # there is no dimensionality reduction. --low-freq=20 # low cutoff frequency for mel bins... this is high-bandwidth data, so # there might be some information at the low end. --high-freq=-400 # high cutoff frequently, relative to Nyquist of 8000 (=7600) ç„¶åå°±å¯ä»¥ä¸ºæ•°æ®è®¡ç®—ç‰¹å¾å’ŒCMVNç»Ÿè®¡ä¿¡æ¯ã€‚ for datadir in test; do steps/make_mfcc.sh --nj 20 --mfcc-config conf/mfcc_hires.conf --cmd &quot;$train_cmd&quot; data/${datadir}_hires steps/compute_cmvn_stats.sh data/${datadir}_hires utils/fix_data_dir.sh data/${datadir}_hires done æ¥ä¸‹æ¥æ˜¯é¢„è®­ç»ƒæ¨¡å‹çš„ä¸‹è½½å’Œå¯¼å…¥ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå†…å®¹å°†æå–åˆ°dataå’Œexpç›®å½•ã€‚è¿™é‡Œæä¾›äº†2ç§è¯­è¨€æ¨¡å‹ï¼šï¼ˆtgsmallå°ä¸‰å…ƒç»„æ¨¡å‹ï¼‰å’Œrnnlmï¼ˆåŸºäºLSTMï¼‰ï¼Œè¿™ä¸¤ç§è¯­è¨€æ¨¡å‹éƒ½ç»è¿‡LibriSpeechè®­ç»ƒè½¬å½•æœ¬çš„è®­ç»ƒã€‚æˆ‘ä»¬å°†ä½¿ç”¨tgsmallæ¨¡å‹è¿›è¡Œè§£ç ï¼Œå¹¶ä½¿ç”¨RNNLMè¿›è¡Œè®°å½•ã€‚ wget http://kaldi-asr.org/models/13/0013_librispeech_v1_chain.tar.gz wget http://kaldi-asr.org/models/13/0013_librispeech_v1_extractor.tar.gz wget http://kaldi-asr.org/models/13/0013_librispeech_v1_lm.tar.gz tar -xvzf 0013_librispeech_v1_chain.tar.gz tar -xvzf 0013_librispeech_v1_extractor.tar.gz tar -xvzf 0013_librispeech_v1_lm.tar.gz ä½¿ç”¨i-vectoræå–å™¨æ¥è·å–æµ‹è¯•æ•°æ®çš„i-vectorã€‚ è¿™ä¼šå°†100ç»´i-å‘é‡æå–åˆ°exp/nnet3_cleanedã€‚ for data in test; do nspk=$(wc -l &lt;data/${data}_hires/spk2utt) steps/online/nnet2/extract_ivectors_online.sh --cmd &quot;$train_cmd&quot; --nj &quot;${nspk}&quot; \\ data/${data}_hires exp/nnet3_cleaned/extractor \\ exp/nnet3_cleaned/ivectors_${data}_hires done ä½¿ç”¨tgsmallLMåˆ›å»ºè§£ç å›¾ã€‚ export dir=exp/chain_cleaned/tdnn_1d_sp export graph_dir=$dir/graph_tgsmall utils/mkgraph.sh --self-loop-scale 1.0 --remove-oov \\ data/lang_test_tgsmall $dir $graph_dir ä½¿ç”¨åˆ›å»ºçš„å›¾å½¢è¿›è¡Œè§£ç ã€‚ export decode_cmd=&quot;run.pl&quot; for decode_set in test; do steps/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 \\ --nj 8 --cmd &quot;$decode_cmd&quot; \\ --online-ivector-dir exp/nnet3_cleaned/ivectors_${decode_set}_hires \\ $graph_dir data/${decode_set}_hires $dir/decode_${decode_set}_tgsmall done åœ¨æ ¸å¯¹ä¹‹å‰æ£€æŸ¥WERã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨scliteè¯„åˆ†ï¼Œè¿™åœ¨Kaldiä¸­å¯ç”¨ï¼Œå¹¶ç”¨äºå¤§å¤šæ•°egsã€‚ for decode_set in test; do steps/score_kaldi.sh --cmd &quot;run.pl&quot; data/${decode_set}_hires $graph_dir $dir/decode_${decode_set}_tgsmall done cat exp/chain_cleaned/tdnn_1d_sp/decode_test_tgsmall/scoring_kaldi/best_wer %WER 57.15 [ 14722 / 25761, 2501 ins, 2559 del, 9662 sub ] exp/chain_cleaned/tdnn_1d_sp/decode_test_tgsmall/wer_17_1.0 ä½¿ç”¨RNNLMé‡æ–°è¯„åˆ†ã€‚ export decode_cmd=&quot;run.pl&quot; for decode_set in test; do decode_dir=exp/chain_cleaned/tdnn_1d_sp/decode_${decode_set}_tgsmall; rnnlm/lmrescore_pruned.sh \\ --cmd &quot;$decode_cmd&quot; \\ --weight 0.45 --max-ngram-order 4 \\ data/lang_test_tgsmall exp/rnnlm_lstm_1a \\ data/${decode_set}_hires ${decode_dir} \\ exp/chain_cleaned/tdnn_1d_sp/decode_${decode_set}_rescore done è®¡åˆ†åŒ…å«åœ¨lmrescore_pruned.shè„šæœ¬ä¸­ã€‚ cat exp/chain_cleaned/tdnn_1d_sp/decode_test_rescore/wer_17_1.0 # %WER 56.12 [ 14456 / 25761, 2607 ins, 2452 del, 9397 sub ] 3. kaldiä½¿ç”¨æ„Ÿå—ä¸åŒäºä»¥å¾€ç”¨çš„pythonï¼Œkaldiçš„åˆæ­¥ä½¿ç”¨é€šè¿‡shellè„šæœ¬æ¥å®ç°ï¼Œå®ƒåŸºäºc++çš„åº•å±‚ï¼Œé€šè¿‡ç¤¾åŒºä¸åŒå‘å±•ï¼Œç°åœ¨å·²ç»æœ‰äº†éå¸¸åºå¤§çš„è„šæœ¬åº“ã€‚å¾ˆå¤šå‡½æ•°éƒ½å®ç°äº†é«˜æ•ˆçš„å°è£…ï¼Œä½†å¦‚æœè¦è‡ªå·±æç‰¹å¾è®­æ¨¡å‹çš„è¯ï¼Œè¿˜éœ€è¦ç»†çœ‹shellä»£ç è¿›ä¸€æ­¥çœ‹c++ä»£ç ã€‚ 4. å‚è€ƒæ–‡çŒ®å‚è€ƒ1å‚è€ƒ2","categories":[],"tags":[]},{"title":"äº†è§£ä¸€ä¸‹Faster RCNN","slug":"fasterrcnn","date":"2020-11-19T08:27:38.000Z","updated":"2020-11-21T10:02:09.208Z","comments":true,"path":"2020/11/19/fasterrcnn/","link":"","permalink":"http://weiquanfan.xyz/2020/11/19/fasterrcnn/","excerpt":"","text":"1. å‰è¨€Faster RCNN ç”± è®ºæ–‡æå‡ºï¼Œæ˜¯ç»§R-CNNå’ŒFast RCNNä¹‹åçš„ç›®æ ‡æ£€æµ‹ä¸Šçš„åˆä¸€åŠ›ä½œã€‚R-CNNæå‡ºselective search(SS)æ¥æœç´¢region proposal(RP)ï¼›Fast RCNNæŒ‡å‡ºä¸å¿…å¯¹æ¯ä¸ªRPå„è‡ªæCNNç‰¹å¾ï¼Œå¯ä»¥å¯¹åŸå›¾æå¥½CNNç‰¹å¾ï¼Œå†å°†SSæ‰¾åˆ°çš„RPæ˜ å°„åˆ°CNNç‰¹å¾å±‚ä¸Šï¼›Faster RCNNåˆ™æå‡ºäº†RPNå±‚ï¼Œå°†ç‰¹å¾æå–ï¼Œproposalæå–ï¼Œbounding boxæ•´åˆåœ¨äº†ä¸€ä¸ªç½‘ç»œä¸­ï¼Œæå¤§åœ°æé«˜äº†æ£€æµ‹é€Ÿåº¦ã€‚ 2. æ¡†æ¶ä¸æµç¨‹Faster RCNNçš„æ¨¡å‹æ¡†æ¶å¦‚å›¾ã€‚ å¯ä»¥åˆ†ä¸º4ä¸ªä¸»è¦å†…å®¹ï¼š Conv layersã€‚ä½œä¸ºä¸€ç§CNNç½‘ç»œç›®æ ‡æ£€æµ‹æ–¹æ³•ï¼ŒFaster RCNNé¦–å…ˆä½¿ç”¨ä¸€ç»„åŸºç¡€çš„conv+relu+poolingå±‚æå–imageçš„feature mapsã€‚è¯¥feature mapsè¢«å…±äº«ç”¨äºåç»­RPNå±‚å’Œå…¨è¿æ¥å±‚ã€‚ Region Proposal Networksã€‚RPNç½‘ç»œç”¨äºç”Ÿæˆregion proposalsã€‚è¯¥å±‚é€šè¿‡softmaxåˆ¤æ–­anchorså±äºpositiveæˆ–è€…negativeï¼Œå†åˆ©ç”¨bounding box regressionä¿®æ­£anchorsè·å¾—ç²¾ç¡®çš„proposalsã€‚ Roi Poolingã€‚è¯¥å±‚æ”¶é›†è¾“å…¥çš„feature mapså’Œproposalsï¼Œç»¼åˆè¿™äº›ä¿¡æ¯åæå–proposal feature mapsï¼Œé€å…¥åç»­å…¨è¿æ¥å±‚åˆ¤å®šç›®æ ‡ç±»åˆ«ã€‚ Classificationã€‚åˆ©ç”¨proposal feature mapsè®¡ç®—proposalçš„ç±»åˆ«ï¼ŒåŒæ—¶å†æ¬¡bounding box regressionè·å¾—æ£€æµ‹æ¡†æœ€ç»ˆçš„ç²¾ç¡®ä½ç½®ã€‚ å®Œæ•´çš„ç½‘ç»œå›¾å¦‚ä¸‹ã€‚ è¯¥ç½‘ç»œå¯¹äºä¸€å‰¯ä»»æ„å¤§å°PxQçš„å›¾åƒï¼Œé¦–å…ˆç¼©æ”¾è‡³å›ºå®šå¤§å°MxNï¼Œç„¶åå°†MxNå›¾åƒé€å…¥ç½‘ç»œï¼› Conv layersä¸­åŒ…å«äº†13ä¸ªconvå±‚+13ä¸ªreluå±‚+4ä¸ªpoolingå±‚ï¼› RPNç½‘ç»œé¦–å…ˆç»è¿‡3x3å·ç§¯ï¼Œå†åˆ†åˆ«ç”Ÿæˆpositive anchorså’Œå¯¹åº”bounding box regressionåç§»é‡ï¼Œç„¶åè®¡ç®—å‡ºproposalsï¼› Roi Poolingå±‚åˆ™åˆ©ç”¨proposalsä»feature mapsä¸­æå–proposal featureé€å…¥åç»­å…¨è¿æ¥å’Œsoftmaxç½‘ç»œä½œclassificationã€‚ 3. æ¨¡å‹ç»†èŠ‚3.1 Region Proposal Networks(RPN)ä»ç½‘ç»œæ€»å›¾ä¸Šå¯ä»¥çœ‹å‡ºï¼ŒRPN å±‚å¯ä»¥åˆ†ä¸ºä¸Šä¸‹ä¸¤æ¡æ”¯è·¯ï¼Œä¸Šé¢ä¸€æ¡é€šè¿‡softmaxåˆ†ç±»anchorsè·å¾—positiveå’Œnegativeåˆ†ç±»ï¼Œä¸‹é¢ä¸€æ¡ç”¨äºè®¡ç®—å¯¹äºanchorsçš„bounding box regressionåç§»é‡ï¼Œä»¥è·å¾—ç²¾ç¡®çš„proposalã€‚è€Œæœ€åçš„Proposalå±‚åˆ™è´Ÿè´£ç»¼åˆpositive anchorså’Œå¯¹åº”bounding box regressionåç§»é‡è·å–proposalsï¼ŒåŒæ—¶å‰”é™¤å¤ªå°å’Œè¶…å‡ºè¾¹ç•Œçš„proposalsã€‚ 3.1.1 anchorsanchors æ˜¯ä¸€ç»„é¢„è®¾å¥½çš„çŸ©å½¢ã€‚å¯¹äºç¼©æ”¾è‡³800Ã—600çš„å›¾ï¼Œä½œè€…é¢„è®¾äº†9ä¸ªanchorsï¼Œåæ ‡å¦‚ä¸‹ã€‚ [[ -84. -40. 99. 55.] [-176. -88. 191. 103.] [-360. -184. 375. 199.] [ -56. -56. 71. 71.] [-120. -120. 135. 135.] [-248. -248. 263. 263.] [ -36. -80. 51. 95.] [ -80. -168. 95. 183.] [-168. -344. 183. 359.]] å…¶ä¸­æ¯è¡Œçš„4ä¸ªå€¼è¡¨ç¤ºçŸ©å½¢çš„å·¦ä¸Šå’Œå³ä¸‹è§’ç‚¹åæ ‡ã€‚è¿™9ä¸ªçŸ©å½¢çš„é•¿å®½æ¯”ä¸º0.5ã€1æˆ–2ï¼Œanchorsä¸­é•¿å®½1:2ä¸­æœ€å¤§ä¸º352x704ï¼Œé•¿å®½2:1ä¸­æœ€å¤§736x384ï¼Œè¿™æ ·å°±å¯ä»¥åŸºæœ¬è¦†ç›–åˆ°æ•´å¼ å›¾ã€‚ æœ‰äº†è¿™äº›anchorsï¼Œæˆ‘ä»¬éå†Conv layersè®¡ç®—è·å¾—çš„feature mapsï¼Œä¸ºæ¯ä¸€ä¸ªç‚¹éƒ½é…å¤‡è¿™9ç§anchorsä½œä¸ºåˆå§‹çš„æ£€æµ‹æ¡†ã€‚è¿™é‡Œå¦‚æœæœ‰è¶…å‡ºå›¾åƒè¾¹ç¼˜çš„æ¡†ï¼Œæˆ‘ä»¬å°±å¯¹æ¡†è¿›è¡Œè£å‰ªï¼Œä¸¢å¼ƒæ‰æ¡†å¤–çš„éƒ¨åˆ†ã€‚é‚£ä¹ˆæ€»å…±å°±æœ‰ (800//16) (600//16) 9 = 17100ä¸ªanchorã€‚ 3.1.2 softmaxåˆ†ç±»ä¸€å‰¯MxNå¤§å°çš„çŸ©é˜µé€å…¥Faster RCNNç½‘ç»œåï¼Œåˆ°RPNç½‘ç»œå˜ä¸º(M/16)x(N/16)ï¼Œè®¾ä¸ºWÃ—Hã€‚ åœ¨è¿›å…¥reshapeä¸softmaxä¹‹å‰ï¼Œå…ˆåšäº†1x1å·ç§¯ï¼Œè¾“å‡º18ï¼ˆå³2Ã—9ï¼‰å±‚feature maps. 9è¡¨ç¤ºä¹ç§anchorï¼Œ2è¡¨ç¤ºè¯¥anchoræ˜¯å¦å«æœ‰ç›®æ ‡ã€‚ è¿™é‡Œï¼Œä¸ºäº†è¿›è¡Œsoftmaxè¾“å‡ºäºŒåˆ†ç±»ç»“æœï¼Œéœ€è¦å•ç‹¬æŠŠâ€˜2â€™è¿™ä¸ªç»´åº¦å­¤ç«‹å‡ºæ¥ï¼Œå› æ­¤åœ¨softmaxå‰åå„æœ‰ä¸€ä¸ªreshapeã€‚æ•°æ®çš„å°ºå¯¸å˜åŒ–ä¸ºï¼š[1, 2x9, H, W] -&gt; [1, 2, Hx9, W], softmax -&gt; [1, 2x9, H, W]. 3.1.3 bounding box regressionå¯¹äºçª—å£ä¸€èˆ¬ä½¿ç”¨å››ç»´å‘é‡(x,y,w,h)è¡¨ç¤ºï¼Œåˆ†åˆ«è¡¨ç¤ºçª—å£çš„ä¸­å¿ƒç‚¹åæ ‡å’Œå®½é«˜ã€‚å¯¹äºpositive Anchors(è®¾ä¸ºA)ï¼Œå’Œgroundtruth(è®¾ä¸ºGâ€™)ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å¯»æ‰¾ä¸€ç§å…³ç³»ï¼Œä½¿å¾—è¾“å…¥åŸå§‹çš„anchor Aç»è¿‡æ˜ å°„å¾—åˆ°ä¸€ä¸ªè·ŸçœŸå®çª—å£Gæ›´æ¥è¿‘çš„å›å½’çª—å£Gâ€™ã€‚æ¯”è¾ƒç®€å•çš„æ€è·¯å°±æ˜¯: æ³¨æ„ï¼Œè¿™é‡Œçš„å¹³ç§»dxå’Œdyå¯ä»¥ç†è§£ä¸ºç›¸å¯¹äºåŸå®½é•¿çš„å¹³ç§»å› å­ï¼Œå³ç›¸å¯¹äºåŸå®½é•¿å¹³ç§»äº†å¤šå°‘å€çš„è·ç¦»ã€‚ç¼©æ”¾dwå’Œdhå¯ä»¥ç†è§£ä¸ºç¼©æ”¾äº†lnçš„dwå’Œdhå€ã€‚ é‚£ä¹ˆï¼Œå¯¹åº”äºFaster RCNNåŸæ–‡ï¼Œpositive anchorä¸ground truthä¹‹é—´çš„å¹³ç§»é‡(tx, ty)ä¸å°ºåº¦å› å­(tw, th)å¦‚ä¸‹ï¼š è®­ç»ƒbouding box regressionç½‘ç»œå›å½’åˆ†æ”¯æ—¶ï¼Œæ ‡ç­¾æ˜¯(tx,ty,tw,th)ã€‚ è¾“å…¥cnn featureï¼Œè¾“å‡º36ï¼ˆå³4Ã—9ï¼‰å±‚feature maps. 9è¡¨ç¤ºä¹ç§anchorï¼Œ4è¡¨ç¤ºè¯¥anchorçš„å¹³ç§»é‡å’Œç¼©æ”¾é‡ã€‚æ³¨æ„è¿™é‡Œçš„å¹³ç§»ç¼©æ”¾é‡æ˜¯é’ˆå¯¹åŸMÃ—Nçš„å°ºå¯¸çš„ï¼Œè€Œè¾“å…¥çš„featureæ˜¯poolingåçš„å°ºå¯¸ã€‚ 3.1.4 Proposal LayerVGGè¾“å‡º 5038512 çš„ç‰¹å¾ï¼Œå¯¹åº”è®¾ç½® 5038kä¸ªanchorsï¼Œè€ŒRPNè¾“å‡ºï¼š å¤§å°ä¸º 50382k çš„positive/negative softmaxåˆ†ç±»ç‰¹å¾çŸ©é˜µ å¤§å°ä¸º 50384k çš„regressionåæ ‡å›å½’ç‰¹å¾çŸ©é˜µ Proposal Layerè´Ÿè´£ç»¼åˆæ‰€æœ‰å¹³ç§»ç¼©æ”¾é‡å’Œpositive anchorsï¼Œè®¡ç®—å‡ºç²¾å‡†çš„proposalï¼Œé€å…¥åç»­RoI Pooling Layerã€‚ Proposal Layer forward æŒ‰ç…§ä»¥ä¸‹é¡ºåºä¾æ¬¡å¤„ç†ï¼š æŒ‰ç…§è¾“å…¥çš„positive softmax scoresç”±å¤§åˆ°å°æ’åºanchorsï¼Œæå–å‰pre_nms_topN(e.g. 6000)ä¸ªanchorsï¼Œå³æå–ä¿®æ­£ä½ç½®åçš„positive anchors é™å®šè¶…å‡ºå›¾åƒè¾¹ç•Œçš„positive anchorsä¸ºå›¾åƒè¾¹ç•Œï¼Œé˜²æ­¢åç»­roi poolingæ—¶proposalè¶…å‡ºå›¾åƒè¾¹ç•Œ å‰”é™¤å°ºå¯¸éå¸¸å°çš„positive anchors å¯¹å‰©ä½™çš„positive anchorsè¿›è¡ŒNMSï¼ˆnonmaximum suppressionï¼‰ï¼Œå»æ‰å¤§é‡é‡å¤æ¡† Proposal Layeræœ‰3ä¸ªè¾“å…¥ï¼šanchorsæ˜¯å¦æœ‰ç›®æ ‡çš„åˆ†ç±»å™¨ç»“æœrpn_cls_prob_reshapeï¼Œå¯¹åº”çš„bboxåæ ‡(e.g. 300)ï¼ŒåŒ…å«äº†ç¼©æ”¾ä¿¡æ¯çš„im_info=[M, N, scale_factor]ã€‚ç„¶åè¾“å‡º300ä¸ª proposal=[x1, y1, x2, y2]ã€‚ 3.2 RoI poolingç”±äºRPNå±‚è¾“å‡ºçš„proposalå°ºå¯¸ä¸ä¸€ï¼Œæ•…æå‡ºäº†RoI poolingå˜æ¢åˆ°ç»Ÿä¸€çš„å°ºå¯¸ã€‚Rol poolingå±‚æœ‰2ä¸ªè¾“å…¥ï¼š åŸå§‹çš„feature maps RPNè¾“å‡ºçš„proposal boxesï¼ˆå¤§å°å„ä¸ç›¸åŒï¼‰ RoI Pooling layer forwardè¿‡ç¨‹ï¼š ç”±äºproposalæ˜¯å¯¹åº”MXNå°ºåº¦çš„ï¼Œæ‰€ä»¥é¦–å…ˆä½¿ç”¨spatial_scale=1/16å°†å…¶æ˜ å°„å›(M/16)X(N/16)å¤§å°çš„feature mapå°ºåº¦ï¼› å†å°†æ¯ä¸ªproposalå¯¹åº”çš„feature mapåŒºåŸŸæ°´å¹³åˆ†ä¸º pooled_w Ã— pooled_h çš„ç½‘æ ¼ï¼› å¯¹ç½‘æ ¼çš„æ¯ä¸€ä»½éƒ½è¿›è¡Œmax poolingå¤„ç†ã€‚ è¿™æ ·å¤„ç†åï¼Œå³ä½¿å¤§å°ä¸åŒçš„proposalè¾“å‡ºç»“æœéƒ½æ˜¯ pooled_w Ã— pooled_h å›ºå®šå¤§å°ï¼Œå®ç°äº†å›ºå®šé•¿åº¦è¾“å‡ºã€‚ 3.3 ClassificationClassificationç¯èŠ‚ï¼Œåˆ©ç”¨å·²ç»è·å¾—çš„proposal feature mapsï¼Œé€šè¿‡full connectå±‚ä¸softmaxè®¡ç®—æ¯ä¸ªproposalå…·ä½“å±äºé‚£ä¸ªç±»åˆ«ï¼ˆå¦‚äººï¼Œè½¦ï¼Œç”µè§†ç­‰ï¼‰ï¼Œè¾“å‡ºcls_probæ¦‚ç‡å‘é‡ï¼›åŒæ—¶å†æ¬¡åˆ©ç”¨bounding box regressionè·å¾—æ¯ä¸ªproposalçš„ä½ç½®åç§»é‡bbox_predï¼Œç”¨äºå›å½’æ›´åŠ ç²¾ç¡®çš„ç›®æ ‡æ£€æµ‹æ¡†ã€‚ 4. Faster RCNNçš„è®­ç»ƒFaster RCNNè®­ç»ƒè¿‡ç¨‹åˆ†ä¸º6ä¸ªæ­¥éª¤ï¼š åœ¨å·²ç»è®­ç»ƒå¥½çš„modelä¸Šï¼Œè®­ç»ƒRPNç½‘ç»œï¼Œå¯¹åº”stage1_rpn_train.pt åˆ©ç”¨æ­¥éª¤1ä¸­è®­ç»ƒå¥½çš„RPNç½‘ç»œï¼Œæ”¶é›†proposalsï¼Œå¯¹åº”rpn_test.pt ç¬¬ä¸€æ¬¡è®­ç»ƒFast RCNNç½‘ç»œï¼Œå¯¹åº”stage1_fast_rcnn_train.pt ç¬¬äºŒè®­ç»ƒRPNç½‘ç»œï¼Œå¯¹åº”stage2_rpn_train.pt å†æ¬¡åˆ©ç”¨æ­¥éª¤4ä¸­è®­ç»ƒå¥½çš„RPNç½‘ç»œï¼Œæ”¶é›†proposalsï¼Œå¯¹åº”rpn_test.pt ç¬¬äºŒæ¬¡è®­ç»ƒFast RCNNç½‘ç»œï¼Œå¯¹åº”stage2_fast_rcnn_train.pt å¯ä»¥çœ‹åˆ°è®­ç»ƒè¿‡ç¨‹ç±»ä¼¼äºä¸€ç§â€œè¿­ä»£â€çš„è¿‡ç¨‹ï¼Œä¸è¿‡åªå¾ªç¯äº†2æ¬¡ã€‚è‡³äºåªå¾ªç¯äº†2æ¬¡çš„åŸå› æ˜¯åº”ä¸ºä½œè€…æåˆ°ï¼šâ€A similar alternating training can be run for more iterations, but we have observed negligible improvementsâ€ï¼Œå³å¾ªç¯æ›´å¤šæ¬¡æ²¡æœ‰æå‡äº†ã€‚æ³¨æ„ï¼Œåœ¨ç¬¬äºŒæ¬¡è®­ç»ƒæ—¶ï¼ŒRPNå’ŒFast RCNNå…±äº«çš„ç½‘ç»œå±‚æ˜¯å†»ç»“çš„ã€‚ 5. æ€»ç»“Faster RCNNæ˜¯ç›®æ ‡æ£€æµ‹é‡Œtwo-stageçš„ä»£è¡¨æ€§æ°ä½œï¼Œåœ¨è¿™ä¹‹åè¿˜æœ‰ä¸€æ¬¾ç”¨äºç›®æ ‡æ£€æµ‹å’Œå®ä¾‹åˆ†å‰²çš„Mask RCNNä¹Ÿä¸ºäººç§°é“ã€‚Mask RCNNç±»ä¼¼äºFaster RCNNçš„ä¸¤ä¸ªè¾“å‡ºï¼ˆé¢„æµ‹æ¡†çš„åæ ‡å’Œç±»åˆ«ï¼‰ï¼Œä½†å¤šä¸€æ¡åŸºäºç‰¹å¾é‡‘å­—å¡”FCNç½‘ç»œçš„å®ä¾‹åˆ†å‰²çš„maské€šè·¯ï¼Œå¦å¤–è¿˜å°†RoI poolingæ¢æˆRoI alignè§£å†³é‡åŒ–å¸¦æ¥çš„è¾¹ç¼˜åƒç´ æŸå¤±é—®é¢˜ã€‚åæ¥ï¼Œç›®æ ‡æ£€æµ‹åˆæœ‰å¾ˆå¤šone-stageæ–¹æ³•æ¶Œç°ï¼Œå³ä¸€æ­¥ç›´æ¥ç”Ÿæˆé¢„æµ‹æ¡†çš„åæ ‡å’Œç±»åˆ«ï¼Œå…¶ä¸­ä»¥YOLOå’ŒSSDä¸ºä»£è¡¨ï¼Œå®ƒä»¬æœ€ç»ˆè¾“å‡ºkÃ—(4+1+c)é€šé“çš„ç‰¹å¾å›¾ï¼Œå…¶ä¸­4æ˜¯åæ ‡ï¼Œ1æ˜¯å‰æ™¯ã€èƒŒæ™¯çš„ç½®ä¿¡åº¦ï¼Œcæ˜¯ç±»åˆ«æ•°ï¼Œcæ˜¯anchoræ•°ã€‚ä¸¤è€…é€‰æ‹©anchoræ¡†çš„ç­–ç•¥ä¸åŒï¼ŒYOLOçš„anchoråŸºäºè®­ç»ƒé›†æ‰€æœ‰æ¡†èšç±»å¾—åˆ°å®½å’Œé•¿ï¼ŒSSDç”±æ•°å­¦å…¬å¼å¾—åˆ°ï¼Œä¸”SSDåœ¨ä¸åŒå°ºåº¦çš„ç‰¹å¾å›¾ä¸Šé€‰å–äº†ä¸åŒçš„anchoræ•°é‡(ä»è€Œå®ç°å¤šå°ºåº¦çš„æ£€æµ‹)ã€‚ä¸¤è€…çš„anchoræ¡†éƒ½åªæœ‰å®½åº¦å’Œé«˜åº¦ï¼Œåæ ‡xå’Œyéƒ½é»˜è®¤åœ¨ç½‘æ ¼ä¸­å¿ƒã€‚ 6. å‚è€ƒæ–‡çŒ®https://zhuanlan.zhihu.com/p/31426458","categories":[],"tags":[]},{"title":"ä½¿ç”¨ç«¯ç‚¹æ£€æµ‹å’Œç™¾åº¦è¯­éŸ³è¯†åˆ«æŠ€æœ¯å®ç°è§†é¢‘çš„å­—å¹•ç”Ÿæˆ","slug":"gen-srt","date":"2020-06-26T02:47:38.000Z","updated":"2020-06-26T02:49:49.855Z","comments":true,"path":"2020/06/26/gen-srt/","link":"","permalink":"http://weiquanfan.xyz/2020/06/26/gen-srt/","excerpt":"","text":"å‰è¨€å­—å¹•æ–‡ä»¶ä¸­åŒ…å«å¾ˆå¤šæ®µä¿¡æ¯ï¼Œæ¯ä¸€æ®µè¡¨ç¤ºäº†ä¸€å¥è¯çš„èµ·å§‹ç»“æŸæ—¶é—´å’Œå†…å®¹ï¼Œå› æ­¤ä¾¿æ¶‰åŠåˆ°äº†ç«¯ç‚¹æ£€æµ‹æŠ€æœ¯å’Œè¯­éŸ³è¯†åˆ«æŠ€æœ¯ã€‚ ç«¯ç‚¹æ£€æµ‹ï¼špydub.silence.detect_nonsilent è¯­éŸ³è¯†åˆ«ï¼šaip.AipSpeechï¼ˆç™¾åº¦æ¥å£ï¼‰pip install pydub pip install baidu-aip æµç¨‹ è§†é¢‘æå–éŸ³é¢‘ å¯¹éŸ³é¢‘è¿›è¡Œç«¯ç‚¹æ£€æµ‹ï¼Œç”Ÿæˆä¸€å¥ä¸€å¥çš„éŸ³é¢‘ å¯¹å„å¥éŸ³é¢‘è¿›è¡Œè¯­éŸ³è¯†åˆ« æ•´åˆæˆå­—å¹•srtæ ¼å¼ ä»£ç #!/usr/bin/env python3 # -*- coding: utf-8 -*- from moviepy.editor import * from pydub import * from aip import AipSpeech video_file = r&#39;C:\\Users\\Lenovo\\Desktop\\video_sep\\test.mp4&#39; audio_file = r&#39;C:\\Users\\Lenovo\\Desktop\\test.wav&#39; srt_file = r&#39;C:\\Users\\Lenovo\\Desktop\\srt\\test.srt&#39; ## transform to audio video = VideoFileClip(video_file) video.audio.write_audiofile(audio_file, ffmpeg_params=[&#39;-ar&#39;,&#39;16000&#39;,&#39;-ac&#39;,&#39;1&#39;]) ## segment sound = AudioSegment.from_wav(audio_file) timestamp_list = silence.detect_nonsilent(sound, 700, sound.dBFS*1.3, 1) # look here for i in range(len(timestamp_list)): d = timestamp_list[i][1] - timestamp_list[i][0] print(&quot;Section is :&quot;, timestamp_list[i], &quot;duration is:&quot;, d) print(&#39;dBFS: {0}, max_dBFS: {1}, duration: {2}, split: {3}&#39;.format(round(sound.dBFS,2),round(sound.max_dBFS,2),sound.duration_seconds,len(timestamp_list))) def format_time(ms): hours = ms // 3600000 ms = ms % 3600000 minutes = ms // 60000 ms = ms % 60000 seconds = ms // 1000 mseconds = ms % 1000 return &#39;{:0&gt;2d}:{:0&gt;2d}:{:0&gt;2d},{:0&gt;3d}&#39;.format(hours, minutes, seconds, mseconds) ## ä»¥ä¸‹åœ¨ç™¾åº¦AIå¼€æ”¾å¹³å°ç”³è¯·è·å¾— ## https://ai.baidu.com/tech/speech APP_ID = &#39;&#39; API_KEY = &#39;&#39; SECRET_KEY = &#39;&#39; client = AipSpeech(APP_ID, API_KEY, SECRET_KEY) idx = 0 text = [] for i in range(len(timestamp_list)): d = timestamp_list[i][1] - timestamp_list[i][0] data = sound[timestamp_list[i][0]:timestamp_list[i][1]].raw_data ## asr result = client.asr(data, &#39;pcm&#39;, 16000, {&#39;lan&#39;: &#39;zh&#39;,}) ## and look here if result[&#39;err_no&#39;] == 0: text.append(&#39;{0}\\n{1} --&gt; {2}\\n&#39;.format(idx, format_time(timestamp_list[i][0]), format_time(timestamp_list[i][1]))) text.append( result[&#39;result&#39;][0]) #.replace(&quot;ï¼Œ&quot;, &quot;&quot;) text.append(&#39;\\n&#39;) idx = idx + 1 # print(format_time(timestamp_list[i][0]/ 1000), &quot;txt is &quot;, result[&#39;result&#39;][0]) with open(srt_file,&quot;w&quot;) as f: f.writelines(text) å­—å¹•ç”Ÿæˆçš„å…¶ä»–æ–¹å¼é€šè¿‡åŒé—¨é™æ³•è¿›è¡Œç«¯ç‚¹æ£€æµ‹åŒé—¨é™æ³•çš„åŸç†æ˜¯æµŠéŸ³çš„èƒ½é‡é«˜äºæ¸…éŸ³ï¼Œæ¸…éŸ³çš„è¿‡é›¶ç‡é«˜äºæ— å£°éƒ¨åˆ†ã€‚å› æ­¤ï¼Œå…¶æ ¸å¿ƒåœ¨äºï¼šå…ˆåˆ©ç”¨èƒ½é‡ï¼Œå°†æµŠéŸ³éƒ¨åˆ†åŒºåˆ†å‡ºæ¥ï¼Œå†åˆ©ç”¨è¿‡é›¶ç‡ï¼Œå°†æ¸…éŸ³ä¹Ÿæå–å‡ºæ¥ï¼Œå°±å®Œæˆäº†ç«¯ç‚¹æ£€æµ‹ã€‚ é€šè¿‡ SpeechRcognition è¿›è¡Œè¯­éŸ³è¯†åˆ«SpeechRcognition å¯ä»¥è¯´æ˜¯ä¸€æ¬¾è¯­éŸ³è¯†åˆ«é›†åˆå™¨ï¼Œå…±åŒ…å«äº†è°·æ­Œã€å¿…åº”ã€IBMç­‰ä¸ƒä¸ªè¯†åˆ«å™¨ï¼š recognize_bing()ï¼šMicrosoft Bing Speech recognize_google()ï¼š Google Web Speech API recognize_google_cloud()ï¼šGoogle Cloud Speech - requires installation of the google-cloud-speech package recognize_houndify()ï¼š Houndify by SoundHound recognize_ibm()ï¼šIBM Speech to Text recognize_sphinx()ï¼šCMU Sphinx - requires installing PocketSphinx recognize_wit()ï¼šWit.ai åŸºæœ¬ä½¿ç”¨æ–¹æ³•å¦‚ä¸‹ï¼š import speech_recognition as sr r = sr.Recognizer() test = sr.AudioFile(r&#39;C:\\Users\\Lenovo\\Desktop\\test.wav&#39;) with test as source: audio = r.record(source) r.recognize_google(audio, language=&#39;zh-CN&#39;, show_all= True) ä½†å¥½åƒéœ€è¦ç¿»å¢™æ‰èƒ½ç”¨â€¦ é€šè¿‡autosubåŒ…ç›´æ¥ç”Ÿæˆå­—å¹•æ–‡ä»¶autosubæ˜¯ä¸€ä¸ªç›´æ¥å¯ä»¥ç”Ÿæˆå­—å¹•æ–‡ä»¶çš„pythonåº“ï¼Œè¯¦ç»†å¯çœ‹ä¸­æ–‡æ•™ç¨‹.html)åŸºæœ¬ç”¨æ³•å¦‚ä¸‹ï¼š autosub -S zh-CN -D zh-CN [ä½ çš„è§†é¢‘/éŸ³é¢‘æ–‡ä»¶å] ä¸è¿‡è¿™ç§æ–¹æ³•ä¹Ÿéœ€è¦ç¿»å¢™ï¼Œæˆ‘å°è¯•äº†æ›´æ”¹proxyä¹Ÿæ²¡ä»€ä¹ˆæ•ˆæœâ€¦ æ€»ç»“æ€»ä½“è€Œè¨€ï¼Œå­—å¹•ç”Ÿæˆéœ€è¦çš„ä¸¤ä¸ªæŠ€æœ¯å—ï¼Œå„æœ‰å¤šç§å®ç°æ–¹æ³•ï¼Œè€Œæˆ‘æœ€ç»ˆé€‰å–çš„pydubåŠ baidu-aipæ˜¯ç›¸å¯¹ç®€å•å¹¶ä¸”æœ‰æ•ˆçš„ä¸€ç§ã€‚ä¸è¿‡å®æµ‹æ•ˆæœå¹¶æ²¡æœ‰è¾¾åˆ°æˆ‘çš„æœŸæœ›ï¼Œå› ä¸ºä¸€å¼€å§‹ç«¯ç‚¹æ£€æµ‹å°±ä¸æ˜¯ååˆ†å‡†ç¡®ï¼Œå¯¼è‡´åœ¨é”™è¯¯çš„å¥å­é‡Œä¸Šä¸‹æ–‡å…³ç³»ä¹Ÿä¸å¤ªå¯¹ï¼Œè¯­éŸ³è¯†åˆ«ä¹Ÿä¼šæœ‰åå·®äº†ã€‚æ›´è¿›ä¸€æ­¥çš„ç«¯ç‚¹æ£€æµ‹æ–¹æ³•è¿˜å¾—ç»¼åˆè€ƒè™‘èƒ½é‡å’Œè¿‡é›¶ç‡ï¼Œæœ€å¥½è¿˜è¦è‡ªå®šä¹‰åœ°åŠ ä¸Šå„ä¸ªå¥å­é•¿åº¦ä¸èƒ½ç›¸å·®å¤ªå¤§çš„é™åˆ¶ç­‰ç­‰ã€‚","categories":[],"tags":[{"name":"ç«¯ç‚¹æ£€æµ‹","slug":"ç«¯ç‚¹æ£€æµ‹","permalink":"http://weiquanfan.xyz/tags/ç«¯ç‚¹æ£€æµ‹/"},{"name":"è¯­éŸ³è¯†åˆ«","slug":"è¯­éŸ³è¯†åˆ«","permalink":"http://weiquanfan.xyz/tags/è¯­éŸ³è¯†åˆ«/"}]},{"title":"åŸºäºkerasçš„ç®€æ˜“è¯­éŸ³è¯†åˆ«","slug":"ASR-with-keras","date":"2020-06-20T07:13:59.000Z","updated":"2020-06-26T02:46:52.004Z","comments":true,"path":"2020/06/20/ASR-with-keras/","link":"","permalink":"http://weiquanfan.xyz/2020/06/20/ASR-with-keras/","excerpt":"","text":"ç®€ä»‹æœ€è¿‘å¿½ç„¶çœ‹åˆ°ä¸æ˜¯åŸºäºkaldiçš„ASRä»£ç ï¼Œå°è¯•äº†ä¸€ä¸‹å‘ç°æ•ˆæœè¿˜ä¸é”™ï¼Œæ¬ä¸Šæ¥è®°å½•ä¸€ä¸‹ã€‚ æºç åœ°å€ï¼š https://pan.baidu.com/s/1tFlZkMJmrMTD05cd_zxmAg æå–ç ï¼šndrr æ•°æ®é›†éœ€è¦è‡ªè¡Œä¸‹è½½ã€‚ æ•°æ®é›†æ•°æ®é›†ä½¿ç”¨çš„æ˜¯æ¸…åå¤§å­¦çš„thchs30ä¸­æ–‡æ•°æ®ï¼Œdataæ–‡ä»¶å¤¹ä¸­åŒ…å«ï¼ˆ.wavæ–‡ä»¶å’Œ.trnæ–‡ä»¶ï¼›trnæ–‡ä»¶é‡Œå­˜æ”¾çš„æ˜¯.wavæ–‡ä»¶çš„æ–‡å­—æè¿°:ç¬¬ä¸€è¡Œä¸ºè¯ï¼Œç¬¬äºŒè¡Œä¸ºæ‹¼éŸ³ï¼Œç¬¬ä¸‰è¡Œä¸ºéŸ³ç´ ï¼‰. æ¨¡å‹é¢„æµ‹å…ˆç›´æ¥è§£é‡Šæœ‰äº†è®­å¥½çš„æ¨¡å‹åå¦‚ä½•ä½¿ç”¨ï¼Œä»£ç å¦‚ä¸‹ï¼š # -*- coding: utf-8 -*- from keras.models import load_model from keras import backend as K import numpy as np import librosa from python_speech_features import mfcc import pickle import glob wavs = glob.glob(&#39;A2_8.wav&#39;) print(wavs) with open(&#39;dictionary.pkl&#39;, &#39;rb&#39;) as fr: [char2id, id2char, mfcc_mean, mfcc_std] = pickle.load(fr) mfcc_dim = 13 model = load_model(&#39;asr.h5&#39;) index = np.random.randint(len(wavs)) print(wavs[index]) ## è¯»å–æ•°æ®ï¼Œå¹¶å»é™¤æ‰æ²¡è¯´è¯çš„èµ·å§‹ç»“æŸæ—¶é—´ audio, sr = librosa.load(wavs[index]) energy = librosa.feature.rmse(audio) frames = np.nonzero(energy &gt;= np.max(energy) / 5) indices = librosa.core.frames_to_samples(frames)[1] audio = audio[indices[0]:indices[-1]] if indices.size else audio[0:0] X_data = mfcc(audio, sr, numcep=mfcc_dim, nfft=551) X_data = (X_data - mfcc_mean) / (mfcc_std + 1e-14) print(X_data.shape) pred = model.predict(np.expand_dims(X_data, axis=0)) pred_ids = K.eval(K.ctc_decode(pred, [X_data.shape[0]], greedy=False, beam_width=10, top_paths=1)[0][0]) pred_ids = pred_ids.flatten().tolist() print(&#39;&#39;.join([id2char[i] for i in pred_ids])) æ¨¡å‹è®­ç»ƒæ¨¡å‹é‡‡ç”¨äº† TDNN ç½‘ç»œç»“æ„ï¼Œå¹¶ç›´æ¥é€šè¿‡å­—ç¬¦çº§åˆ«æ¥é¢„æµ‹ï¼Œç›´æ¥æ ¹æ®å¸¸è§åº¦å°†å­—ç¬¦å¯¹åº”æˆæ•°å­—æ ‡ç­¾ã€‚æ•´ä¸ªæµç¨‹è€Œè¨€ï¼Œ å…ˆå°†ä¸€ä¸ªä¸ªè¯­éŸ³æ ·æœ¬å˜æˆMFCCç‰¹å¾ï¼Œå³ä¸€ä¸ªæ ·æœ¬çš„ç»´åº¦ä¸ºtime*num_MFCCï¼Œtimeç»´åº¦å°†è¢«è¡¥é½åˆ°batché‡Œæœ€é•¿çš„timeã€‚ å°†æ‰¹é‡æ ·æœ¬é€å…¥ç½‘ç»œï¼Œé‡‡ç”¨1då·ç§¯ï¼Œä»…åœ¨æ—¶é—´è½´ä¸Šå·ç§¯ï¼Œä¸€ä¸ªæ ·æœ¬çš„è¾“å‡ºç»´åº¦ä¸ºtime*(num_words+1)ï¼ŒåŠ çš„1ä»£è¡¨é¢„æµ‹äº†ç©ºçŠ¶æ€ã€‚ é€šè¿‡CTC Lossè®¡ç®—æŸå¤± # -*- coding: utf-8 -*- #å¯¼å…¥ç›¸å…³çš„åº“ from keras.models import Model from keras.layers import Input, Activation, Conv1D, Lambda, Add, Multiply, BatchNormalization from keras.optimizers import Adam, SGD from keras import backend as K from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau import numpy as np import matplotlib.pyplot as plt from mpl_toolkits.axes_grid1 import make_axes_locatable import random import pickle import glob from tqdm import tqdm import os from python_speech_features import mfcc import scipy.io.wavfile as wav import librosa from IPython.display import Audio #è¯»å–æ•°æ®é›†æ–‡ä»¶ text_paths = glob.glob(&#39;data/*.trn&#39;) total = len(text_paths) print(total) with open(text_paths[0], &#39;r&#39;, encoding=&#39;utf8&#39;) as fr: lines = fr.readlines() print(lines) #æ•°æ®é›†æ–‡ä»¶trnå†…å®¹è¯»å–ä¿å­˜åˆ°æ•°ç»„ä¸­ texts = [] paths = [] for path in text_paths: with open(path, &#39;r&#39;, encoding=&#39;utf8&#39;) as fr: lines = fr.readlines() line = lines[0].strip(&#39;\\n&#39;).replace(&#39; &#39;, &#39;&#39;) texts.append(line) paths.append(path.rstrip(&#39;.trn&#39;)) print(paths[0], texts[0]) #å®šä¹‰mfccæ•° mfcc_dim = 13 #æ ¹æ®æ•°æ®é›†æ ‡å®šçš„éŸ³ç´ è¯»å…¥ def load_and_trim(path): audio, sr = librosa.load(path) energy = librosa.feature.rmse(audio) frames = np.nonzero(energy &gt;= np.max(energy) / 5) indices = librosa.core.frames_to_samples(frames)[1] audio = audio[indices[0]:indices[-1]] if indices.size else audio[0:0] return audio, sr #å¯è§†åŒ–ï¼Œæ˜¾ç¤ºè¯­éŸ³æ–‡ä»¶çš„MFCCå›¾ def visualize(index): path = paths[index] text = texts[index] print(&#39;Audio Text:&#39;, text) audio, sr = load_and_trim(path) plt.figure(figsize=(12, 3)) plt.plot(np.arange(len(audio)), audio) plt.title(&#39;Raw Audio Signal&#39;) plt.xlabel(&#39;Time&#39;) plt.ylabel(&#39;Audio Amplitude&#39;) plt.show() feature = mfcc(audio, sr, numcep=mfcc_dim, nfft=551) print(&#39;Shape of MFCC:&#39;, feature.shape) fig = plt.figure(figsize=(12, 5)) ax = fig.add_subplot(111) im = ax.imshow(feature, cmap=plt.cm.jet, aspect=&#39;auto&#39;) plt.title(&#39;Normalized MFCC&#39;) plt.ylabel(&#39;Time&#39;) plt.xlabel(&#39;MFCC Coefficient&#39;) plt.colorbar(im, cax=make_axes_locatable(ax).append_axes(&#39;right&#39;, size=&#39;5%&#39;, pad=0.05)) ax.set_xticks(np.arange(0, 13, 2), minor=False); plt.show() return path Audio(visualize(0)) #æå–éŸ³é¢‘ç‰¹å¾å¹¶å­˜å‚¨ features = [] for i in tqdm(range(total)): path = paths[i] audio, sr = load_and_trim(path) features.append(mfcc(audio, sr, numcep=mfcc_dim, nfft=551)) print(len(features), features[0].shape) #éšæœºé€‰æ‹©100ä¸ªæ•°æ®é›† samples = random.sample(features, 100) samples = np.vstack(samples) #å¹³å‡MFCCçš„å€¼ä¸ºäº†å½’ä¸€åŒ–å¤„ç† mfcc_mean = np.mean(samples, axis=0) #è®¡ç®—æ ‡å‡†å·®ä¸ºäº†å½’ä¸€åŒ– mfcc_std = np.std(samples, axis=0) print(mfcc_mean) print(mfcc_std) #å½’ä¸€åŒ–ç‰¹å¾ features = [(feature - mfcc_mean) / (mfcc_std + 1e-14) for feature in features] #å°†æ•°æ®é›†è¯»å…¥çš„æ ‡ç­¾å’Œå¯¹åº”idå­˜å‚¨åˆ—è¡¨ chars = {} for text in texts: for c in text: chars[c] = chars.get(c, 0) + 1 chars = sorted(chars.items(), key=lambda x: x[1], reverse=True) chars = [char[0] for char in chars] print(len(chars), chars[:100]) char2id = {c: i for i, c in enumerate(chars)} id2char = {i: c for i, c in enumerate(chars)} data_index = np.arange(total) np.random.shuffle(data_index) train_size = int(0.9 * total) test_size = total - train_size train_index = data_index[:train_size] test_index = data_index[train_size:] #ç¥ç»ç½‘ç»œè¾“å…¥å’Œè¾“å‡ºX,Yçš„è¯»å…¥æ•°æ®é›†ç‰¹å¾ X_train = [features[i] for i in train_index] Y_train = [texts[i] for i in train_index] X_test = [features[i] for i in test_index] Y_test = [texts[i] for i in test_index] batch_size = 16 #å®šä¹‰è®­ç»ƒæ‰¹æ¬¡çš„äº§ç”Ÿï¼Œä¸€æ¬¡è®­ç»ƒ16ä¸ª def batch_generator(x, y, batch_size=batch_size): offset = 0 while True: offset += batch_size if offset == batch_size or offset &gt;= len(x): data_index = np.arange(len(x)) np.random.shuffle(data_index) x = [x[i] for i in data_index] y = [y[i] for i in data_index] offset = batch_size X_data = x[offset - batch_size: offset] Y_data = y[offset - batch_size: offset] X_maxlen = max([X_data[i].shape[0] for i in range(batch_size)]) Y_maxlen = max([len(Y_data[i]) for i in range(batch_size)]) X_batch = np.zeros([batch_size, X_maxlen, mfcc_dim]) Y_batch = np.ones([batch_size, Y_maxlen]) * len(char2id) X_length = np.zeros([batch_size, 1], dtype=&#39;int32&#39;) Y_length = np.zeros([batch_size, 1], dtype=&#39;int32&#39;) for i in range(batch_size): X_length[i, 0] = X_data[i].shape[0] X_batch[i, :X_length[i, 0], :] = X_data[i] Y_length[i, 0] = len(Y_data[i]) Y_batch[i, :Y_length[i, 0]] = [char2id[c] for c in Y_data[i]] inputs = {&#39;X&#39;: X_batch, &#39;Y&#39;: Y_batch, &#39;X_length&#39;: X_length, &#39;Y_length&#39;: Y_length} outputs = {&#39;ctc&#39;: np.zeros([batch_size])} yield (inputs, outputs) epochs = 50 num_blocks = 3 filters = 128 X = Input(shape=(None, mfcc_dim,), dtype=&#39;float32&#39;, name=&#39;X&#39;) Y = Input(shape=(None,), dtype=&#39;float32&#39;, name=&#39;Y&#39;) X_length = Input(shape=(1,), dtype=&#39;int32&#39;, name=&#39;X_length&#39;) Y_length = Input(shape=(1,), dtype=&#39;int32&#39;, name=&#39;Y_length&#39;) #å·ç§¯1å±‚ # ä¸€ç»´å·ç§¯ï¼Œé»˜è®¤channels_lastï¼Œå³é€šé“ç»´(MFCCç‰¹å¾ç»´)æ”¾æœ€åï¼Œå¯¹æ—¶é—´ç»´è¿›è¡Œå·ç§¯ def conv1d(inputs, filters, kernel_size, dilation_rate): return Conv1D(filters=filters, kernel_size=kernel_size, strides=1, padding=&#39;causal&#39;, activation=None, dilation_rate=dilation_rate)(inputs) #æ ‡å‡†åŒ–å‡½æ•° def batchnorm(inputs): return BatchNormalization()(inputs) #æ¿€æ´»å±‚å‡½æ•° def activation(inputs, activation): return Activation(activation)(inputs) #å…¨è¿æ¥å±‚å‡½æ•° def res_block(inputs, filters, kernel_size, dilation_rate): hf = activation(batchnorm(conv1d(inputs, filters, kernel_size, dilation_rate)), &#39;tanh&#39;) hg = activation(batchnorm(conv1d(inputs, filters, kernel_size, dilation_rate)), &#39;sigmoid&#39;) h0 = Multiply()([hf, hg]) ha = activation(batchnorm(conv1d(h0, filters, 1, 1)), &#39;tanh&#39;) hs = activation(batchnorm(conv1d(h0, filters, 1, 1)), &#39;tanh&#39;) return Add()([ha, inputs]), hs h0 = activation(batchnorm(conv1d(X, filters, 1, 1)), &#39;tanh&#39;) shortcut = [] for i in range(num_blocks): for r in [1, 2, 4, 8, 16]: h0, s = res_block(h0, filters, 7, r) shortcut.append(s) h1 = activation(Add()(shortcut), &#39;relu&#39;) h1 = activation(batchnorm(conv1d(h1, filters, 1, 1)), &#39;relu&#39;) #softmaxæŸå¤±å‡½æ•°è¾“å‡ºç»“æœ Y_pred = activation(batchnorm(conv1d(h1, len(char2id) + 1, 1, 1)), &#39;softmax&#39;) sub_model = Model(inputs=X, outputs=Y_pred) #è®¡ç®—æŸå¤±å‡½æ•° def calc_ctc_loss(args): y, yp, ypl, yl = args return K.ctc_batch_cost(y, yp, ypl, yl) ctc_loss = Lambda(calc_ctc_loss, output_shape=(1,), name=&#39;ctc&#39;)([Y, Y_pred, X_length, Y_length]) #åŠ è½½æ¨¡å‹è®­ç»ƒ model = Model(inputs=[X, Y, X_length, Y_length], outputs=ctc_loss) #å»ºç«‹ä¼˜åŒ–å™¨ optimizer = SGD(lr=0.02, momentum=0.9, nesterov=True, clipnorm=5) #æ¿€æ´»æ¨¡å‹å¼€å§‹è®¡ç®— model.compile(loss={&#39;ctc&#39;: lambda ctc_true, ctc_pred: ctc_pred}, optimizer=optimizer) checkpointer = ModelCheckpoint(filepath=&#39;asr.h5&#39;, verbose=0) lr_decay = ReduceLROnPlateau(monitor=&#39;loss&#39;, factor=0.2, patience=1, min_lr=0.000) #å¼€å§‹è®­ç»ƒ history = model.fit_generator( generator=batch_generator(X_train, Y_train), steps_per_epoch=len(X_train) // batch_size, epochs=epochs, validation_data=batch_generator(X_test, Y_test), validation_steps=len(X_test) // batch_size, callbacks=[checkpointer, lr_decay]) #ä¿å­˜æ¨¡å‹ sub_model.save(&#39;asr.h5&#39;) #å°†å­—ä¿å­˜åœ¨pl=pklä¸­ with open(&#39;dictionary.pkl&#39;, &#39;wb&#39;) as fw: pickle.dump([char2id, id2char, mfcc_mean, mfcc_std], fw) train_loss = history.history[&#39;loss&#39;] plt.plot(np.linspace(1, epochs, epochs), train_loss, label=&#39;train&#39;) plt.legend(loc=&#39;upper right&#39;) plt.xlabel(&#39;Epoch&#39;) plt.ylabel(&#39;Loss&#39;) plt.show() #ä¸‹é¢æ˜¯æ¨¡å‹çš„é¢„æµ‹æ•ˆæœï¼Œå¯è§main.py from keras.models import load_model import pickle with open(&#39;dictionary.pkl&#39;, &#39;rb&#39;) as fr: [char2id, id2char, mfcc_mean, mfcc_std] = pickle.load(fr) sub_model = load_model(&#39;asr.h5&#39;) def random_predict(x, y): index = np.random.randint(len(x)) feature = x[index] text = y[index] pred = sub_model.predict(np.expand_dims(feature, axis=0)) pred_ids = K.eval(K.ctc_decode(pred, [feature.shape[0]], greedy=False, beam_width=10, top_paths=1)[0][0]) pred_ids = pred_ids.flatten().tolist() print(&#39;True transcription:\\n-- &#39;, text, &#39;\\n&#39;) print(&#39;Predicted transcription:\\n-- &#39; + &#39;&#39;.join([id2char[i] for i in pred_ids]), &#39;\\n&#39;) random_predict(X_train, Y_train) random_predict(X_test, Y_test) æ€»ç»“å¯¹æ¯”å…¶ä»–çš„åˆ†ç±»ä»»åŠ¡ï¼Œè¯­éŸ³è¯†åˆ«å¤šäº†ä¸ªè§£ç è¿‡ç¨‹ï¼Œè¿™ä¹Ÿå¯¼è‡´äº†ç›®å‰åœ¨å¸¸è§çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­è¿˜æ²¡æœ‰å¾ˆå¥½çš„ASRæ¡†æ¶ï¼Œç›®å‰è€Œè¨€ï¼ŒCTCçš„åº”ç”¨ä¹Ÿå¯¼è‡´å‡ºç°äº†ä¸€äº›å®Œå…¨ç«¯åˆ°ç«¯çš„ASRç³»ç»Ÿï¼Œç›¸ä¿¡ä»¥åè¿™ä¹Ÿä¼šæ˜¯ä¸ªå¤§è¶‹åŠ¿ã€‚","categories":[{"name":"è¯­éŸ³è¯†åˆ«","slug":"è¯­éŸ³è¯†åˆ«","permalink":"http://weiquanfan.xyz/categories/è¯­éŸ³è¯†åˆ«/"}],"tags":[{"name":"è¯­éŸ³è¯†åˆ«","slug":"è¯­éŸ³è¯†åˆ«","permalink":"http://weiquanfan.xyz/tags/è¯­éŸ³è¯†åˆ«/"}]},{"title":"ä½¿ç”¨QT designerã€pythonæ­å»ºç•Œé¢ç¨‹åº","slug":"QT","date":"2020-06-10T06:49:28.000Z","updated":"2020-06-20T07:08:22.853Z","comments":true,"path":"2020/06/10/QT/","link":"","permalink":"http://weiquanfan.xyz/2020/06/10/QT/","excerpt":"","text":"å‰è¨€PyQt æ˜¯Pythonè¯­è¨€çš„GUIç¼–ç¨‹è§£å†³æ–¹æ¡ˆä¹‹ä¸€ï¼Œæ˜¯ç±»ä¼¼äº Tkinter çš„ä¸€ä¸ªé«˜çº§åº“ã€‚ ä¸ºäº†æ›´å¥½çš„è¾…åŠ©PyQtç•Œé¢çš„æ­å»ºï¼Œå¯ä»¥é€šè¿‡Qt Designerå®ŒæˆGUIç•Œé¢è®¾è®¡ã€‚ ä½¿ç”¨Qt Designerå¯ä»¥é€šè¿‡æ‹–æ‹½ã€ç‚¹å‡»å®ŒæˆGUIç•Œé¢è®¾è®¡ï¼Œå¹¶ä¸”è®¾è®¡å®Œæˆåç”Ÿæˆçš„.uiç¨‹åºå¯ä»¥é€šè¿‡ pyuic5 å‘½ä»¤ç›´æ¥è½¬æ¢æˆ.pyæ–‡ä»¶ä»¥ä¾›pythonç¨‹åºè°ƒç”¨ã€‚ æ­å»ºå®Œç•Œé¢å¹¶å†™å¥½é€»è¾‘åï¼Œè¿˜å¯é€šè¿‡ pyinstaller å°†.pyæ–‡ä»¶å°è£…æˆ.exeæ–‡ä»¶ï¼Œä»¥ä¾›æ²¡æœ‰pythonè§£é‡Šå™¨çš„ç”¨æˆ·ä½¿ç”¨ã€‚ æœ¬æ–‡ä»¥æ­å»ºæ ‡æ³¨å·¥å…·ç•Œé¢ç¨‹åºä¸ºä¾‹ã€‚ é¢„å®‰è£…çš„è½¯ä»¶ä¸åº“ Qt Designer: pip install â€”pre pyqt5-tools~=5.11ï¼ˆä½äº\\Python36\\Lib\\site-packages\\pyqt5_tools\\designer.exeï¼Œä¹Ÿå¯é€šè¿‡è¿™é‡Œä¸‹è½½ï¼‰ PyQt5: pip install PyQt5 pip install pyinstaller Qt Designer çš„ç•Œé¢è®¾è®¡ Qt Designer çš„ç•Œé¢ä¸»è¦åˆ†ä¸ºå››å¤§åŒºï¼šé¡¹ç›®åŒºã€æ§ä»¶åŒºã€ç¼–è¾‘åŒºã€å±æ€§åŒºã€‚ å…·ä½“è€Œè¨€ï¼Œå°±æ˜¯åœ¨ã€æ§ä»¶åŒºã€‘é‡Œç‚¹å‡»æ·»åŠ éœ€è¦çš„æ§ä»¶ï¼Œè¿™äº›æ§ä»¶çš„æ•ˆæœä¼šåœ¨ã€ç¼–è¾‘åŒºã€‘é‡Œå®æ—¶æ˜¾ç¤ºï¼Œå¹¶åœ¨ã€å±æ€§åŒºã€‘è¿™äº›æ§ä»¶çš„å±æ€§ï¼Œã€é¡¹ç›®åŒºã€‘ç”¨äºæ˜¾ç¤ºæ§ä»¶é—´çš„å±‚çº§å…³ç³»ã€‚ åœ¨æ–°å»ºä¸€ä¸ªçª—å£åï¼Œä¸€èˆ¬éœ€è¦é€šè¿‡ Container ç¡®å®šå¤–éƒ¨è½®å»“ï¼Œå¯é€‰ç”¨å¸¸è§çš„ Frame æ§ä»¶ï¼Œå†åœ¨ Frame é‡Œè¾¹é€‰ç”¨ Layouts æ¥è§„èŒƒåç»­æ§ä»¶çš„æ’åˆ—æ ·å¼ï¼Œå¸¸ç”¨æ°´å¹³æˆ–å‚ç›´æ’åˆ—ï¼Œæœ€åå†é€‰ç”¨å…·ä½“éƒ¨ä»¶å¾€é‡Œè¾¹å¡«å……ã€‚ å¸¸ç”¨çš„æ§ä»¶æœ‰å„ç§Buttonï¼ˆæŒ‰é’®ï¼‰ã€Labelï¼ˆé™æ€æ˜¾ç¤ºæ–‡æœ¬æ¡†ï¼‰ã€Text Editï¼ˆè¾“å…¥è¾“å‡ºæ–‡æœ¬æ¡†ï¼‰ã€listWidgetï¼ˆåˆ—è¡¨æ˜¾ç¤ºæ¡†ï¼‰ã€Check Boxï¼ˆé€‰ä¸­æ¡†ï¼‰ã€å„ç§Sliderï¼ˆæ»‘åŠ¨æ¡ï¼‰ç­‰ã€‚ æ¯ä¸€ä¸ªç»„ä»¶éƒ½æœ‰å¯è®¾ç½®çš„å±æ€§ï¼Œæœ€é‡è¦çš„é€šç”¨å±æ€§æœ‰ objectName ï¼ˆç”¨äºåœ¨åç»­é€»è¾‘ç¼–å†™æ—¶æŒ‡æ˜æ—¶å“ªä¸ªæ§ä»¶ï¼‰ï¼Œtext ï¼ˆç”¨äºåœ¨GUIé‡Œåœ¨æ§ä»¶ä¸Šæ˜¾ç¤ºï¼‰ï¼Œ geometry ï¼ˆç”¨äºè®¾ç½®æ§ä»¶ä½ç½®å’Œå°ºå¯¸ï¼Œä½†æ§ä»¶ä½äºLayerä¸­æ—¶å°±ä¸å¯è®¾ç½®äº†ï¼‰ã€‚ è®¾è®¡å¥½ç•Œé¢ä¹‹åä¿å­˜å¯ä»¥ç”Ÿæˆmy_win.uiæ–‡ä»¶ï¼Œå®ƒå¯ä»¥ç›´æ¥åœ¨pythonä»£ç é‡Œè¢«åŠ è½½ä½¿ç”¨ï¼Œä½†ä¸ºäº†åœ¨ä»£ç é‡Œè¿›ä¸€æ­¥è°ƒç”¨ä¿®æ”¹ç­‰ï¼Œæ›´å¥½çš„æ–¹æ³•æ˜¯å°†.uiæ–‡ä»¶è½¬æ¢æˆç›¸åº”çš„.pyæ–‡ä»¶ã€‚è¿™éœ€è¦å€ŸåŠ© \\Python36\\Scripts\\pyuic5.exeå·¥å…·ã€‚ pyuic5 -o my_win.py my_win.ui Qt é€»è¾‘ç¼–å†™å¾ˆå¤šæ§ä»¶éƒ½å¯ä»¥é€šè¿‡ç‚¹å‡»ï¼ˆæˆ–å…¶ä»–æ“ä½œï¼‰è§¦å‘äº‹ä»¶ï¼Œäº‹ä»¶å“åº”å¯è‡ªç”±ç¼–å†™ï¼Œé€šè¿‡ connect å‡½æ•°ç»‘å®šã€‚ #!/usr/bin/env python3 # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Sun June 12 12:06:21 2020 @author: weiquan fan &quot;&quot;&quot; import sys, os from PyQt5.QtWidgets import QApplication, QMainWindow, QMessageBox, QCompleter, QFileDialog from PyQt5.QtMultimedia import QMediaContent, QMediaPlayer from PyQt5.QtCore import pyqtSignal, QEvent from PyQt5.Qt import QUrl from my_win import Ui_MainWindow import csv root_path_metadata = &quot;./data/&quot; if not os.path.exists(root_path_metadata): os.makedirs(root_path_metadata) class mainWin(QMainWindow, Ui_MainWindow): doubleClicked_speaker = pyqtSignal() doubleClicked_dialog = pyqtSignal() def __init__(self, parent=None): super(mainWin, self).__init__(parent) self.setupUi(self) ## emotion self.refresh_1() self.radioButton.clicked.connect(self.showPos) self.radioButton_2.clicked.connect(self.showNeu) self.radioButton_3.clicked.connect(self.showNeg) ## DA self.refresh_2() ## dialog identity self.refresh_3() self.frame_9.setHidden(True) self.checkBox_5.stateChanged.connect(self.use_subsysdem3) self.radioButton_5.clicked.connect(self.personA) self.radioButton_4.clicked.connect(self.personB) ## save buttons self.refresh_save() self.btn_save.clicked.connect(self.save_data) self.btn_save_2.clicked.connect(self.save_dialog_data) ## history self.list_speaker = [] self.list_dialog = [] self.lineEdit_speaker.installEventFilter(self) self.lineEdit.installEventFilter(self) self.doubleClicked_speaker.connect(self.completer_name_speaker) self.doubleClicked_dialog.connect(self.completer_name_dialog) ## video player self.player = QMediaPlayer() self.player.setVideoOutput(self.wgt_player) self.btn_open.clicked.connect(self.openVideoFile) self.btn_play_pause.clicked.connect(self.playPause) self.player.durationChanged.connect(self.getDuration) self.player.positionChanged.connect(self.getPosition) self.sld_duration.sliderMoved.connect(self.updatePosition) ## for opening video def openVideoFile(self): name = QFileDialog.getOpenFileName()[0] self.lineEdit.setText(name.split(&#39;/&#39;)[-1]) self.player.setMedia(QMediaContent(QUrl.fromLocalFile(name))) # self.player.setMedia(QMediaContent(QFileDialog.getOpenFileUrl()[0])) self.player.play() def playPause(self): if self.player.state()==1: self.player.pause() else: self.player.play() def getDuration(self, d): self.sld_duration.setRange(0, d) self.sld_duration.setEnabled(True) self.displayTime(d) def getPosition(self, p): self.sld_duration.setValue(p) self.displayTime(p) def displayTime(self, ms): minutes = int(ms/60000) seconds = int((ms-minutes*60000)/1000) dur_ms = self.sld_duration.maximum() dur_min = int(dur_ms/60000) dur_sec = int((dur_ms-dur_min*60000)/1000) self.lab_duration.setText(&#39;{:0&gt;2d}:{:0&gt;2d} / {:0&gt;2d}:{:0&gt;2d}&#39;.format(minutes, seconds, dur_min, dur_sec)) def updatePosition(self, v): self.player.setPosition(v) self.displayTime(self.sld_duration.maximum()-v) ## for history def eventFilter(self, widget, event): if widget == self.lineEdit_speaker: if event.type() == QEvent.MouseButtonDblClick: self.doubleClicked_speaker.emit() elif widget == self.lineEdit: if event.type() == QEvent.MouseButtonDblClick: self.doubleClicked_dialog.emit() return super().eventFilter(widget, event) def completer_name_dialog(self): self.completer = QCompleter(self.list_dialog) self.lineEdit.setCompleter(self.completer) self.completer.setCompletionMode(QCompleter.UnfilteredPopupCompletion) self.completer.complete() self.completer.popup() def completer_name_speaker(self): self.completer = QCompleter(self.list_speaker) self.lineEdit_speaker.setCompleter(self.completer) self.completer.setCompletionMode(QCompleter.UnfilteredPopupCompletion) self.completer.complete() self.completer.popup() ## for label 1 def showPos(self): self.listWidget.clear() self.listWidget.addItem(&quot;é«˜å…´&quot;) self.listWidget.addItem(&quot;å…´å¥‹&quot;) self.listWidget.addItem(&quot;è‡ªè±ª&quot;) self.listWidget.addItem(&quot;æ»¡è¶³&quot;) self.listWidget.addItem(&quot;æ„Ÿæ¿€&quot;) self.listWidget.addItem(&quot;è‡ªä¿¡&quot;) self.listWidget.addItem(&quot;è½»æ¾&quot;) self.listWidget.addItem(&quot;ç¾¡æ…•&quot;) def showNeg(self): self.listWidget.clear() self.listWidget.addItem(&quot;ç”Ÿæ°”&quot;) self.listWidget.addItem(&quot;ä¼¤å¿ƒ&quot;) self.listWidget.addItem(&quot;å®³æ€•&quot;) self.listWidget.addItem(&quot;çƒ¦æ¼&quot;) self.listWidget.addItem(&quot;å­¤ç‹¬&quot;) self.listWidget.addItem(&quot;ç¾æ„§&quot;) self.listWidget.addItem(&quot;æ¶å¿ƒ&quot;) self.listWidget.addItem(&quot;å¤±æœ›&quot;) self.listWidget.addItem(&quot;éƒé—·&quot;) self.listWidget.addItem(&quot;ä¸å®‰&quot;) self.listWidget.addItem(&quot;ç´§å¼ &quot;) self.listWidget.addItem(&quot;æ— å¥ˆ&quot;) self.listWidget.addItem(&quot;çº ç»“&quot;) def showNeu(self): self.listWidget.clear() self.listWidget.addItem(&quot;å…±æƒ…&quot;) self.listWidget.addItem(&quot;å¹³é™&quot;) ## for label 3 def use_subsysdem3(self): if self.checkBox_5.isChecked(): self.frame_9.setHidden(False) else: self.refresh_3() self.frame_9.setHidden(True) def personA(self): self.frame_3.setHidden(False) self.frame_8.setHidden(True) def personB(self): self.frame_3.setHidden(True) self.frame_8.setHidden(False) def refresh_gui(self): self.refresh_1() self.refresh_2() self.refresh_3() self.refresh_save() def refresh_1(self): self.buttonGroup_2.setExclusive(False) self.radioButton.setChecked(False) self.radioButton_2.setChecked(False) self.radioButton_3.setChecked(False) self.buttonGroup_2.setExclusive(True) self.listWidget.clear() self.checkBox_3.setChecked(True) self.checkBox_2.setChecked(True) self.checkBox.setChecked(True) self.checkBox_4.setChecked(False) def refresh_2(self): self.listWidget_2.clear() self.listWidget_2.addItem(&quot;é—®å€™&quot;) self.listWidget_2.addItem(&quot;æé—®&quot;) self.listWidget_2.addItem(&quot;å›ç­”&quot;) self.listWidget_2.addItem(&quot;é™ˆè¿°è§‚ç‚¹&quot;) self.listWidget_2.addItem(&quot;é™ˆè¿°éè§‚ç‚¹&quot;) self.listWidget_2.addItem(&quot;é“æ­‰&quot;) self.listWidget_2.addItem(&quot;å‘½ä»¤&quot;) self.listWidget_2.addItem(&quot;èµåŒ&quot;) self.listWidget_2.addItem(&quot;åå¯¹&quot;) self.listWidget_2.addItem(&quot;è¡¨è¾¾çŸ¥ä¼š&quot;) self.listWidget_2.addItem(&quot;æ¬£èµ&quot;) self.listWidget_2.addItem(&quot;å¹è¯&quot;) self.listWidget_2.addItem(&quot;ç»“æŸå¯¹è¯&quot;) self.listWidget_2.addItem(&quot;å¼•ç”¨&quot;) self.listWidget_2.addItem(&quot;å…¶ä»–&quot;) def refresh_3(self): # self.checkBox_5.setChecked(False) self.buttonGroup.setExclusive(False) self.radioButton_4.setChecked(False) self.radioButton_5.setChecked(False) self.buttonGroup.setExclusive(True) self.buttonGroup_3.setExclusive(False) self.radioButton_6.setChecked(False) self.radioButton_7.setChecked(False) self.radioButton_8.setChecked(False) self.radioButton_9.setChecked(False) self.radioButton_10.setChecked(False) self.buttonGroup_3.setExclusive(True) # self.frame_9.setHidden(True) self.frame_3.setHidden(True) self.frame_8.setHidden(True) def refresh_save(self): self.lineEdit_2.setText(&#39;0&#39;) self.lineEdit_3.setText(&#39;0&#39;) self.lineEdit_4.setText(&#39;0&#39;) self.lineEdit_5.setText(&#39;0&#39;) self.lineEdit_6.setText(&#39;0&#39;) self.lineEdit_7.setText(&#39;0&#39;) self.lineEdit_speaker.setText(&#39;&#39;) def save_data(self): ## check many things try: self.label_val = self.buttonGroup_2.checkedButton().text() self.label_emotion = self.listWidget.selectedItems()[0].text() except: QMessageBox.information(self,&#39;æç¤º&#39;,&#39;è¯·é€‰æ‹©å…·ä½“æƒ…æ„Ÿåå†é‡æ–°ä¿å­˜&#39;, QMessageBox.Yes) return False try: self.label_da = self.listWidget_2.selectedItems()[0].text() except: QMessageBox.information(self,&#39;æç¤º&#39;,&#39;è¯·é€‰æ‹©å¯¹è¯çŠ¶æ€åå†é‡æ–°ä¿å­˜&#39;, QMessageBox.Yes) return False self.label_iden_isok = self.checkBox_5.isChecked() if self.label_iden_isok: if self.buttonGroup.checkedId() == -1: QMessageBox.information(self,&#39;æç¤º&#39;,&#39;æ‚¨å·²å‹¾é€‰è¯¥å¯¹è¯èº«ä»½å¯æ ‡ï¼Œè¯·é€‰æ‹©è¯´è¯äººèº«ä»½åå†é‡æ–°ä¿å­˜&#39;, QMessageBox.Yes) return False else: self.label_iden = self.buttonGroup.checkedButton().text() if self.label_iden == &quot;å€¾è¯‰è€…&quot;: self.label_reason = self.lineEdit_reason.text() self.label_result = self.lineEdit_result.text() self.label_reaction = &quot;ç©º&quot; else: self.label_reason = &quot;ç©º&quot; self.label_result = &quot;ç©º&quot; try: self.label_reaction = self.buttonGroup_3.checkedButton().text() except: QMessageBox.information(self,&#39;æç¤º&#39;,&#39;æ‚¨å·²å‹¾é€‰è¯¥å¯¹è¯èº«ä»½å¯æ ‡ï¼Œè¯·é€‰æ‹©å€¾è¯‰è€…ååº”åå†é‡æ–°ä¿å­˜&#39;, QMessageBox.Yes) return False else: self.label_iden = &quot;ä¸å¯æ ‡&quot; self.label_reason = &quot;ä¸å¯æ ‡&quot; self.label_result = &quot;ä¸å¯æ ‡&quot; self.label_reaction = &quot;ä¸å¯æ ‡&quot; if self.lineEdit_speaker.text() == &#39;&#39;: QMessageBox.information(self,&#39;æç¤º&#39;,&#39;è¯·è¾“å…¥è¯´è¯äººå§“å&#39;, QMessageBox.Yes) return False else: self.name_speaker = self.lineEdit_speaker.text() try: self.start_time = &quot;{}:{}:{}&quot;.format(int(self.lineEdit_2.text()), int(self.lineEdit_3.text()), int(self.lineEdit_4.text())) self.end_time = &quot;{}:{}:{}&quot;.format(int(self.lineEdit_5.text()), int(self.lineEdit_6.text()), int(self.lineEdit_7.text())) except: QMessageBox.information(self,&#39;æç¤º&#39;,&#39;æ—¶é—´åº”è¾“å…¥æ•´æ•°&#39;, QMessageBox.Yes) return False if self.lineEdit.text() == &#39;&#39;: QMessageBox.information(self,&#39;æç¤º&#39;,&#39;è¯·è¾“å…¥è§†é¢‘åå­—&#39;, QMessageBox.Yes) return False else: self.name_dialog = self.lineEdit.text() if not os.path.exists(root_path_metadata+self.name_dialog+&#39;.csv&#39;): with open(root_path_metadata+self.name_dialog+&#39;.csv&#39;,&quot;a&quot;,newline=&#39;&#39;,encoding=&#39;utf_8_sig&#39;) as csvfile: writer = csv.writer(csvfile, delimiter=&#39;,&#39;) writer.writerow([&#39;è§†é¢‘åå­—&#39;, &#39;è¯´è¯è€…å§“å&#39;, &#39;èµ·å§‹æ—¶é—´&#39;, &#39;ç»“æŸæ—¶é—´&#39;, &#39;æƒ…ç»ªï¼ˆç²—ç²’åº¦ï¼‰&#39;, &#39;æƒ…ç»ªï¼ˆç»†ç²’åº¦ï¼‰&#39;, &#39;æ˜¯å¦åŸºäºéŸ³é¢‘&#39;, &#39;æ˜¯å¦åŸºäºè§†é¢‘&#39;, &#39;æ˜¯å¦åŸºäºæ–‡æœ¬&#39;, &#39;æ˜¯å¦éš¾ä»¥æ ‡æ³¨&#39;, &#39;å¯¹è¯çŠ¶æ€&#39;, &#39;æ˜¯å¦å¯æ ‡å¯¹è¯èº«ä»½&#39;, &#39;è¯´è¯äººèº«ä»½&#39;, &#39;èµ·å› &#39;, &#39;ç»“æœ&#39;, &#39;å€¾è¯‰è€…ååº”&#39;]) ## save self.label_emotion_audio_based = self.checkBox_3.isChecked() self.label_emotion_video_based = self.checkBox_2.isChecked() self.label_emotion_text_based = self.checkBox.isChecked() self.label_emotion_hard = self.checkBox_4.isChecked() onelist = [self.name_dialog, self.name_speaker, self.start_time, self.end_time, self.label_val, self.label_emotion, self.label_emotion_audio_based, self.label_emotion_video_based, self.label_emotion_text_based, self.label_emotion_hard, self.label_da, self.label_iden_isok, self.label_iden, self.label_reason, self.label_result, self.label_reaction] with open(root_path_metadata+self.name_dialog+&#39;.csv&#39;,&quot;a&quot;,newline=&#39;&#39;,encoding=&#39;utf_8_sig&#39;) as csvfile: writer = csv.writer(csvfile, delimiter=&#39;,&#39;) writer.writerow(onelist) self.refresh_gui() self.list_dialog.append(self.name_dialog) self.list_speaker.append(self.name_speaker) self.list_dialog = list(set(self.list_dialog)) self.list_speaker = list(set(self.list_speaker)) # self.lineEdit.setCompleter(QCompleter(self.list_dialog)) # self.lineEdit_speaker.setCompleter(QCompleter(self.list_speaker)) return True def save_dialog_data(self): flag_save_success = self.save_data() if flag_save_success == False: return 0 QMessageBox.about(self,&#39;æç¤º&#39;,&#39;å¯¹è¯ä¿å­˜æˆåŠŸ&#39;) self.refresh_gui() self.lineEdit.setText(&#39;&#39;) self.lineEdit_reason.setText(&#39;&#39;) self.lineEdit_result.setText(&#39;&#39;) self.checkBox_5.setChecked(False) self.frame_9.setHidden(True) def del_last_data(self): try: with open(root_path_metadata+self.name_dialog+&#39;.csv&#39;,&quot;r&quot;,newline=&#39;&#39;,encoding=&#39;utf_8_sig&#39;) as csvfile: data = csvfile.readlines() del data[-1] with open(root_path_metadata+self.name_dialog+&#39;.csv&#39;,&quot;w&quot;,newline=&#39;&#39;,encoding=&#39;utf_8_sig&#39;) as csvfile: writer = csv.writer(csvfile, delimiter=&#39;,&#39;) for row in data: writer.writerow(row.strip().split(&#39;,&#39;)) # writer.writerows(data) QMessageBox.about(self,&#39;æç¤º&#39;,&#39;ä¸Šä¸€å¥çš„æ ‡æ³¨å·²åˆ é™¤&#39;) except: QMessageBox.information(self,&#39;æç¤º&#39;,&#39;è¯¥è§†é¢‘å°šæœªä¿å­˜ä»»ä½•æ•°æ®&#39;, QMessageBox.Yes) if __name__ == &#39;__main__&#39;: app = QApplication(sys.argv) main_win = mainWin() main_win.show() # main_win.showFullScreen() sys.exit(app.exec_()) å°è£…æˆå¯æ‰§è¡Œæ–‡ä»¶å¯¹äºç¼–å†™å¥½çš„.pyæ–‡ä»¶ï¼Œè‹¥æ˜¯éœ€è¦æ›´å¥½çš„ç»™æ²¡æœ‰pythonç¼–è¾‘å™¨çš„äººä½¿ç”¨ï¼Œåˆ™éœ€è¦å°è£…æˆ.exeæ–‡ä»¶ï¼Œè¿™å¯ä»¥é€šè¿‡ pyinstaller å‘½ä»¤æ¥å®Œæˆã€‚ pyinstaller -F biaozhu.py pyinstaller æœ‰ä¸¤ç§å¸¸è§çš„æ¨¡å¼ï¼š-F: å°‡ç¨‹å¼æ‰“åŒ…æˆå•ä¸€çš„æ‰§è¡Œæ–‡ä»¶(é€‚åˆæ¯”è¾ƒç®€å•çš„ä»£ç )-D: æ‰“åŒ…å¤šå€‹æ–‡ä»¶ï¼ŒexeåŠä¾èµ–çš„ä¸œè¥¿ä¼šä¸€èµ·æ”¾ç½®åœ¨distè³‡æ–™å¤¾é‡Œ(é€‚åˆæ¡†æ¶å½¢å¼çš„ç¨‹å¼) åœ¨æ‰“åŒ…è¿‡ç¨‹ä¸­ï¼ŒåŒ…å«å¦‚ä¸‹æ­¥éª¤ åœ¨è·¯å¾„ä¸‹ç”Ÿæˆäº†biaozhu.spec: åŒ…å«æ‰“åŒ…æ—¶ç›¸å…³çš„è®¾å®š å»ºç«‹build æ–‡ä»¶å¤¹ï¼Œæ”¾ç½®äº†logè®°å½•å’Œç›¸å…³æ–‡ä»¶ å»ºç«‹dist æ–‡ä»¶å¤¹ï¼Œæ”¾ç½®äº†å¯æ‰§è¡Œæ–‡ä»¶ï¼Œè‹¥æ˜¯ â€”F æ¨¡å¼ï¼Œåˆ™é‡Œè¾¹ä»…æœ‰ä¸€ä¸ª.exeæ–‡ä»¶ å¦å¤–ï¼Œè‹¥æ˜¯æ‰“åŒ…å¤±è´¥ï¼Œå¯ä»¥é€šè¿‡æ”¹å†™.specæ–‡ä»¶ï¼Œå†é€šè¿‡ pyinstaller -D XXX.spec é‡æ–°æ‰“åŒ…ã€‚ å¦‚æœæ˜¯åº“çš„ import é—®é¢˜ï¼Œå¯ä»¥é€šè¿‡ hiddenimport é‡Œæ”¾ç½®åº“åæ¥hiddenæ‰è¯¥é”™è¯¯ã€‚ æ€»ç»“ä»¥å‰åªçŸ¥é“ Tkinter å¯ä»¥æ¥å®ç° python çš„ç•Œé¢è®¾è®¡ï¼Œä½†æ„Ÿè§‰å¹¶ä¸é‚£ä¹ˆå‹å¥½ã€‚ è€Œè¿™æ¬¡å­¦ä¹ åˆ°çš„ PyQt ä»¥åŠç›¸åº”çš„ Qt designeråˆ™å¾ˆå¥½çš„è§£å†³äº†è¿™ä¸€é—®é¢˜ï¼Œå¯ä»¥é€šè¿‡æ‹‰æ‹½è¿›è¡Œå¸ƒå±€ï¼Œå°±åƒc++çš„SDLä¸€æ ·ã€‚å®Œæˆç•Œé¢è®¾è®¡åçš„é€»è¾‘ç¼–å†™æ‰æ˜¯æ›´è®©äººå¤´ç–¼çš„é—®é¢˜ï¼Œå®¹æ˜“äº§ç”Ÿå„ç§bugï¼Œåªèƒ½æ…¢æ…¢è°ƒã€‚ æœ€åå®Œæˆç¨‹åºä¹‹åè¿˜å¯ä»¥è½¬æˆ.exeæ–‡ä»¶ï¼Œä»è€Œå¯ä»¥ç›´æ¥ç»™åˆ«äººä½¿ç”¨ï¼Œè¿™ä¸ªæ˜¯æ„æ–™ä¹‹å¤–çš„æƒŠå–œã€‚","categories":[{"name":"ç•Œé¢","slug":"ç•Œé¢","permalink":"http://weiquanfan.xyz/categories/ç•Œé¢/"}],"tags":[{"name":"ç•Œé¢","slug":"ç•Œé¢","permalink":"http://weiquanfan.xyz/tags/ç•Œé¢/"}]},{"title":"æ·±åº¦å­¦ä¹ ä¸»æµæ¡†æ¶çš„ä»£ç å®ä¾‹","slug":"DL-Framework","date":"2020-05-27T14:57:23.000Z","updated":"2020-05-27T15:29:06.309Z","comments":true,"path":"2020/05/27/DL-Framework/","link":"","permalink":"http://weiquanfan.xyz/2020/05/27/DL-Framework/","excerpt":"","text":"å‰è¨€æ·±åº¦å­¦ä¹ æ¡†æ¶ä»ä¸€å¼€å§‹çš„ Theanoã€TensorFlowï¼Œåˆ°åæ¥å°è£…ç¨‹åº¦æ›´é«˜çš„Pytorchã€Kerasç­‰ï¼Œå±‚å‡ºä¸ç©·ã€‚æ­¤æ–‡é€šè¿‡ä¸€ä¸ªç®€å•çš„åˆ†ç±»ä»»åŠ¡ï¼Œç»¼åˆè¿›è¿™äº›æ¡†æ¶çš„ä»£ç ã€‚ä»£ç æ¥æºäºè«çƒ¦pythonã€‚ Theanofrom __future__ import print_function import numpy as np import theano import theano.tensor as T def compute_accuracy(y_target, y_predict): correct_prediction = np.equal(y_predict, y_target) accuracy = np.sum(correct_prediction)/len(correct_prediction) return accuracy rng = np.random N = 400 # training sample size feats = 784 # number of input variables # generate a dataset: D = (input_values, target_class) D = (rng.randn(N, feats), rng.randint(size=N, low=0, high=2)) # Declare Theano symbolic variables x = T.dmatrix(&quot;x&quot;) y = T.dvector(&quot;y&quot;) # initialize the weights and biases W = theano.shared(rng.randn(feats), name=&quot;w&quot;) b = theano.shared(0., name=&quot;b&quot;) # Construct Theano expression graph p_1 = T.nnet.sigmoid(T.dot(x, W) + b) # Logistic Probability that target = 1 (activation function) prediction = p_1 &gt; 0.5 # The prediction thresholded xent = -y * T.log(p_1) - (1-y) * T.log(1-p_1) # Cross-entropy loss function # or # xent = T.nnet.binary_crossentropy(p_1, y) # this is provided by theano cost = xent.mean() + 0.01 * (W ** 2).sum()# The cost to minimize (l2 regularization) gW, gb = T.grad(cost, [W, b]) # Compute the gradient of the cost # Compile learning_rate = 0.1 train = theano.function( inputs=[x, y], outputs=[prediction, xent.mean()], updates=((W, W - learning_rate * gW), (b, b - learning_rate * gb))) predict = theano.function(inputs=[x], outputs=prediction) # Training for i in range(500): pred, err = train(D[0], D[1]) if i % 50 == 0: print(&#39;cost:&#39;, err) print(&quot;accuracy:&quot;, compute_accuracy(D[1], predict(D[0]))) print(&quot;target values for D:&quot;) print(D[1]) print(&quot;prediction on D:&quot;) print(predict(D[0]) å…ˆæ­å»ºè®¡ç®—å›¾ï¼Œå†é€šè¿‡theano.functionç»‘å®šå¥½è¾“å…¥å’Œè¾“å‡ºï¼Œå½¢æˆä¸€ä¸ªå‡½æ•°ï¼ˆå¦‚trainï¼Œpredictï¼‰ TensorFlowfrom __future__ import print_function import tensorflow as tf from tensorflow.examples.tutorials.mnist import input_data # number 1 to 10 data mnist = input_data.read_data_sets(&#39;MNIST_data&#39;, one_hot=True) def compute_accuracy(v_xs, v_ys): global prediction y_pre = sess.run(prediction, feed_dict={xs: v_xs, keep_prob: 1}) correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys, keep_prob: 1}) return result def weight_variable(shape): initial = tf.truncated_normal(shape, stddev=0.1) return tf.Variable(initial) def bias_variable(shape): initial = tf.constant(0.1, shape=shape) return tf.Variable(initial) def conv2d(x, W): # stride [1, x_movement, y_movement, 1] # Must have strides[0] = strides[3] = 1 return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=&#39;SAME&#39;) def max_pool_2x2(x): # stride [1, x_movement, y_movement, 1] return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding=&#39;SAME&#39;) # define placeholder for inputs to network xs = tf.placeholder(tf.float32, [None, 784])/255. # 28x28 ys = tf.placeholder(tf.float32, [None, 10]) keep_prob = tf.placeholder(tf.float32) x_image = tf.reshape(xs, [-1, 28, 28, 1]) # print(x_image.shape) # [n_samples, 28,28,1] ## conv1 layer ## W_conv1 = weight_variable([5,5, 1,32]) # patch 5x5, in size 1, out size 32 b_conv1 = bias_variable([32]) h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # output size 28x28x32 h_pool1 = max_pool_2x2(h_conv1) # output size 14x14x32 ## conv2 layer ## W_conv2 = weight_variable([5,5, 32, 64]) # patch 5x5, in size 32, out size 64 b_conv2 = bias_variable([64]) h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # output size 14x14x64 h_pool2 = max_pool_2x2(h_conv2) # output size 7x7x64 ## fc1 layer ## W_fc1 = weight_variable([7*7*64, 1024]) b_fc1 = bias_variable([1024]) # [n_samples, 7, 7, 64] -&gt;&gt; [n_samples, 7*7*64] h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64]) h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1) h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) ## fc2 layer ## W_fc2 = weight_variable([1024, 10]) b_fc2 = bias_variable([10]) prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2) # the error between prediction and real data cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction), reduction_indices=[1])) # loss train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy) sess = tf.Session() # important step # tf.initialize_all_variables() no long valid from # 2017-03-02 if using tensorflow &gt;= 0.12 if int((tf.__version__).split(&#39;.&#39;)[1]) &lt; 12 and int((tf.__version__).split(&#39;.&#39;)[0]) &lt; 1: init = tf.initialize_all_variables() else: init = tf.global_variables_initializer() sess.run(init) for i in range(1000): batch_xs, batch_ys = mnist.train.next_batch(100) sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5}) if i % 50 == 0: print(compute_accuracy( mnist.test.images[:1000], mnist.test.labels[:1000])) å…ˆæ­å»ºè®¡ç®—å›¾ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªsessä¼šè¯ï¼Œé€šè¿‡sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5})è¿™æ ·çš„å½¢å¼è¿›è¡Œå®é™…è®­ç»ƒ Pytorch# library # standard library import os # third-party library import torch import torch.nn as nn import torch.utils.data as Data import torchvision import matplotlib.pyplot as plt # torch.manual_seed(1) # reproducible # Hyper Parameters EPOCH = 1 # train the training data n times, to save time, we just train 1 epoch BATCH_SIZE = 50 LR = 0.001 # learning rate DOWNLOAD_MNIST = False # Mnist digits dataset if not(os.path.exists(&#39;./mnist/&#39;)) or not os.listdir(&#39;./mnist/&#39;): # not mnist dir or mnist is empyt dir DOWNLOAD_MNIST = True train_data = torchvision.datasets.MNIST( root=&#39;./mnist/&#39;, train=True, # this is training data transform=torchvision.transforms.ToTensor(), # Converts a PIL.Image or numpy.ndarray to # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0] download=DOWNLOAD_MNIST, ) # plot one example print(train_data.train_data.size()) # (60000, 28, 28) print(train_data.train_labels.size()) # (60000) plt.imshow(train_data.train_data[0].numpy(), cmap=&#39;gray&#39;) plt.title(&#39;%i&#39; % train_data.train_labels[0]) plt.show() # Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28) train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True) # pick 2000 samples to speed up testing test_data = torchvision.datasets.MNIST(root=&#39;./mnist/&#39;, train=False) test_x = torch.unsqueeze(test_data.test_data, dim=1).type(torch.FloatTensor)[:2000]/255. # shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1) test_y = test_data.test_labels[:2000] class CNN(nn.Module): def __init__(self): super(CNN, self).__init__() self.conv1 = nn.Sequential( # input shape (1, 28, 28) nn.Conv2d( in_channels=1, # input height out_channels=16, # n_filters kernel_size=5, # filter size stride=1, # filter movement/step padding=2, # if want same width and length of this image after Conv2d, padding=(kernel_size-1)/2 if stride=1 ), # output shape (16, 28, 28) nn.ReLU(), # activation nn.MaxPool2d(kernel_size=2), # choose max value in 2x2 area, output shape (16, 14, 14) ) self.conv2 = nn.Sequential( # input shape (16, 14, 14) nn.Conv2d(16, 32, 5, 1, 2), # output shape (32, 14, 14) nn.ReLU(), # activation nn.MaxPool2d(2), # output shape (32, 7, 7) ) self.out = nn.Linear(32 * 7 * 7, 10) # fully connected layer, output 10 classes def forward(self, x): x = self.conv1(x) x = self.conv2(x) x = x.view(x.size(0), -1) # flatten the output of conv2 to (batch_size, 32 * 7 * 7) output = self.out(x) return output, x # return x for visualization cnn = CNN() print(cnn) # net architecture optimizer = torch.optim.Adam(cnn.parameters(), lr=LR) # optimize all cnn parameters loss_func = nn.CrossEntropyLoss() # the target label is not one-hotted # following function (plot_with_labels) is for visualization, can be ignored if not interested from matplotlib import cm try: from sklearn.manifold import TSNE; HAS_SK = True except: HAS_SK = False; print(&#39;Please install sklearn for layer visualization&#39;) def plot_with_labels(lowDWeights, labels): plt.cla() X, Y = lowDWeights[:, 0], lowDWeights[:, 1] for x, y, s in zip(X, Y, labels): c = cm.rainbow(int(255 * s / 9)); plt.text(x, y, s, backgroundcolor=c, fontsize=9) plt.xlim(X.min(), X.max()); plt.ylim(Y.min(), Y.max()); plt.title(&#39;Visualize last layer&#39;); plt.show(); plt.pause(0.01) plt.ion() # training and testing for epoch in range(EPOCH): for step, (b_x, b_y) in enumerate(train_loader): # gives batch data, normalize x when iterate train_loader output = cnn(b_x)[0] # cnn output loss = loss_func(output, b_y) # cross entropy loss optimizer.zero_grad() # clear gradients for this training step loss.backward() # backpropagation, compute gradients optimizer.step() # apply gradients if step % 50 == 0: test_output, last_layer = cnn(test_x) pred_y = torch.max(test_output, 1)[1].data.numpy() accuracy = float((pred_y == test_y.data.numpy()).astype(int).sum()) / float(test_y.size(0)) print(&#39;Epoch: &#39;, epoch, &#39;| train loss: %.4f&#39; % loss.data.numpy(), &#39;| test accuracy: %.2f&#39; % accuracy) if HAS_SK: # Visualization of trained flatten layer (T-SNE) tsne = TSNE(perplexity=30, n_components=2, init=&#39;pca&#39;, n_iter=5000) plot_only = 500 low_dim_embs = tsne.fit_transform(last_layer.data.numpy()[:plot_only, :]) labels = test_y.numpy()[:plot_only] plot_with_labels(low_dim_embs, labels) plt.ioff() # print 10 predictions from test data test_output, _ = cnn(test_x[:10]) pred_y = torch.max(test_output, 1)[1].data.numpy() print(pred_y, &#39;prediction number&#39;) print(test_y[:10].numpy(), &#39;real number&#39;) åŠ¨æ€æ­å»ºç½‘ç»œï¼Œä¸€èˆ¬æ•°æ®å¯¼å…¥ï¼Œç½‘ç»œæ­å»º æŸå¤±å‡½æ•°ï¼Œè®­ç»ƒéƒ½æ˜¯ç”¨å„è‡ªçš„æ¨¡å—å®Œæˆã€‚é€šè¿‡ç»§æ‰¿å°è£…å¥½çš„çˆ¶ç±»ï¼Œå¦‚nn.Moduleè¿›è¡Œç½‘ç»œæ­å»ºï¼Œtorch.utils.data.Datasetå¯¼å…¥æ•°æ®ç­‰ç­‰ Keras# to try tensorflow, un-comment following two lines # import os # os.environ[&#39;KERAS_BACKEND&#39;]=&#39;tensorflow&#39; import numpy as np np.random.seed(1337) # for reproducibility from keras.datasets import mnist from keras.utils import np_utils from keras.models import Sequential from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten from keras.optimizers import Adam # download the mnist to the path &#39;~/.keras/datasets/&#39; if it is the first time to be called # training X shape (60000, 28x28), Y shape (60000, ). test X shape (10000, 28x28), Y shape (10000, ) (X_train, y_train), (X_test, y_test) = mnist.load_data() # data pre-processing X_train = X_train.reshape(-1, 1,28, 28)/255. X_test = X_test.reshape(-1, 1,28, 28)/255. y_train = np_utils.to_categorical(y_train, num_classes=10) y_test = np_utils.to_categorical(y_test, num_classes=10) # Another way to build your CNN model = Sequential() # Conv layer 1 output shape (32, 28, 28) model.add(Convolution2D( batch_input_shape=(None, 1, 28, 28), filters=32, kernel_size=5, strides=1, padding=&#39;same&#39;, # Padding method data_format=&#39;channels_first&#39;, )) model.add(Activation(&#39;relu&#39;)) # Pooling layer 1 (max pooling) output shape (32, 14, 14) model.add(MaxPooling2D( pool_size=2, strides=2, padding=&#39;same&#39;, # Padding method data_format=&#39;channels_first&#39;, )) # Conv layer 2 output shape (64, 14, 14) model.add(Convolution2D(64, 5, strides=1, padding=&#39;same&#39;, data_format=&#39;channels_first&#39;)) model.add(Activation(&#39;relu&#39;)) # Pooling layer 2 (max pooling) output shape (64, 7, 7) model.add(MaxPooling2D(2, 2, &#39;same&#39;, data_format=&#39;channels_first&#39;)) # Fully connected layer 1 input shape (64 * 7 * 7) = (3136), output shape (1024) model.add(Flatten()) model.add(Dense(1024)) model.add(Activation(&#39;relu&#39;)) # Fully connected layer 2 to shape (10) for 10 classes model.add(Dense(10)) model.add(Activation(&#39;softmax&#39;)) # Another way to define your optimizer adam = Adam(lr=1e-4) # We add metrics to get more results you want to see model.compile(optimizer=adam, loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) print(&#39;Training ------------&#39;) # Another way to train the model model.fit(X_train, y_train, epochs=1, batch_size=64,) print(&#39;\\nTesting ------------&#39;) # Evaluate the model with the metrics we defined earlier loss, accuracy = model.evaluate(X_test, y_test) print(&#39;\\ntest loss: &#39;, loss) print(&#39;\\ntest accuracy: &#39;, accuracy) KerasåŸºäºTheanoæˆ–TensorFlowçš„å†…æ ¸ï¼Œå½¢æˆäº†æ›´é«˜å±‚çš„å°è£…ï¼Œæœ‰ç‚¹ç±»ä¼¼Pytorchã€‚é€šè¿‡model.compile()ç»‘å®šæ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ï¼Œå¹¶é€šè¿‡model.fitå³å¯è¿›è¡Œè®­ç»ƒ æ€»ç»“è¿™å››ç§æ¡†æ¶å„è‡ªéƒ½åœ¨ä¸æ–­åœ°è‡ªæˆ‘å®Œå–„æ¨é™ˆå‡ºæ–°ï¼Œåƒæ˜¯ç›®å‰TensorFlow 2å·²ç»æŠŠKerasåˆå¹¶è¿›æ¥äº†ï¼ŒKerasç”¨æˆ·è¿ç§»è¿‡æ¥ä¹Ÿååˆ†ç®€å•ï¼ŒPytorchä¹Ÿåœ¨ä¸æ–­åœ°è®©è‡ªèº«æ›´ç®€æ´ï¼Œå¦‚å»æ‰äº†Variableå˜é‡çš„ä½¿ç”¨ç­‰ã€‚ç›®å‰è€Œè¨€ï¼ŒTensorFlow å’Œ Pytorch æ˜¯ä¸¤å¤§å·¨å¤´ï¼Œä¸ªäººæ„Ÿè§‰ä¼ä¸šç”¨ TensorFlow æ›´å¤šï¼Œé«˜æ ¡ç”¨ Pytorch æ›´å¤šå§ã€‚","categories":[],"tags":[]},{"title":"å¼ºåŒ–å­¦ä¹ ç®€ä»‹","slug":"RL","date":"2020-05-27T11:34:29.000Z","updated":"2020-06-20T07:06:22.829Z","comments":true,"path":"2020/05/27/RL/","link":"","permalink":"http://weiquanfan.xyz/2020/05/27/RL/","excerpt":"","text":"å‰è¨€å¼ºåŒ–å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ ä¸­çš„ä¸€å¤§ç±»ï¼Œå®ƒå¯ä»¥è®©æœºå™¨å­¦ç€å¦‚ä½•åœ¨ç¯å¢ƒä¸­æ‹¿åˆ°é«˜åˆ†, è¡¨ç°å‡ºä¼˜ç§€çš„æˆç»©. è€Œè¿™äº›æˆç»©èƒŒåå´æ˜¯ä»–æ‰€ä»˜å‡ºçš„è¾›è‹¦åŠ³åŠ¨, ä¸æ–­çš„è¯•é”™, ä¸æ–­åœ°å°è¯•, ç´¯ç§¯ç»éªŒ, å­¦ä¹ ç»éªŒ. å¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•å¯ä»¥åˆ†ä¸ºç†ä¸ç†è§£æ‰€å¤„ç¯å¢ƒã€‚ä¸ç†è§£ç¯å¢ƒï¼Œç¯å¢ƒç»™ä»€ä¹ˆå°±æ˜¯ä»€ä¹ˆï¼Œç§°ä¸ºmodel-freeï¼ŒåŒ…å« Q learning, Sarsa, Policy Gradients ç­‰æ–¹æ³•ã€‚ ç†è§£ç¯å¢ƒï¼Œç”¨å¤šä¸€ä¸ªæ¨¡å‹å»è¡¨ç¤ºç¯å¢ƒï¼Œå°±æ˜¯ model-based æ–¹æ³•ã€‚ OpenAI gym ç¯å¢ƒåº“æ˜¯ä¸€ä¸ªç¼–å†™å¥½äº†å¤šç§äº¤äº’ç¯å¢ƒçš„åº“ï¼Œè€Œè‡ªå·±ç¼–å†™ç¯å¢ƒæ˜¯ä¸€ä¸ªå¾ˆè€—æ—¶é—´çš„è¿‡ç¨‹ï¼Œä»¥ä¸‹å‡ä¸æ¶‰åŠç¯å¢ƒçš„ç¼–å†™ã€‚ Q learningQ learning æ˜¯ä¸€ç§model-freeæ–¹æ³•ï¼Œå®ƒçš„æ ¸å¿ƒåœ¨äºæ„å»ºä¸€ä¸ªQè¡¨ï¼Œè¿™ä¸ªè¡¨è¡¨ç¤ºäº†å¤„äºæ¯ä¸€ç§çŠ¶æ€(state)æ—¶è¿›è¡Œå„ä¸ªè¡ŒåŠ¨(action)çš„å¥–åŠ±å€¼ã€‚ ä¸¾ä¾‹è€Œè¨€(è«çƒ¦pythonçš„ä¾‹å­)ï¼Œä¸‹å›¾å°±æ˜¯ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ çš„è¿‡ç¨‹ï¼Œæœ‰16ä¸ªstate(ä½ç½®)ï¼Œ4ä¸ªå¯é€‰çš„action(ä¸Šä¸‹å·¦å³)ã€‚è®©æ¢ç´¢è€…(çº¢æ¡†)å­¦ä¼šèµ°è¿·å®«. é»„è‰²çš„æ˜¯å¤©å ‚ (reward 1), é»‘è‰²çš„åœ°ç‹± (reward -1)ã€‚ é‚£ä¹ˆï¼ŒQ learning çš„æµç¨‹å¦‚ä¸‹ã€‚ åŒ…å«äº†ä¸æ–­é‡å¤çš„ä¸‰ä¸ªæ­¥éª¤ã€‚ ç»™å®šå½“å‰çŠ¶æ€så’ŒQè¡¨ï¼Œ ä½¿ç”¨è´ªå©ªç®—æ³•é‡‡å–ä¸€ä¸ªè¡ŒåŠ¨a ç»™å®šå½“å‰çŠ¶æ€så’Œè¡ŒåŠ¨aï¼Œç”±ç¯å¢ƒäº¤äº’ç»™å‡ºä¸‹ä¸€ä¸ªçŠ¶æ€sâ€™å’Œå¥–åŠ±r ç”±sã€sâ€™ã€aã€Qè¡¨ï¼Œæ›´æ–°å¾—åˆ°æ–°çš„Qè¡¨æ¯æ¬¡æ›´æ–°æˆ‘ä»¬éƒ½ç”¨åˆ°äº† Q ç°å®å’Œ Q ä¼°è®¡, è€Œä¸” Q learning çš„è¿·äººä¹‹å¤„å°±æ˜¯ åœ¨ Q(s1, a2) ç°å® ä¸­, ä¹ŸåŒ…å«äº†ä¸€ä¸ª Q(s2) çš„æœ€å¤§ä¼°è®¡å€¼, å°†å¯¹ä¸‹ä¸€æ­¥çš„è¡°å‡çš„æœ€å¤§ä¼°è®¡å’Œå½“å‰æ‰€å¾—åˆ°çš„å¥–åŠ±å½“æˆè¿™ä¸€æ­¥çš„ç°å®. ä»£ç å¦‚ä¸‹ï¼š import numpy as np import pandas as pd class QLearningTable: def __init__(self, actions, learning_rate=0.01, reward_decay=0.9, e_greedy=0.9): self.actions = actions # a list self.lr = learning_rate self.gamma = reward_decay self.epsilon = e_greedy self.q_table = pd.DataFrame(columns=self.actions, dtype=np.float64) def choose_action(self, observation): self.check_state_exist(observation) # action selection if np.random.uniform() &lt; self.epsilon: # choose best action state_action = self.q_table.loc[observation, :] # some actions may have the same value, randomly choose on in these actions action = np.random.choice(state_action[state_action == np.max(state_action)].index) else: # choose random action action = np.random.choice(self.actions) return action def learn(self, s, a, r, s_): self.check_state_exist(s_) q_predict = self.q_table.loc[s, a] if s_ != &#39;terminal&#39;: q_target = r + self.gamma * self.q_table.loc[s_, :].max() # next state is not terminal else: q_target = r # next state is terminal self.q_table.loc[s, a] += self.lr * (q_target - q_predict) # update def check_state_exist(self, state): if state not in self.q_table.index: # append new state to q table self.q_table = self.q_table.append( pd.Series( [0]*len(self.actions), index=self.q_table.columns, name=state, ) ) from maze_env import Maze from RL_brain import QLearningTable def update(): for episode in range(100): # initial observation observation = env.reset() while True: # fresh env env.render() # RL choose action based on observation action = RL.choose_action(str(observation)) # RL take action and get next observation and reward observation_, reward, done = env.step(action) # RL learn from this transition RL.learn(str(observation), action, reward, str(observation_)) # swap observation observation = observation_ # break while loop when end of this episode if done: break # end of game print(&#39;game over&#39;) env.destroy() if __name__ == &quot;__main__&quot;: env = Maze() RL = QLearningTable(actions=list(range(env.n_actions))) env.after(100, update) env.mainloop() SarsaSarsa å’Œ Q learning å¾ˆç±»ä¼¼ï¼Œå·®åˆ«åœ¨äºSarsaä¼šæ›´â€˜èƒ†å°â€™ä¸€ç‚¹ï¼Œä¸å¤ªæ•¢å°è¯•ã€‚å®ƒçš„æµç¨‹å¦‚ä¸‹ã€‚ å¯ä»¥çœ‹å‡ºï¼Œå®ƒå’Œ Q learning å·®åˆ«ä»…åœ¨äºæ›´æ–°ç¯èŠ‚ï¼Œå…·ä½“æ¥è®²ï¼š ä»–åœ¨å½“å‰ state å·²ç»æƒ³å¥½äº† state å¯¹åº”çš„ action, è€Œä¸”æƒ³å¥½äº† ä¸‹ä¸€ä¸ª state_ å’Œä¸‹ä¸€ä¸ª action_ (Qlearning è¿˜æ²¡æœ‰æƒ³å¥½ä¸‹ä¸€ä¸ª action_) æ›´æ–° Q(s,a) çš„æ—¶å€™åŸºäºçš„æ˜¯ä¸‹ä¸€ä¸ªè´ªå©ªç®—æ³•çš„ Q(s_, a_) (Qlearning æ˜¯åŸºäº maxQ(s_))è¿™ç§ä¸åŒä¹‹å¤„ä½¿å¾— Sarsa ç›¸å¯¹äº Qlearning, æ›´åŠ çš„èƒ†å°. å› ä¸º Qlearning æ°¸è¿œéƒ½æ˜¯æƒ³ç€ maxQ æœ€å¤§åŒ–, å› ä¸ºè¿™ä¸ª maxQ è€Œå˜å¾—è´ªå©ª, ä¸è€ƒè™‘å…¶ä»–é maxQ çš„ç»“æœ. æˆ‘ä»¬å¯ä»¥ç†è§£æˆ Qlearning æ˜¯ä¸€ç§è´ªå©ª, å¤§èƒ†, å‹‡æ•¢çš„ç®—æ³•, å¯¹äºé”™è¯¯, æ­»äº¡å¹¶ä¸åœ¨ä¹. è€Œ Sarsa æ˜¯ä¸€ç§ä¿å®ˆçš„ç®—æ³•, ä»–åœ¨ä¹æ¯ä¸€æ­¥å†³ç­–, å¯¹äºé”™è¯¯å’Œæ­»äº¡æ¯”è¾ƒé“­æ„Ÿ. import numpy as np import pandas as pd class RL(object): def __init__(self, action_space, learning_rate=0.01, reward_decay=0.9, e_greedy=0.9): self.actions = action_space # a list self.lr = learning_rate self.gamma = reward_decay self.epsilon = e_greedy self.q_table = pd.DataFrame(columns=self.actions, dtype=np.float64) def check_state_exist(self, state): if state not in self.q_table.index: # append new state to q table self.q_table = self.q_table.append( pd.Series( [0]*len(self.actions), index=self.q_table.columns, name=state, ) ) def choose_action(self, observation): self.check_state_exist(observation) # action selection if np.random.rand() &lt; self.epsilon: # choose best action state_action = self.q_table.loc[observation, :] # some actions may have the same value, randomly choose on in these actions action = np.random.choice(state_action[state_action == np.max(state_action)].index) else: # choose random action action = np.random.choice(self.actions) return action def learn(self, *args): pass # off-policy class QLearningTable(RL): def __init__(self, actions, learning_rate=0.01, reward_decay=0.9, e_greedy=0.9): super(QLearningTable, self).__init__(actions, learning_rate, reward_decay, e_greedy) def learn(self, s, a, r, s_): self.check_state_exist(s_) q_predict = self.q_table.loc[s, a] if s_ != &#39;terminal&#39;: q_target = r + self.gamma * self.q_table.loc[s_, :].max() # next state is not terminal else: q_target = r # next state is terminal self.q_table.loc[s, a] += self.lr * (q_target - q_predict) # update # on-policy class SarsaTable(RL): def __init__(self, actions, learning_rate=0.01, reward_decay=0.9, e_greedy=0.9): super(SarsaTable, self).__init__(actions, learning_rate, reward_decay, e_greedy) def learn(self, s, a, r, s_, a_): self.check_state_exist(s_) q_predict = self.q_table.loc[s, a] if s_ != &#39;terminal&#39;: q_target = r + self.gamma * self.q_table.loc[s_, a_] # next state is not terminal else: q_target = r # next state is terminal self.q_table.loc[s, a] += self.lr * (q_target - q_predict) # update from maze_env import Maze from RL_brain import SarsaTable def update(): for episode in range(100): # åˆå§‹åŒ–ç¯å¢ƒ observation = env.reset() # Sarsa æ ¹æ® state è§‚æµ‹é€‰æ‹©è¡Œä¸º action = RL.choose_action(str(observation)) while True: # åˆ·æ–°ç¯å¢ƒ env.render() # åœ¨ç¯å¢ƒä¸­é‡‡å–è¡Œä¸º, è·å¾—ä¸‹ä¸€ä¸ª state_ (obervation_), reward, å’Œæ˜¯å¦ç»ˆæ­¢ observation_, reward, done = env.step(action) # æ ¹æ®ä¸‹ä¸€ä¸ª state (obervation_) é€‰å–ä¸‹ä¸€ä¸ª action_ action_ = RL.choose_action(str(observation_)) # ä» (s, a, r, s, a) ä¸­å­¦ä¹ , æ›´æ–° Q_tabel çš„å‚æ•° ==&gt; Sarsa RL.learn(str(observation), action, reward, str(observation_), action_) # å°†ä¸‹ä¸€ä¸ªå½“æˆä¸‹ä¸€æ­¥çš„ state (observation) and action observation = observation_ action = action_ # ç»ˆæ­¢æ—¶è·³å‡ºå¾ªç¯ if done: break # å¤§å¾ªç¯å®Œæ¯• print(&#39;game over&#39;) env.destroy() if __name__ == &quot;__main__&quot;: env = Maze() RL = SarsaTable(actions=list(range(env.n_actions))) env.after(100, update) env.mainloop() Deep Q Network(DQN)DQN æ˜¯ä¸€ç§ç»“åˆäº†ç¥ç»ç½‘ç»œçš„å¼ºåŒ–å­¦ä¹ ã€‚æ™®é€šçš„å¼ºåŒ–å­¦ä¹ ä¸­éœ€è¦ç”Ÿæˆä¸€ä¸ªQè¡¨ï¼Œè€Œå¦‚æœçŠ¶æ€æ•°å¤ªå¤šçš„è¯Qè¡¨ä¹Ÿæä¸ºè€—å†…å­˜ï¼Œæ‰€ä»¥ DQN æå‡ºäº†ç”¨ç¥ç»ç½‘ç»œæ¥ä»£æ›¿Qè¡¨çš„åŠŸèƒ½ã€‚ç½‘ç»œè¾“å…¥ä¸€ä¸ªçŠ¶æ€ï¼Œè¾“å‡ºå„ä¸ªåŠ¨ä½œçš„Qå€¼ã€‚ç½‘ç»œé€šè¿‡å¯¹Qä¼°è®¡å’ŒQç°å®ä½¿ç”¨RMSpropæ¥æ›´æ–°å‚æ•°ã€‚Qä¼°è®¡å°±æ˜¯ç½‘ç»œè¾“å‡ºï¼Œè€ŒQç°å®ç­‰äºå¥–åŠ±+ä¸‹ä¸€çŠ¶æ€çš„å‰æ¨¡å‹çš„Qä¼°è®¡ã€‚æµç¨‹å›¾å¦‚ä¸‹ï¼š æ•´ä¸ªç®—æ³•ä¹çœ‹èµ·æ¥å¾ˆå¤æ‚, ä¸è¿‡æˆ‘ä»¬æ‹†åˆ†ä¸€ä¸‹, å°±å˜ç®€å•äº†. ä¹Ÿå°±æ˜¯ä¸ª Q learning ä¸»æ¡†æ¶ä¸ŠåŠ äº†äº›è£…é¥°ï¼ŒåŒ…æ‹¬: è®°å¿†åº“ (ç”¨äºé‡å¤å­¦ä¹ ) ç¥ç»ç½‘ç»œè®¡ç®— Q å€¼ æš‚æ—¶å†»ç»“ q_target å‚æ•° (åˆ‡æ–­ç›¸å…³æ€§) å…·ä½“è€Œè¨€ï¼Œè®°å¿†åº“æ˜¯é€šè¿‡å­˜å‚¨ä¸€å †æ•°æ®åœ¨ä¸€ä¸ªä¸æ–­æ›´æ–°çš„è®°å¿†åº“é‡Œï¼Œè®­ç»ƒæ—¶éšæœºæŠ½å–æ•°æ®å‡ºæ¥è®­ç»ƒã€‚ç¥ç»ç½‘ç»œç”¨æ¥é’ˆå¯¹è¾“å…¥çš„çŠ¶æ€æ¥è¾“å‡ºé‡‡å–å„ä¸ªè¡ŒåŠ¨çš„Qå€¼ã€‚å…±ç”¨äº†ä¸¤ä¸ªç½‘ç»œï¼Œä»–ä»¬çš„ç»“æ„ä¸€æ¨¡ä¸€æ ·ï¼Œä½† q_target ç½‘ç»œç”¨çš„æ˜¯ä¸»ç½‘ç»œä¹‹å‰å¾ˆå¤šä¸ªstepçš„å‚æ•°ï¼Œè¿™æ˜¯ä¸ºäº†å½¢æˆä¸€ç§å»¶è¿Ÿï¼Œåˆ‡æ–­ä»–ä»¬çš„ç›¸å…³æ€§ã€‚ import numpy as np import pandas as pd import tensorflow as tf np.random.seed(1) tf.set_random_seed(1) # Deep Q Network off-policy class DeepQNetwork: def __init__( self, n_actions, n_features, learning_rate=0.01, reward_decay=0.9, e_greedy=0.9, replace_target_iter=300, memory_size=500, batch_size=32, e_greedy_increment=None, output_graph=False, ): self.n_actions = n_actions self.n_features = n_features self.lr = learning_rate self.gamma = reward_decay self.epsilon_max = e_greedy self.replace_target_iter = replace_target_iter self.memory_size = memory_size self.batch_size = batch_size self.epsilon_increment = e_greedy_increment self.epsilon = 0 if e_greedy_increment is not None else self.epsilon_max # total learning step self.learn_step_counter = 0 # initialize zero memory [s, a, r, s_] self.memory = np.zeros((self.memory_size, n_features * 2 + 2)) # consist of [target_net, evaluate_net] self._build_net() t_params = tf.get_collection(&#39;target_net_params&#39;) e_params = tf.get_collection(&#39;eval_net_params&#39;) self.replace_target_op = [tf.assign(t, e) for t, e in zip(t_params, e_params)] self.sess = tf.Session() if output_graph: # $ tensorboard --logdir=logs # tf.train.SummaryWriter soon be deprecated, use following tf.summary.FileWriter(&quot;logs/&quot;, self.sess.graph) self.sess.run(tf.global_variables_initializer()) self.cost_his = [] def _build_net(self): # ------------------ build evaluate_net ------------------ self.s = tf.placeholder(tf.float32, [None, self.n_features], name=&#39;s&#39;) # input self.q_target = tf.placeholder(tf.float32, [None, self.n_actions], name=&#39;Q_target&#39;) # for calculating loss with tf.variable_scope(&#39;eval_net&#39;): # c_names(collections_names) are the collections to store variables c_names, n_l1, w_initializer, b_initializer = \\ [&#39;eval_net_params&#39;, tf.GraphKeys.GLOBAL_VARIABLES], 10, \\ tf.random_normal_initializer(0., 0.3), tf.constant_initializer(0.1) # config of layers # first layer. collections is used later when assign to target net with tf.variable_scope(&#39;l1&#39;): w1 = tf.get_variable(&#39;w1&#39;, [self.n_features, n_l1], initializer=w_initializer, collections=c_names) b1 = tf.get_variable(&#39;b1&#39;, [1, n_l1], initializer=b_initializer, collections=c_names) l1 = tf.nn.relu(tf.matmul(self.s, w1) + b1) # second layer. collections is used later when assign to target net with tf.variable_scope(&#39;l2&#39;): w2 = tf.get_variable(&#39;w2&#39;, [n_l1, self.n_actions], initializer=w_initializer, collections=c_names) b2 = tf.get_variable(&#39;b2&#39;, [1, self.n_actions], initializer=b_initializer, collections=c_names) self.q_eval = tf.matmul(l1, w2) + b2 with tf.variable_scope(&#39;loss&#39;): self.loss = tf.reduce_mean(tf.squared_difference(self.q_target, self.q_eval)) with tf.variable_scope(&#39;train&#39;): self._train_op = tf.train.RMSPropOptimizer(self.lr).minimize(self.loss) # ------------------ build target_net ------------------ self.s_ = tf.placeholder(tf.float32, [None, self.n_features], name=&#39;s_&#39;) # input with tf.variable_scope(&#39;target_net&#39;): # c_names(collections_names) are the collections to store variables c_names = [&#39;target_net_params&#39;, tf.GraphKeys.GLOBAL_VARIABLES] # first layer. collections is used later when assign to target net with tf.variable_scope(&#39;l1&#39;): w1 = tf.get_variable(&#39;w1&#39;, [self.n_features, n_l1], initializer=w_initializer, collections=c_names) b1 = tf.get_variable(&#39;b1&#39;, [1, n_l1], initializer=b_initializer, collections=c_names) l1 = tf.nn.relu(tf.matmul(self.s_, w1) + b1) # second layer. collections is used later when assign to target net with tf.variable_scope(&#39;l2&#39;): w2 = tf.get_variable(&#39;w2&#39;, [n_l1, self.n_actions], initializer=w_initializer, collections=c_names) b2 = tf.get_variable(&#39;b2&#39;, [1, self.n_actions], initializer=b_initializer, collections=c_names) self.q_next = tf.matmul(l1, w2) + b2 def store_transition(self, s, a, r, s_): if not hasattr(self, &#39;memory_counter&#39;): self.memory_counter = 0 transition = np.hstack((s, [a, r], s_)) # replace the old memory with new memory index = self.memory_counter % self.memory_size self.memory[index, :] = transition self.memory_counter += 1 def choose_action(self, observation): # to have batch dimension when feed into tf placeholder observation = observation[np.newaxis, :] if np.random.uniform() &lt; self.epsilon: # forward feed the observation and get q value for every actions actions_value = self.sess.run(self.q_eval, feed_dict={self.s: observation}) action = np.argmax(actions_value) else: action = np.random.randint(0, self.n_actions) return action def learn(self): # check to replace target parameters if self.learn_step_counter % self.replace_target_iter == 0: self.sess.run(self.replace_target_op) print(&#39;\\ntarget_params_replaced\\n&#39;) # sample batch memory from all memory if self.memory_counter &gt; self.memory_size: sample_index = np.random.choice(self.memory_size, size=self.batch_size) else: sample_index = np.random.choice(self.memory_counter, size=self.batch_size) batch_memory = self.memory[sample_index, :] q_next, q_eval = self.sess.run( [self.q_next, self.q_eval], feed_dict={ self.s_: batch_memory[:, -self.n_features:], # fixed params self.s: batch_memory[:, :self.n_features], # newest params }) # change q_target w.r.t q_eval&#39;s action q_target = q_eval.copy() batch_index = np.arange(self.batch_size, dtype=np.int32) eval_act_index = batch_memory[:, self.n_features].astype(int) reward = batch_memory[:, self.n_features + 1] q_target[batch_index, eval_act_index] = reward + self.gamma * np.max(q_next, axis=1) &quot;&quot;&quot; For example in this batch I have 2 samples and 3 actions: q_eval = [[1, 2, 3], [4, 5, 6]] q_target = q_eval = [[1, 2, 3], [4, 5, 6]] Then change q_target with the real q_target value w.r.t the q_eval&#39;s action. For example in: sample 0, I took action 0, and the max q_target value is -1; sample 1, I took action 2, and the max q_target value is -2: q_target = [[-1, 2, 3], [4, 5, -2]] So the (q_target - q_eval) becomes: [[(-1)-(1), 0, 0], [0, 0, (-2)-(6)]] We then backpropagate this error w.r.t the corresponding action to network, leave other action as error=0 cause we didn&#39;t choose it. &quot;&quot;&quot; # train eval network _, self.cost = self.sess.run([self._train_op, self.loss], feed_dict={self.s: batch_memory[:, :self.n_features], self.q_target: q_target}) self.cost_his.append(self.cost) # increasing epsilon self.epsilon = self.epsilon + self.epsilon_increment if self.epsilon &lt; self.epsilon_max else self.epsilon_max self.learn_step_counter += 1 def plot_cost(self): import matplotlib.pyplot as plt plt.plot(np.arange(len(self.cost_his)), self.cost_his) plt.ylabel(&#39;Cost&#39;) plt.xlabel(&#39;training steps&#39;) plt.show() from maze_env import Maze from RL_brain import DeepQNetwork def run_maze(): step = 0 # ç”¨æ¥æ§åˆ¶ä»€ä¹ˆæ—¶å€™å­¦ä¹  for episode in range(300): # åˆå§‹åŒ–ç¯å¢ƒ observation = env.reset() while True: # åˆ·æ–°ç¯å¢ƒ env.render() # DQN æ ¹æ®è§‚æµ‹å€¼é€‰æ‹©è¡Œä¸º action = RL.choose_action(observation) # ç¯å¢ƒæ ¹æ®è¡Œä¸ºç»™å‡ºä¸‹ä¸€ä¸ª state, reward, æ˜¯å¦ç»ˆæ­¢ observation_, reward, done = env.step(action) # DQN å­˜å‚¨è®°å¿† RL.store_transition(observation, action, reward, observation_) # æ§åˆ¶å­¦ä¹ èµ·å§‹æ—¶é—´å’Œé¢‘ç‡ (å…ˆç´¯ç§¯ä¸€äº›è®°å¿†å†å¼€å§‹å­¦ä¹ ) if (step &gt; 200) and (step % 5 == 0): RL.learn() # å°†ä¸‹ä¸€ä¸ª state_ å˜ä¸º ä¸‹æ¬¡å¾ªç¯çš„ state observation = observation_ # å¦‚æœç»ˆæ­¢, å°±è·³å‡ºå¾ªç¯ if done: break step += 1 # æ€»æ­¥æ•° # end of game print(&#39;game over&#39;) env.destroy() if __name__ == &quot;__main__&quot;: env = Maze() RL = DeepQNetwork(env.n_actions, env.n_features, learning_rate=0.01, reward_decay=0.9, e_greedy=0.9, replace_target_iter=200, # æ¯ 200 æ­¥æ›¿æ¢ä¸€æ¬¡ target_net çš„å‚æ•° memory_size=2000, # è®°å¿†ä¸Šé™ # output_graph=True # æ˜¯å¦è¾“å‡º tensorboard æ–‡ä»¶ ) env.after(100, run_maze) env.mainloop() RL.plot_cost() # è§‚çœ‹ç¥ç»ç½‘ç»œçš„è¯¯å·®æ›²çº¿ æ€»ç»“å¼ºåŒ–å­¦ä¹ æœ¬èº«æ˜¯ä¸ä¾èµ–äºæ·±åº¦å­¦ä¹ çš„ï¼Œå®ƒæ›´å¤šçš„æ˜¯ä¸€ç§æ€æƒ³ï¼Œé€šè¿‡è¡Œä¸ºä¸ç¯å¢ƒçš„äº¤äº’äº§ç”Ÿå¥–åŠ±å€¼ï¼Œä»è€Œæ¥æ›´æ–°Qè¡¨(æˆ–ç›¸åŒåŠŸèƒ½çš„ç¥ç»ç½‘ç»œ)ã€‚å®ƒæ²¡æœ‰ä¸€ç§å›ºå®šçš„ä»£ç ï¼Œåªæœ‰ä¸€å¥—æ¨¡å¼ï¼Œå…·ä½“ä»£ç è¿˜å¾—æ ¹æ®å®é™…åº”ç”¨ä¸äº¤äº’ç¯å¢ƒæ¥ç¼–å†™ã€‚","categories":[{"name":"å¼ºåŒ–å­¦ä¹ ","slug":"å¼ºåŒ–å­¦ä¹ ","permalink":"http://weiquanfan.xyz/categories/å¼ºåŒ–å­¦ä¹ /"}],"tags":[{"name":"å¼ºåŒ–å­¦ä¹ ","slug":"å¼ºåŒ–å­¦ä¹ ","permalink":"http://weiquanfan.xyz/tags/å¼ºåŒ–å­¦ä¹ /"}]},{"title":"ä½¿ç”¨BeautifulSoupã€requestså’Œyou_getçˆ¬è™«ä¸‹è½½Bç«™è§†é¢‘","slug":"BeautifulSoup","date":"2020-05-19T12:13:21.000Z","updated":"2020-05-19T12:36:15.497Z","comments":true,"path":"2020/05/19/BeautifulSoup/","link":"","permalink":"http://weiquanfan.xyz/2020/05/19/BeautifulSoup/","excerpt":"","text":"å‰è¨€BeautifulSoup æ˜¯ä¸€ä¸ªå¯ä»¥ä»HTMLæˆ–XMLæ–‡ä»¶ä¸­æå–æ•°æ®å¹¶è§£æçš„Pythonåº“ï¼Œ Requests æ˜¯ä¸€å¸¸ç”¨çš„å¯ä»¥è·å–å’Œå‘é€httpçš„è¯·æ±‚åº“ï¼Œ you_get åˆ™æ˜¯æ–¹ä¾¿çš„ä¸‹è½½å„å¤§ç½‘ç«™çš„è§†é¢‘çš„å‘½ä»¤è¡Œå·¥å…·ã€‚æ•´ä½“æµç¨‹ä¸Šæ˜¯ï¼Œå…ˆç”¨ Requests è¯·æ±‚è·å¾—ç½‘ç«™æºä»£ç ï¼Œå†ç”¨ BeautifulSoup è§£æç½‘ç«™å¹¶ç­›é€‰å‡ºè‡ªå·±è¦çš„ä¿¡æ¯ï¼ˆå¦‚è§†é¢‘çš„urlï¼‰ï¼Œæœ€åç”¨ you_get ä¸‹è½½ã€‚ ä¾‹å­ä»¥ä¸‹ä»£ç å®ç°çš„æ˜¯ä¸‹è½½Bç«™ç”µå½±ã€‚ #!/usr/bin/env python3 # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Sun Mar 15 12:06:21 2020 @author: weiquan fan &quot;&quot;&quot; from bs4 import BeautifulSoup as bs import requests,re,os def download(url, filename): path_root = &#39;./Videos&#39; os.system(&#39;you-get -o {} -O {} {}&#39;.format(path_root, filename, url)) url_base = &#39;https://www.bilibili.com/movie/?spm_id_from=333.851.b_62696c695f7265706f72745f6d6f766965.2&#39; response = requests.get(url_base) page = response.text soup = bs(page, &#39;html.parser&#39;) vids = soup.findAll(&#39;li&#39;,attrs={&#39;class&#39;:re.compile(&#39;video-item-biref.*?&#39;)})# bilibili video_urls = [] counter=1 if(vids): for v in vids: #v_link = v.find(&#39;a&#39;)[&#39;href&#39;] #v_name = v.find(&#39;img&#39;)[&#39;alt&#39;] print(v) v_link = v.find(&#39;a&#39;)[&#39;href&#39;] v_name = v.find(&#39;img&#39;)[&#39;alt&#39;] video_urls.append([v_link, v_name]) print(v_link,v_name) try: download(v_link, v_name) except Exception: print(&#39;can\\&#39;t download &#39;+v_name+&#39; in &#39;+v_link) counter -= 1 counter += 1 if(counter&gt;15): break","categories":[{"name":"çˆ¬è™«","slug":"çˆ¬è™«","permalink":"http://weiquanfan.xyz/categories/çˆ¬è™«/"}],"tags":[]},{"title":"CNNçš„è¿›å‡»ä¹‹è·¯â€”â€”è®²è®²ResNet, Inception, ResNeXtå’ŒDensenetç­‰å¸¸è§ç½‘ç»œ","slug":"resnet","date":"2020-05-13T06:50:15.000Z","updated":"2020-06-20T06:33:46.242Z","comments":true,"path":"2020/05/13/resnet/","link":"","permalink":"http://weiquanfan.xyz/2020/05/13/resnet/","excerpt":"","text":"å‰è¨€æœ¬æ–‡æ˜¯ä¸€ç¯‡å¤§æ‚çƒ©ï¼ŒæŒ‰ç…§å‘å¸ƒæ—¶é—´æ€»ç»“äº†CNNçš„ä¸€äº›å¸¸è§ç½‘ç»œã€‚ AlexNetAlexNetæ¥æºäºImageNet Classification with Deep Convolutional Neural Networksã€‚åœ¨ImageNet LSVRC-2010ä¸Šä»¥è¿œè¶…ç¬¬äºŒçš„å‡†ç¡®ç‡å¤ºå¾—äº†å† å†›ï¼Œæ‹‰å¼€äº†æ·±åº¦å­¦ä¹ çƒ­æ½®çš„å¤§å¹•ã€‚ æ¨¡å‹ç»“æ„ï¼š æ¨¡å‹ç‰¹ç‚¹ï¼š æå‡ºäº†éçº¿æ€§æ¿€æ´»å‡½æ•°ReLU (ä¹‹å‰æ™®éä½¿ç”¨Sigmoidæˆ–è€…tanh) æå‡ºDropoutï¼ˆæ¯æ¬¡è¿­ä»£è®­ç»ƒæ—¶éšæœºåˆ é™¤ä¸€äº›ç¥ç»å…ƒï¼‰ é‡å æ± åŒ–ï¼ˆæ± åŒ–çš„æ—¶å€™ï¼Œæ¯æ¬¡ç§»åŠ¨çš„æ­¥é•¿å°äºæ± åŒ–çš„çª—å£é•¿åº¦ï¼‰ æ•°æ®æ‰©å……ï¼ˆæ°´å¹³ç¿»è½¬å›¾åƒï¼Œä»åŸå§‹å›¾åƒä¸­éšæœºè£å‰ªã€å¹³ç§»å˜æ¢ï¼Œé¢œè‰²ã€å…‰ç…§å˜æ¢ï¼‰ LRNå½’ä¸€åŒ–å±‚ï¼ˆåˆ©ç”¨ä¸´è¿‘çš„æ•°æ®åšå½’ä¸€åŒ–ï¼‰ å¤šGPUå®ç°ï¼ˆå—å½“æ—¶GPUé™åˆ¶ï¼Œåœ¨æ¯ä¸ªGPUä¸­æ”¾ç½®ä¸€åŠç¥ç»å…ƒï¼Œå°†ç½‘ç»œåˆ†å¸ƒåœ¨ä¸¤ä¸ªGPUä¸Šè¿›è¡Œå¹¶è¡Œè®¡ï¼‰ VGGVGGæ¥æºäºOxfordçš„Visual Geometry Groupçš„ç»„æå‡ºçš„Very Deep Convolutional Networks for Large-Scale Image Recognitionï¼Œåœ¨ILSVRC 2014è·å¾—äºšå†›ã€‚ æ¨¡å‹ç»“æ„ï¼š å…¶ä¸­Dã€Eåˆ—å°±æ˜¯è‘—åçš„VGG-16ã€VGG-19ã€‚ æ¨¡å‹ç‰¹ç‚¹ï¼šä½¿ç”¨äº†3ä¸ª3x3å·ç§¯æ ¸æ¥ä»£æ›¿7x7å·ç§¯æ ¸ï¼Œä½¿ç”¨äº†2ä¸ª3x3å·ç§¯æ ¸æ¥ä»£æ›¿5x5å·ç§¯æ ¸ã€‚å› æ­¤æ¨¡å‹ç»“æ„å¾ˆç»Ÿä¸€ç®€æ´ï¼ˆå·ç§¯æ ¸å°ºå¯¸3x3å’Œæœ€å¤§æ± åŒ–å°ºå¯¸2x2ï¼‰ï¼Œå¹¶ä¸æ–­åŠ æ·±ç½‘ç»œã€‚ GoogLeNet V1GoogLeNet V1æ¥æºäºGoing deeper with convolutionsï¼Œåœ¨ILSVRC 2014è·å¾—å† å†›ã€‚ è¯¥ç½‘ç»œçš„æ ¸å¿ƒåœ¨äºæå‡ºäº†Inception Moduleã€‚è¯¥æ¨¡å—æœ‰4ä¸ªåˆ†æ”¯ï¼Œåˆå§‹ç‰ˆæœ¬å¦‚ä¸‹å›¾å·¦ï¼ŒåŒ…å«ä¸‰ä¸ªä¸åŒå°ºåº¦çš„å·ç§¯æ ¸å±‚å’Œä¸€ä¸ªæœ€å¤§æ± åŒ–å±‚ï¼Œå¹¶åœ¨è¾“å‡ºé€šé“ç»´åº¦ä¸Šåˆå¹¶ã€‚ç”±äº5Ã—5çš„è®¡ç®—é‡å¤§ï¼Œå°±è¿›ä¸€æ­¥å…ˆé€šè¿‡1Ã—1å·ç§¯é™ä½ç»´åº¦å†é€šè¿‡å¤§å·ç§¯æ ¸ã€‚è¿™é‡Œçš„æœ€å¤§æ± åŒ–ä¹Ÿæ˜¯é‡å æ± åŒ–çš„ï¼Œç»paddingåä¸ä¼šç¼©å°ç‰¹å¾å›¾å°ºå¯¸ã€‚ æ¨¡å‹ç»“æ„ï¼š æ¨¡å‹ç‰¹ç‚¹ï¼š å¤šå°ºåº¦å·ç§¯çš„æ€æƒ³è®©ç½‘ç»œå˜å®½ æå‡º1Ã—1å·ç§¯ GoogLeNet V2GoogLeNet V2æ¥æºäºBatch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shiftã€‚è¯¥ç½‘ç»œåŸºäºV1ç‰ˆæœ¬ï¼Œå¸æ”¶äº†VGGçš„åˆ†è§£æ“ä½œï¼Œä½¿ç”¨äº†2ä¸ª3x3å·ç§¯æ ¸æ¥ä»£æ›¿5x5å·ç§¯æ ¸ã€‚ æ¨¡å‹ç‰¹ç‚¹ï¼š æå‡ºäº†è‘—åçš„BNå±‚ã€‚ å¦å¤–ï¼Œä¸ºäº†é€‚é…BNå±‚ï¼Œå¢å¤§å­¦ä¹ é€Ÿç‡å¹¶åŠ å¿«å­¦ä¹ è¡°å‡é€Ÿåº¦ä»¥é€‚ç”¨BNè§„èŒƒåŒ–åçš„æ•°æ®ï¼›å»é™¤Dropoutå¹¶å‡è½»L2æ­£åˆ™ï¼ˆå› BNå·²èµ·åˆ°æ­£åˆ™åŒ–çš„ä½œç”¨ï¼‰ï¼›å»é™¤LRNï¼›æ›´å½»åº•åœ°å¯¹è®­ç»ƒæ ·æœ¬è¿›è¡Œshuffleï¼›å‡å°‘æ•°æ®å¢å¼ºè¿‡ç¨‹ä¸­å¯¹æ•°æ®çš„å…‰å­¦ç•¸å˜ï¼ˆå› ä¸ºBNè®­ç»ƒæ›´å¿«ï¼Œæ¯ä¸ªæ ·æœ¬è¢«è®­ç»ƒçš„æ¬¡æ•°æ›´å°‘ï¼Œå› æ­¤æ›´çœŸå®çš„æ ·æœ¬å¯¹è®­ç»ƒæ›´æœ‰å¸®åŠ©ï¼‰ã€‚ GoogLeNet V3GoogLeNet V3æ¥æºäºRethinking the Inception Architecture for Computer Visionã€‚è¯¥ç½‘ç»œåŸºäºV2ç‰ˆæœ¬ï¼Œè¿›ä¸€æ­¥æ”¹è¿›äº†Inceptionï¼Œå°†3x3åˆ†è§£æˆ1x3å’Œ3x1ã€‚åŒç†ï¼Œnxnå¯ä»¥åˆ†è§£æˆ1xnå’Œnx1ã€‚ ResNetResNetæ¥æºäºå¤§ç¥ä½•å‡¯æ˜çš„Deep Residual Learning for Image Recognitionï¼Œåœ¨ILSVRCå’ŒCOCO 2015ä¸Šéƒ½å¤ºå¾—äº†å† å†›ï¼Œæœ‰ç€é‡Œç¨‹ç¢‘çš„æ„ä¹‰ã€‚ æ·±åº¦æ¨¡å‹å½“æ·±åº¦åˆ°äº†å‡ åå±‚ä¹‹åï¼Œç”±äºæ¢¯åº¦æ¶ˆå¤±æˆ–è€…çˆ†ç‚¸çš„åŸå› ï¼Œå°±å®¹æ˜“å‘ç”Ÿé€€åŒ–é—®é¢˜ï¼šç½‘ç»œæ·±åº¦å¢åŠ æ—¶ï¼Œç½‘ç»œå‡†ç¡®åº¦å‡ºç°é¥±å’Œï¼Œç”šè‡³å‡ºç°ä¸‹é™ã€‚ç°åœ¨å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªæµ…å±‚ç½‘ç»œï¼Œæˆ‘ä»¬æƒ³é€šè¿‡å‘ä¸Šå †ç§¯æ–°å±‚æ¥å»ºç«‹æ·±å±‚ç½‘ç»œï¼Œä¸€ä¸ªæç«¯æƒ…å†µæ˜¯è¿™äº›å¢åŠ çš„å±‚ä»€ä¹ˆä¹Ÿä¸å­¦ä¹ ï¼Œä»…ä»…å¤åˆ¶æµ…å±‚ç½‘ç»œçš„ç‰¹å¾ï¼Œå³è¿™æ ·æ–°å±‚æ˜¯æ’ç­‰æ˜ å°„ï¼ˆIdentity mappingï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ·±å±‚ç½‘ç»œåº”è¯¥è‡³å°‘å’Œæµ…å±‚ç½‘ç»œæ€§èƒ½ä¸€æ ·ï¼Œä¹Ÿä¸åº”è¯¥å‡ºç°é€€åŒ–ç°è±¡ã€‚è¿™å¼•å‘äº†æ®‹å·®å­¦ä¹ ï¼Œå³æˆ‘ä»¬çš„ç›®æ ‡æ˜¯å­¦ä¹ åˆ°æ®‹å·®F(x)=H(x)-xï¼Œåˆ™è¯¥å±‚å­¦ä¹ åˆ°çš„æœ€ç»ˆç‰¹å¾H(x)=F(x)+xã€‚å½“æ®‹å·®ä¸º0æ—¶ï¼Œæ­¤æ—¶å †ç§¯å±‚ä»…ä»…åšäº†æ’ç­‰æ˜ å°„ï¼Œè‡³å°‘ç½‘ç»œæ€§èƒ½ä¸ä¼šä¸‹é™ï¼Œå®é™…ä¸Šæ®‹å·®ä¸ä¼šä¸º0ï¼Œè¿™ä¹Ÿä¼šä½¿å¾—å †ç§¯å±‚åœ¨è¾“å…¥ç‰¹å¾åŸºç¡€ä¸Šå­¦ä¹ åˆ°æ–°çš„ç‰¹å¾ï¼Œä»è€Œæ‹¥æœ‰æ›´å¥½çš„æ€§èƒ½ã€‚æ®‹å·®å­¦ä¹ çš„ç»“æ„ä¸‹å›¾æ‰€ç¤ºã€‚è¿™æœ‰ç‚¹ç±»ä¼¼ä¸ç”µè·¯ä¸­çš„â€œçŸ­è·¯â€ï¼Œæ‰€ä»¥æ˜¯ä¸€ç§çŸ­è·¯è¿æ¥ï¼ˆshortcut connectionï¼‰ã€‚ æ¨¡å‹ç»“æ„ï¼šResNetç½‘ç»œå‚è€ƒVGG19ç½‘ç»œï¼Œå¼•å…¥æ®‹å·®å•å…ƒã€‚å¦‚ä¸‹å›¾ï¼Œç¬¬ä¸‰åˆ—å³æ˜¯ResNet-34ã€‚ æ¨¡å‹ç‰¹ç‚¹ï¼š æå‡ºæ®‹å·®æ¨¡å— æ¨¡å‹å¼€å§‹å˜å¾—å¾ˆæ·±ï¼Œå¯ä»¥è¾¾åˆ°152å±‚ å·ç§¯å±‚ç”±Conv+BN+ReLUå˜æˆBN+ReLU+Conv GoogLeNet V4GoogLeNet V4æ¥æºäºInception-v4, Inception-ResNet and the Impact of Residual Connections on Learningã€‚è¯¥è®ºæ–‡ä¸€æ–¹é¢æ²¿è¢­v3ç‰ˆæœ¬ï¼Œä½¿ç”¨æ›´å¤šçš„Inception moduleå¾—åˆ°GoogLeNet V4ã€‚å¦ä¸€æ–¹é¢å¸æ”¶äº†ResNetçš„æ®‹å·®å•å…ƒï¼Œæå‡ºäº†ä¸¤ç§Inception-ResNetã€‚ æ¨¡å‹ç»“æ„ï¼šä¸‹å›¾ä¸ºå…¶ä¸­ä¸€ç§ï¼ŒInception-ResNet-v1ï¼Œå…·æœ‰å¦‚ä¸‹ç‰¹ç‚¹ï¼š Inception moduleéƒ½æ˜¯ç®€åŒ–ç‰ˆï¼Œæ²¡æœ‰ä½¿ç”¨é‚£ä¹ˆå¤šçš„åˆ†æ”¯ï¼Œå› ä¸ºidentityéƒ¨åˆ†ï¼ˆç›´æ¥ç›¸è¿çš„çº¿ï¼‰æœ¬èº«åŒ…å«ä¸°å¯Œçš„ç‰¹å¾ä¿¡æ¯ï¼› Inception moduleæ¯ä¸ªåˆ†æ”¯éƒ½æ²¡æœ‰ä½¿ç”¨poolingï¼› æ¯ä¸ªInception moduleæœ€åéƒ½ä½¿ç”¨äº†ä¸€ä¸ª1x1çš„å·ç§¯ï¼ˆlinear activationï¼‰ï¼Œä½œç”¨æ˜¯ä¿è¯identityéƒ¨åˆ†å’ŒInceptionéƒ¨åˆ†è¾“å‡ºç‰¹å¾ç»´åº¦ç›¸åŒï¼Œè¿™æ ·æ‰èƒ½ä¿è¯ä¸¤éƒ¨åˆ†ç‰¹å¾èƒ½å¤Ÿç›¸åŠ ã€‚ æ¨¡å‹ç‰¹ç‚¹ï¼š ä½¿å¾—å®½æ¨¡å‹å˜å¾—æ›´æ·± DenseNetDenseNetæ¥æºäºDensely Connected Convolutional Networksï¼Œæ–©è·äº†CVPR 2017çš„æœ€ä½³è®ºæ–‡å¥–ã€‚ æ¨¡å‹ç»“æ„ï¼šDenseNetæœ‰ç‚¹ç±»ä¼¼äºResNetï¼Œä½†æœ¬è´¨ä¸Šåˆæœ‰å¾ˆå¤§çš„ä¸åŒã€‚ç»“æ„ä¸Šï¼ŒæŠŠä»¥å‰æ‰€æœ‰å±‚çš„ç‰¹å¾å›¾éƒ½æ²¿ç€é€šé“è½´æ‹¼æ¥èµ·æ¥ï¼ˆè€Œä¸æ˜¯ç›¸åŠ ï¼‰ã€‚è¿™å¯ä»¥ç†è§£ä¸ºå……åˆ†åˆ©ç”¨äº§ç”Ÿè¿‡çš„ç‰¹å¾ã€‚ å¦‚ä¸‹ä¸ºResNetï¼š å¦‚ä¸‹ä¸ºDenseNetï¼š æ¨¡å‹ç‰¹ç‚¹ï¼š å»ºç«‹äº†ä¸åŒå±‚çš„è¿æ¥å…³ç³»ï¼Œå……åˆ†åˆ©ç”¨ç‰¹å¾å›¾ MobileNetMobileNetæ¥æºäºGoogleæå‡ºçš„MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applicationsï¼Œæ˜¯ä¸€ç§å°å·§è€Œé«˜æ•ˆçš„CNNæ¨¡å‹ã€‚ æ¨¡å‹ç»“æ„ï¼šMobileNetçš„æ ¸å¿ƒåœ¨äºæå‡ºäº†æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼Œå®ƒæŠŠä¼ ç»Ÿå·ç§¯åˆ†è§£æˆäº†æ·±åº¦å·ç§¯(depthwise convolution)å’Œé€ç‚¹å·ç§¯(pointwise convolution)ï¼Œä»è€Œå¤§é‡å‡å°‘å‚æ•°é‡ã€‚ å¯¹äºè¾“å…¥ç‰¹å¾å›¾(DF,DF,M)ï¼Œè¾“å‡ºç‰¹å¾å›¾(DG,DG,N)ï¼Œä¼ ç»Ÿå·ç§¯æ ¸çš„å°ºå¯¸ä¸º(K,K,M,N)ï¼Œå¦‚ä¸‹å›¾(a)ã€‚è€Œå¯¹äºæ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼Œæ·±åº¦å·ç§¯çš„å°ºå¯¸ä¸º(K,K,1,M)ï¼Œå®ƒå°†è¿™Mä¸ªå·ç§¯æ ¸å„è‡ªåº”ç”¨äºè¾“å…¥ç‰¹å¾å›¾çš„å„ä¸ªé€šé“ï¼ˆè¿™ä¸ä¼ ç»Ÿå·ç§¯ä¸åŒï¼Œè¿™é‡Œç›¸ä¹˜åä¸éœ€è¦æ²¿ç€é€šé“è½´ç›¸åŠ ï¼‰ï¼Œè¾“å‡ºç‰¹å¾ä¸º(DG,DG,M)ï¼Œå¦‚(b)æ‰€ç¤ºã€‚é€ç‚¹å·ç§¯çš„å°ºå¯¸ä¸º(1,1,M,N)ï¼Œè¿™ä¸ªå°±æ˜¯æ™®é€šçš„1Ã—1å·ç§¯äº†ï¼Œè¾“å‡ºç‰¹å¾ä¸º(DG,DG,N)ï¼Œå¦‚(c)æ‰€ç¤ºã€‚å¯ä»¥çœ‹åˆ°ï¼Œå‚æ•°é‡ä»ï¼ˆKÃ—KÃ—MÃ—Nï¼‰å˜æˆï¼ˆKÃ—KÃ—1Ã—M + 1Ã—1Ã—MÃ—Nï¼‰ï¼Œå‡å°äº† M(KKN - KK -N)ã€‚ æ¨¡å‹ç‰¹ç‚¹ï¼š è½»å‹æ¨¡å‹ï¼Œå¯ç”¨äºç§»åŠ¨ç«¯ ResNeXtResNeXtæ¥æºäºAggregated Residual Transformations for Deep Neural Networksã€‚å®ƒæ˜¯åŸºäºResNetï¼Œå¸æ”¶äº†GoogLeNetçš„Inceptionï¼Œæ‰€ä»¥å’Œè°·æ­Œçš„Inception-ResNetå¾ˆåƒã€‚ æ¨¡å‹ç»“æ„ï¼šå¦‚ä¸‹å›¾ï¼Œå·¦å›¾æ˜¯æ˜¯ResNetï¼Œå³å›¾æ˜¯æ–°çš„ResNeXtã€‚ è¯¥ç»“æ„å¯ä»¥åšå¦‚ä¸‹ç­‰æ•ˆï¼Œç¬¬ä¸‰ç§å°±æ˜¯ç­‰æ•ˆçš„åˆ†ç»„ç»“æ„ã€‚ æ¨¡å‹ç‰¹ç‚¹ï¼š ResNeXtçš„åˆ†æ”¯çš„æ‹“æ‰‘ç»“æ„æ˜¯ç›¸åŒçš„ï¼Œè€ŒInception V4éœ€è¦äººå·¥è®¾è®¡ æå‡ºäº†ä¸€ç§ä»‹äºæ™®é€šå·ç§¯æ ¸æ·±åº¦å¯åˆ†ç¦»å·ç§¯çš„è¿™ç§ç­–ç•¥ï¼šåˆ†ç»„å·ç§¯ XceptionXceptionæ¥æºäºXception: Deep Learning with Depthwise Separable Convolutionsã€‚å®ƒæ˜¯Inception-V3çš„å¦ä¸€ç§æ”¹è¿›ï¼Œå¸æ”¶äº†æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼Œé€ å°±äº†ä¸€ç§å‚æ•°é‡ç›¸å¯¹å°‘ä¸€äº›çš„ç½‘ç»œç»“æ„ã€‚ æ¨¡å‹ç»“æ„ï¼šInception-V3å¯åšå¦‚ä¸‹ç®€åŒ–ï¼Œå¯ä»¥çœ‹åˆ°ï¼Œå¦‚ä¸‹å›¾å’Œæ·±åº¦å¯åˆ†ç¦»å·ç§¯æ˜¯å¾ˆåƒçš„ï¼Œåªæ˜¯ä¸‹å›¾æ˜¯å…ˆè¿›è¡Œ1Ã—1çš„å·ç§¯ï¼Œå†è¿›è¡Œchannel-wiseçš„spatial convolutionï¼Œæœ€åconcatï¼Œè€Œåè€…æ˜¯å…ˆè¿›è¡Œä¸€ä¸ªchannel-wiseçš„spatial convolutionï¼Œç„¶åæ˜¯1Ã—1çš„å·ç§¯ã€‚æ‰€ä»¥ä½œè€…å¹²è„†æŠŠå®ƒæ¢æˆæ·±åº¦å¯åˆ†ç¦»å·ç§¯ã€‚ æœ€ç»ˆæ•´ä½“ç»“æ„å¦‚ä¸‹ï¼Œå…¶ä¸­SeparalbeConvå³æ˜¯æ·±åº¦å¯åˆ†ç¦»å·ç§¯ã€‚ æ¨¡å‹ç‰¹ç‚¹ï¼š è™½ç„¶ä½¿ç”¨äº†æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼Œä½†ç½‘ç»œä¹ŸåŠ å®½äº†ï¼Œæ€»ä½“å‚æ•°é‡å’ŒInception-V3å·®ä¸å¤šï¼Œæ€§èƒ½æå‡äº†ã€‚ æå‡ºæ—¶é—´å’ŒMobileNetç›¸è¿‘ï¼Œå®ƒä»¬ä»ä¸åŒçš„è§’åº¦æ­ç¤ºäº†æ·±åº¦å¯åˆ†ç¦»å·ç§¯çš„å¼ºå¤§ä½œç”¨ï¼ŒMobileNetçš„æ€è·¯æ˜¯é€šè¿‡å°† 3Ã—3 å·ç§¯æ‹†åˆ†çš„å½¢å¼æ¥å‡å°‘å‚æ•°æ•°é‡ï¼Œè€ŒXceptionæ˜¯é€šè¿‡å¯¹Inceptionçš„å……åˆ†è§£è€¦æ¥å®Œæˆçš„ã€‚ ShuffleNetXceptionæ¥æºäºShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devicesã€‚è¿™ä¹Ÿæ˜¯ä¸€æ¬¾æ•ˆç‡æé«˜çš„è½»å‹CNNæ¨¡å‹ï¼Œé€šè¿‡é€ç‚¹ç¾¤å·ç§¯(pointwise group convolution)å’Œé€šé“æ··æ´—(channel shuffle)å¤§å¤§é™ä½è®¡ç®—é‡ã€‚ æ¨¡å‹ç»“æ„ï¼šå¦‚ä¸‹å›¾å·¦æ˜¯æ™®é€šçš„åˆ†ç»„å·ç§¯ï¼Œä½†æ˜¯ç»è¿‡å¤šå±‚åˆ†ç»„å·ç§¯åæŸä¸ªè¾“å‡ºchannelä»…ä»…æ¥è‡ªè¾“å…¥channelçš„ä¸€å°éƒ¨åˆ†ï¼Œå­¦å‡ºæ¥çš„ç‰¹å¾ä¹Ÿå¾ˆå±€é™ï¼Œå› æ­¤ä½œè€…æå‡ºäº†é€šé“æ··æ´—channel shuffleï¼Œè¿‡ç¨‹å¦‚ä¸‹å›¾ä¸­ï¼Œåœ¨è¿›è¡ŒGConv2ä¹‹å‰ï¼Œå¯¹å…¶è¾“å…¥feature mapåšä¸€ä¸ªåˆ†é…ï¼Œä¹Ÿå°±æ˜¯æ¯ä¸ªgroupåˆ†æˆå‡ ä¸ªsubgroupï¼Œç„¶åå°†ä¸åŒgroupçš„subgroupä½œä¸ºGConv2çš„ä¸€ä¸ªgroupçš„è¾“å…¥ï¼Œä½¿å¾—GConv2çš„æ¯ä¸€ä¸ªgroupéƒ½èƒ½å·ç§¯è¾“å…¥çš„æ‰€æœ‰groupçš„feature mapï¼Œç»“æœå›¾ä¸‹å›¾å³ã€‚ pointwise group convolutionï¼Œå…¶å®å°±æ˜¯å¸¦groupçš„å·ç§¯æ ¸ä¸º1Ã—1çš„å·ç§¯ã€‚ä¸‹å›¾å·¦æ˜¯ä¸€ä¸ªæ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼Œè€Œä¸­é—´çš„å›¾åˆ™æ˜¯ä¸€ä¸ªä½¿ç”¨äº†pointwise group convolutionçš„ShuffleNet unitï¼Œå®ƒå°†1Ã—1å·ç§¯å˜æˆåˆ†ç»„å·ç§¯ï¼Œå¹¶åœ¨ç¬¬ä¸€ç»„åˆ†ç»„å·ç§¯ååŠ ä¸Šé€šé“æ··æ´—è€Œæˆã€‚å³è¾¹çš„å›¾åˆ™æ˜¯å¸¦æœ‰é™é‡‡æ ·çš„ShuffleNet unitï¼Œå®ƒä¸€æ–¹é¢åœ¨è¾…åˆ†æ”¯åŠ å…¥æ­¥é•¿ä¸º2çš„3Ã—3å¹³å‡æ± åŒ–ï¼Œä¸€æ–¹é¢å°†æœ€åçš„ç›¸åŠ å˜æˆäº†é€šé“çº§è”ã€‚ æ¨¡å‹ç‰¹å¾ï¼š åº”ç”¨äº†1Ã—1çš„é€šé“å·ç§¯ æå‡ºäº†é€šé“æ··æ´— æ€»ç»“å…¶å®æ€»çš„æ¥è¯´ï¼Œåˆ›æ–°æ€§çš„åº”è¯¥åŒ…å«äº†inceptionï¼Œæ®‹å·®å­¦ä¹ ï¼Œæ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼Œåˆ†ç»„å·ç§¯å‡ ç§ã€‚inceptionæœ‰GoogLeNet V1-V4ã€Xceptionã€ResNeXtã€‚æ®‹å·®å­¦ä¹ æœ‰ResNetã€ResNeXtã€DenseNetã€GoogLeNet V4ã€‚æ·±åº¦å¯åˆ†ç¦»å·ç§¯æœ‰MobileNetã€ShuffleNetã€Xceptionã€‚åˆ†ç»„å·ç§¯æœ‰ResNeXtã€ShuffleNetã€‚","categories":[{"name":"æ·±åº¦å­¦ä¹ æ¨¡å‹","slug":"æ·±åº¦å­¦ä¹ æ¨¡å‹","permalink":"http://weiquanfan.xyz/categories/æ·±åº¦å­¦ä¹ æ¨¡å‹/"}],"tags":[]},{"title":"cvä¸­Attentionçš„å¥‡å¦™æ—…é€”â€”â€”è®²è®²Self-Attention, SENetå’ŒCBAM","slug":"SENet","date":"2020-05-08T07:57:04.000Z","updated":"2020-06-20T06:49:17.115Z","comments":true,"path":"2020/05/08/SENet/","link":"","permalink":"http://weiquanfan.xyz/2020/05/08/SENet/","excerpt":"","text":"å‰è¨€ç”±äºæ³¨æ„åŠ›æœºåˆ¶çš„é«˜é€Ÿå‘å±•ï¼Œæˆ‘å°è¯•ç€å¯¹attentionå½¢æˆä¸€ç§æ¯”è¾ƒç³»ç»ŸåŒ–çš„ç†è§£ï¼Œé€‰äº†æ¯”è¾ƒæœ‰ä»£è¡¨æ€§çš„Self-Attention, SENetå’ŒCBAMï¼Œæ•´ç†æˆæœ¬æ–‡ã€‚ Self-Attentionåœ¨è°·æ­Œå‘è¡¨çš„Attention Is All You Needä¹‹åï¼ŒSelf-Attentionå¼€å§‹å¹¿ä¸ºäººçŸ¥ã€‚æ­£å¦‚æˆ‘æ­¤å‰å¯¹è¿™ç¯‡è®ºæ–‡çš„è®²è§£ï¼Œæœ€ç»ˆçš„æ³¨æ„åŠ›å¯ä»¥è¡¨ç¤ºä¸ºä¸‹å›¾ï¼Œå…¶ä¸­Qä¸ºQueryï¼ŒKä¸ºKeyï¼ŒVä¸ºValueï¼Œä¸‰è€…éƒ½æ˜¯ç”±è¾“å…¥Xç»è¿‡ä¸åŒçš„æ˜ å°„å¾—æ¥çš„ã€‚è¿™ä¸ªå…¬å¼å¯ä»¥è¿™ä¹ˆè®°ï¼Œå…ˆé€šè¿‡ç›¸ä¹˜å¾—åˆ°Queryå’ŒKeyçš„ç›¸ä¼¼åº¦ï¼Œè€Œåå½’ä¸€åŒ–åŠ softmaxæˆä¸ºæ³¨æ„åŠ›æƒé‡ï¼Œè¯¥æƒé‡ä¹˜ä»¥Valueå€¼å°±æ˜¯è¾“å‡ºçš„æ–°è¡¨è¾¾äº†ã€‚ ç„¶è€Œï¼Œè¿™ä¸ªå…¬å¼åœ¨è¿™é‡Œçš„è¾“å…¥Xçš„ç»´åº¦æ˜¯time Ã— embeddingï¼Œé‚£ä¹ˆæ€ä¹ˆç”¨äºä¸‰ç»´çš„å›¾åƒå‘¢ï¼Ÿå¾ˆè‡ªç„¶çš„å¯ä»¥æƒ³åˆ°ï¼Œæ—¶åºä¿¡å·ä¸­çš„æ—¶é—´å¯ä»¥ç±»æ¯”åˆ°å›¾åƒä¸­çš„ç©ºé—´ï¼Œé‚£ä¹ˆåªéœ€è¦æŠŠé•¿å’Œå®½ä¸¤ä¸ªç»´åº¦æ‹‰æˆä¸€ä¸ªç»´åº¦ï¼Œå°±å½¢æˆäº†ä¸€è¡Œåœ°çš„ç©ºé—´ä¿¡æ¯ã€‚é‚£ä¹ˆæ¥ä¸‹æ¥ï¼Œå‰©ä¸‹çš„é€šé“ï¼ˆå•é€šé“æˆ–ä¸‰é€šé“ï¼‰ï¼Œå°±å¯ä»¥ç±»æ¯”æˆæ—¶åºä¿¡å·ä¸­tokençš„embeddingã€‚å› æ­¤ï¼ŒSelf-Attentionå…¬å¼åœ¨å›¾åƒä¸Šçš„è¾“å…¥çš„ç»´åº¦æ˜¯spatial Ã— channelã€‚é‚£ä¹ˆï¼Œå›¾åƒä¸Šçš„Self-Attentionæœ¬è´¨ä¸Šæ˜¯è®¡ç®—ä¸€ç§ç©ºé—´æƒé‡ã€‚ SENet2017å¹´Squeeze-and-Excitation Networksè·å¾—äº†ILSVRCçš„å† å†›ï¼Œä½¿å¾—SENetåå£°å¤§å™ªã€‚å…¶å®è¿™ç¯‡è®ºæ–‡çš„æ ¸å¿ƒåœ¨äºæå‡ºäº†ä¸€ç§å¾ˆæ–¹ä¾¿åµŒå…¥å…¶ä»–æ¨¡å‹çš„æ¨¡å—â€”â€”â€”â€”SE blockã€‚å®ƒçš„ç»“æ„å›¾å¦‚ä¸‹ã€‚å‰è¾¹æ˜¯ä¼ ç»Ÿçš„å·ç§¯æ“ä½œï¼Œå¾—åˆ°äº†ç‰¹å¾å›¾U(H x W x C)ã€‚è€Œåçœ‹ä¸Šè¾¹çš„æ”¯è·¯ï¼Œå…±æœ‰ä¸¤ä¸ªæ“ä½œï¼Œä¸€ä¸ªæ˜¯Squeezeä¸€ä¸ªæ˜¯Excitationï¼Œå¯ä»¥å¾—åˆ°ä¸€ä¸²é€šé“ä¸Šçš„æ³¨æ„åŠ›æƒé‡ï¼Œå†æŠŠå®ƒä¹˜è¿›å„ä¸ªé€šé“ï¼Œå°±å¾—åˆ°äº†æ–°çš„ç‰¹å¾å›¾ã€‚ Squeezeæ“ä½œå¯¹Uè¿›è¡ŒGlobal Average Poolingï¼Œå¾—åˆ°ä¸€ä¸²(1 x 1 x C)çš„æƒé‡ï¼Œè¿™é‡Œå°±æ˜¯æ³¨æ„åŠ›çš„é›å½¢äº†ï¼Œæ¯”èµ·ä¸€å¼€å§‹Selfæ³¨æ„åŠ›çš„QKçŸ©é˜µçœŸæ˜¯ç®€å•ç²—æš´äº†å¾ˆå¤šã€‚ Excitationæ“ä½œä¹Ÿå¾ˆç›´æ¥ï¼Œå°±æ˜¯æŠŠåˆšæ‰å¾—åˆ°çš„æƒé‡ç»è¿‡ä¸¤å±‚å…¨è¿æ¥å±‚ï¼ˆåè¾¹å¸¦ReLUï¼‰å†åŠ ä¸€å±‚Sigmoidã€‚è‡³äºä¸¤å±‚å…¨è¿æ¥çš„ç¥ç»å…ƒæ•°ï¼Œç¬¬ä¸€å±‚æ˜¯è¾“å…¥Cä¸ªè€Œè¾“å‡ºC/rä¸ªç¥ç»å…ƒï¼Œç¬¬äºŒæ¬¡åˆ™æ˜¯è¾“å…¥C/rè€Œè¾“å‡ºCä¸ªç¥ç»å…ƒã€‚å¯ä»¥çœ‹æˆä¸€ç§å‹ç¼©å†æ¢å¤çš„è¿‡ç¨‹ï¼Œrè¡¨ç¤ºå‹ç¼©ç¨‹åº¦ã€‚ä½œè€…çš„å®éªŒè¡¨æ˜rå–16æ—¶æ•ˆæœæ¯”è¾ƒå¥½ã€‚æ‰€ä»¥ï¼Œå›¾åƒä¸Šçš„SENetæœ¬è´¨ä¸Šæ˜¯è®¡ç®—ä¸€ç§é€šé“æƒé‡ã€‚ CBAMç°åœ¨æˆ‘ä»¬çŸ¥é“äº†æœ‰ç©ºé—´çš„æ³¨æ„åŠ›ï¼Œæœ‰é€šé“çš„æ³¨æ„åŠ›ï¼Œé‚£ä¹ˆä¹Ÿå¯ä»¥æƒ³åˆ°ä¸€ç§ä¸¤è€…éƒ½æœ‰çš„æ³¨æ„åŠ›ã€‚CBAM: Convolutional Block Attention Moduleå°±å¹²äº†è¿™ä¹ˆä¸€ä»¶äº‹ã€‚å®ƒä¹Ÿæ˜¯ä¸€ç§å¯åµŒå…¥çš„æ¨¡å—ï¼Œç»“æ„å›¾å¦‚ä¸‹,åŒ…å«é€šé“æ³¨æ„åŠ›æ¨¡å—å’Œç©ºé—´æ³¨æ„åŠ›æ¨¡å—ã€‚ è¿™é‡Œåˆ†åˆ«è®²è§£è¿™ä¸¤ç§æ¨¡å—ã€‚ é€šé“æ³¨æ„åŠ›æ¨¡å— é€šé“æ³¨æ„åŠ›æ¨¡å—å…¶å®åŸºæœ¬å°±æ˜¯SE blockï¼Œä¸åŒç‚¹åœ¨äºé™¤äº†SEç”¨çš„AvgPoolä¹‹å¤–è¿˜ç”¨äº†MaxPoolï¼Œç›¸å½“äºæœ‰ä¸¤ç§Squeezeæ–¹å¼ï¼Œè€Œåå¾—åˆ°çš„ä¸¤ä¸²æ³¨æ„åŠ›é›å½¢å„è‡ªåŒæ ·ç»è¿‡ä¸¤å±‚å¸¦ReLUçš„å…¨è¿æ¥å±‚ï¼ˆæ³¨æ„è¿™é‡Œavgå’Œmaxä½¿ç”¨çš„å…¨è¿æ¥æ˜¯å…±äº«çš„ï¼Œæœ‰ç‚¹å¥‡æ€ªï¼Œä¸ªäººæ„Ÿè§‰ä¸å…±äº«ä¼šå¥½ä¸€äº›ï¼‰ï¼Œç›¸åŠ èµ·æ¥å†ç»è¿‡Sigmoidï¼Œå°±å¾—åˆ°äº†é€šé“ä¸Šçš„æ³¨æ„åŠ›ï¼Œç„¶åä¹˜å›å»å¾—åˆ°äº†é€šé“ä¸Šæ›´æ–°äº†çš„ç‰¹å¾å›¾ã€‚ ç©ºé—´æ³¨æ„åŠ›æ¨¡å— ç©ºé—´æ³¨æ„åŠ›æ¨¡å—å¯ä»¥è¯´æ˜¯ç”¨Selfçš„æ€æƒ³å’ŒSENetçš„æ“ä½œå½¢æˆçš„ã€‚å¯ä»¥çœ‹åˆ°ï¼Œåˆšæ‰çš„é€šé“æ³¨æ„åŠ›æ˜¯åœ¨ç©ºé—´ä¸Šè¿›è¡ŒPoolï¼Œé‚£ä¹ˆï¼Œç©ºé—´æ³¨æ„åŠ›æ˜¯ä¸æ˜¯ä¹Ÿå¯ä»¥åœ¨é€šé“ä¸Šè¿›è¡ŒPoolå‘¢ï¼Ÿè¿™å°±å½¢æˆäº†ç©ºé—´æ³¨æ„åŠ›æ¨¡å—ã€‚é¦–å…ˆï¼Œå®ƒåŸºäºé€šé“ä¸Šè¿›è¡Œglobal max pooling å’Œglobal average poolingï¼Œå¾—åˆ°çš„ä¸¤å¼ ç©ºé—´å›¾æ‹¼æ¥ä¸€ä¸‹å½¢æˆ2é€šé“ï¼Œå†è¿›è¡Œä¸€ä¸‹å·ç§¯(å®éªŒè¡¨æ˜7 * 7å·ç§¯æ•ˆæœå¥½äº›)é™æˆå•é€šé“ï¼Œç±»ä¼¼çš„ç»è¿‡ä¸€ä¸ªSigmoidï¼Œå°±å¾—åˆ°äº†ç©ºé—´æ³¨æ„åŠ›æƒé‡ã€‚ä¹˜å›å»å°±å¾—åˆ°äº†ç©ºé—´ä¸Šæ›´æ–°äº†çš„ç‰¹å¾å›¾ã€‚ æ‰€ä»¥ï¼ŒCBAMåŸºäºsenetçš„é€šé“æ³¨æ„åŠ›ï¼Œå¼•å…¥ç©ºé—´æ³¨æ„åŠ›ï¼Œæœ¬è´¨ä¸Šæ˜¯è®¡ç®—äº†é€šé“å’Œç©ºé—´çš„æƒé‡ã€‚ æ€»ç»“ç»è¿‡è¿™ä¹ˆä¸€ä¸ªæµç¨‹å¯ä»¥çœ‹åˆ°ï¼š æ³¨æ„åŠ›å°±æ˜¯è®¡ç®—é€šé“(åµŒå…¥)å’Œç©ºé—´(æ—¶é—´)çš„æ³¨æ„åŠ›æƒé‡ï¼ŒSelfæ˜¯ç©ºé—´ï¼ŒSENetæ˜¯é€šé“ï¼ŒCBAMæ˜¯ç©ºé—´åŠ é€šé“ã€‚ç”šè‡³äºç©ºé—´ä¸Šçš„æ³¨æ„åŠ›è¿˜å¯ä»¥æ‹†åˆ†ï¼Œåªæœ‰æ¨ªè½´çš„æ³¨æ„åŠ›æˆ–åªæœ‰çºµè½´çš„æ³¨æ„åŠ›ï¼Œè¿™äº›éƒ½è§†å®é™…è¾“å…¥çš„å›¾åƒéœ€æ±‚æ¥é€‰æ‹©ã€‚ æ³¨æ„åŠ›çš„å½¢å¼å˜å¾—ç®€å•ã€‚ä¸€å¼€å§‹çš„Selféœ€è¦ç»è¿‡QKçŸ©é˜µç®—å‡ºä¸€ä¸ªä¸‰ç»´ï¼ˆnlpä¸­æ˜¯äºŒç»´ï¼Œç©ºé—´æ‹‰å‡ºé•¿å®½å°±å˜æˆäº†ä¸‰ç»´ï¼‰çš„æ³¨æ„åŠ›æƒé‡ï¼Œè¡¨ç¤ºç©ºé—´ä¸Šæ¯ä¸€ä¸ªç‚¹ä¸ç©ºé—´ä¸Šæ‰€æœ‰ç‚¹çš„æ³¨æ„åŠ›ã€‚CBAMä¸­çš„ç©ºé—´æ³¨æ„åŠ›æ¨¡å—ï¼Œåªéœ€ç»è¿‡poolingå’Œä¸€äº›ç®€å•çš„å…¶å®ƒæ“ä½œå³å¾—åˆ°äº†ä¸€ä¸ªäºŒç»´çš„æ³¨æ„åŠ›æƒé‡ï¼Œè¡¨ç¤ºä¸€ç§æ•´ä½“ä¸Šåº”è¯¥å…³æ³¨ç©ºé—´ä¸Šçš„å“ªäº›ä½ç½®ã€‚","categories":[{"name":"æ·±åº¦å­¦ä¹ æ¨¡å‹","slug":"æ·±åº¦å­¦ä¹ æ¨¡å‹","permalink":"http://weiquanfan.xyz/categories/æ·±åº¦å­¦ä¹ æ¨¡å‹/"}],"tags":[{"name":"attention","slug":"attention","permalink":"http://weiquanfan.xyz/tags/attention/"}]},{"title":"è®²è®²æ¨ªæ‰«nlpä»»åŠ¡çš„BERTæ¨¡å‹","slug":"BERT","date":"2020-05-07T08:08:20.000Z","updated":"2020-06-20T06:36:37.133Z","comments":true,"path":"2020/05/07/BERT/","link":"","permalink":"http://weiquanfan.xyz/2020/05/07/BERT/","excerpt":"","text":"å‰è¨€æœ¬æ–‡è®²è§£Googleåœ¨2019å¹´å‘è¡¨çš„è®ºæ–‡BERT: Pre-training of Deep Bidirectional Transformers forLanguage Understanding ã€‚ä»æ ‡é¢˜å¯ä»¥çœ‹å‡ºï¼Œè¯¥è®ºæ–‡åŸºäºTransformeræ¨¡å‹ï¼Œæå‡ºäº†ä¸€æ¬¾ç”¨äºè¯­è¨€ç†è§£çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¹¶åœ¨GLUE, SQuADç­‰nlpä»»åŠ¡ä¸­éƒ½å–å¾—äº†å¾ˆå¥½çš„æ•ˆæœã€‚è¯¥æ¨¡å‹çš„åˆ›æ–°ç‚¹å®é™…ä¸Šä¸åœ¨äºæ¨¡å‹ç»“æ„ï¼Œè€Œåœ¨äºé¢„è®­ç»ƒçš„æ–¹æ³•ã€‚ä»¥ä¸‹å›´ç»•è¿™ä¸¤æ–¹é¢éƒ½è¿›è¡Œä¸€äº›è®²è§£ã€‚ æ¨¡å‹ç»“æ„æ€»ä½“æ¡†å›¾é¦–å…ˆæœ€å¥½è¿˜æ˜¯å…ˆç†è§£ä¸€ä¸‹Transfomerï¼Œè¿™æ˜¯BERTæ¨¡å‹çš„åŸºç¡€æ‰€åœ¨ã€‚ç®€è€Œè¨€ä¹‹ï¼ŒTransfomeråŒ…å«Nä¸ªç¼–ç å™¨å’Œè§£ç å™¨ã€‚ç¼–ç å™¨å°†è¾“å…¥åºåˆ—ç¼–ç æˆå¸¦æœ‰å…¨å±€æ–°çš„ç‰¹å¾åºåˆ—ï¼Œè§£ç å™¨å°†ç¼–ç å™¨çš„ç‰¹å¾åºåˆ—è§£ç æˆé¢„æµ‹ç»“æœã€‚BERTä½¿ç”¨çš„æ­£æ˜¯å…¶ä¸­çš„ç¼–ç å™¨ï¼Œæ¨¡å‹å¦‚ä¸‹æ‰€ç¤ºã€‚ æ³¨æ„ï¼šå¹¶ä¸æ˜¯ä¸€ä¸ªTmä»£è¡¨ä¸€ä¸ªTransformerï¼Œå¯ä»¥çœ‹æˆä¸€è¡ŒTmè¡¨ç¤ºä¸€ä¸ªTransformerçš„ç¼–ç å™¨ï¼Œè€Œç¼–ç å™¨ä¹Ÿä¸æ˜¯ä¸¤å±‚å¯ä»¥æœ‰å¤šå±‚ã€‚é‚£ä¹ˆï¼Œè¾“å…¥åºåˆ—é€å…¥BERTåï¼Œæœ€åä¸€å±‚Tmå°†å¯¹æ¯ä¸€ä¸ªè¾“å…¥tokenéƒ½ç”Ÿæˆä¸€ä¸ªæ–°çš„ç‰¹å¾åºåˆ—ï¼Œè€ŒTåˆ™è¡¨ç¤ºä»»åŠ¡ï¼Œä¸€èˆ¬éƒ½æ˜¯ç”¨å…¨è¿æ¥å±‚æ¥å®Œæˆåˆ†ç±»ä»»åŠ¡ã€‚å¦å¤–ç”¨æ¥å¯¹æ¯”çš„æ˜¯ï¼Œä¸GPTæ˜¯å•å‘çš„Transformerè¿æ¥ï¼ŒELMoæ˜¯åŒå‘çš„LSTMè¿æ¥ã€‚ Embeddingä»æ¡†å›¾ä¸Šå¯ä»¥çœ‹åˆ°ï¼Œè¾“å…¥åºåˆ—æ˜¯å„tokençš„embeddingã€‚åœ¨Transfomerä¸­ï¼Œè¿™ç§åµŒå…¥ç”±word embeddingåŠ ä¸Špositional embeddingè€Œæ¥ã€‚è€Œåœ¨BERTä¸­ï¼Œè¿˜è¦é¢å¤–åŠ ä¸Šä¸€ä¸ªsegment embeddingï¼Œç”¨äºæŒ‡ç¤ºå„ä¸ªtokenå±äºè¾“å…¥çš„ç¬¬å‡ ä¸ªå¥å­ã€‚è¿™æ˜¯å› ä¸ºæœ‰çš„nlpä»»åŠ¡æ˜¯è¾“å…¥ä¸€å¯¹å¥å­çš„ï¼Œéœ€è¦å€Ÿæ­¤åŠ ä»¥åŒºåˆ†ã€‚è€Œä¸”ï¼Œpositional embeddingä¹Ÿä¸æ˜¯æ²¿ç”¨ä¸‰è§’å‡½æ•°ï¼Œä¸‰ç§embeddingéƒ½æ˜¯å­¦ä¹ å‡ºæ¥çš„ã€‚å¦å¤–ï¼Œä¸€å¼€å§‹çš„tokenï¼Œé™¤äº†è¦åœ¨ä¸€å¼€å§‹æ·»åŠ ä¸€ä¸ªèµ·å§‹æ ‡å¿—[CLS]ä¹‹å¤–ï¼Œè¿˜è¦åœ¨ä¸åŒå¥å­çš„è¿‡æ¸¡ä½ç½®æ’ä¸€ä¸ª[SEP]æ ‡å¿—ï¼ˆå¦‚æœæœ‰å¤šå¥å­çš„è¯ï¼‰ã€‚ è¿ç§»ç­–ç•¥BERTæ˜¯ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦æ€ä¹ˆæ‹¿è¿‡æ¥ç”¨å‘¢ï¼Ÿå®˜æ–¹ä¸ºæˆ‘ä»¬æä¾›äº†å„ç§ä»»åŠ¡çš„åº”ç”¨æ–¹æ³•ã€‚é¦–å…ˆï¼ŒNLPçš„ä¸‹æ¸¸ä»»åŠ¡å¯ä»¥åˆ†ä¸º4ç±»ï¼š å¥å­å…³ç³»åˆ¤æ–­ï¼šè¯†åˆ«è•´å«(entailment)ã€è¯†åˆ«è¯­ä¹‰ç›¸ä¼¼ç­‰ åˆ†ç±»ä»»åŠ¡ï¼šæ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿè®¡ç®—ç­‰ åºåˆ—æ ‡æ³¨ï¼šåˆ†è¯ã€å®ä½“è¯†åˆ«ã€è¯­ä¹‰æ ‡æ³¨ç­‰ ç”Ÿæˆå¼ä»»åŠ¡ï¼šæœºå™¨ç¿»è¯‘ã€æ–‡æœ¬æ‘˜è¦ç­‰ å›¾ä¸­ (a) è§£å†³çš„æ˜¯å¥å­å…³ç³»åˆ¤æ–­é—®é¢˜ï¼ŒMultiNLI(è¯†åˆ«è•´å«ï¼ŒMæ¨ç†å‡ºNï¼Œè•´å«/çŸ›ç›¾/ä¸­ç«‹ï¼‰ï¼ŒQQPï¼ˆè¯†åˆ«è¯­ä¹‰ç›¸ä¼¼ï¼‰ï¼ŒQNLIï¼ˆè¯†åˆ«æ˜¯å¦å›ç­”äº†é—®é¢˜ï¼‰ï¼ŒSTS-Bï¼ˆè¯†åˆ«è¯­ä¹‰ç›¸ä¼¼ï¼‰ï¼ŒMRPCï¼ˆè¯†åˆ«è¯­ä¹‰ç­‰ä»·ï¼Œå¾®è½¯ï¼‰ã€RTEï¼ˆè¯†åˆ«è•´å«ï¼Œå°æ•°æ®ï¼‰ï¼ŒSWAGï¼ˆè¯†åˆ«å›ç­”é—®é¢˜ï¼Œå¤§æ•°æ®)ã€‚(b) è§£å†³çš„æ˜¯åˆ†ç±»ä»»åŠ¡ï¼ŒSST-2ï¼ˆæƒ…æ„Ÿè®¡ç®—ï¼Œæ–¯å¦ç¦ï¼‰ï¼ŒCoLAï¼ˆå¥å­è¯­è¨€æ€§åˆ¤æ–­ï¼Œæ˜¯å¦èƒ½æˆå¥ï¼‰ã€‚(c) è§£å†³çš„æ˜¯åºåˆ—æ ‡æ³¨ä»»åŠ¡ï¼ŒSQuADï¼ˆåˆ¤æ–­å›ç­”çš„èµ·å§‹å’Œç»“æŸæ—¶åˆ»ï¼Œæ–¯å¦ç¦é—®ç­”æ•°æ®é›†ï¼Œä»phraseä¸­é€‰å–answerï¼‰ã€‚(d) è§£å†³çš„æ˜¯åºåˆ—æ ‡æ³¨ä»»åŠ¡ï¼ŒNERï¼ˆå‘½åå®ä½“è¯†åˆ«ï¼‰ã€‚æ€»çš„æ¥è¯´ (a) å’Œ (b) éƒ½æ˜¯åˆ†ç±»ä»»åŠ¡ï¼Œå·®åˆ«åœ¨äºè¾“å…¥çš„æ˜¯ä¸€ä¸ªå¥å­è¿˜æ˜¯ä¸€å¯¹å¥å­ã€‚è¿™ç±»ä»»åŠ¡ï¼Œåªéœ€é€šè¿‡åœ¨ç¬¬ä¸€ä¸ªtokenï¼ˆå³[CLS]æ ‡å¿—ï¼‰çš„ç‰¹å¾åºåˆ—é€å…¥å…¨è¿æ¥å±‚å³å¯è·å–è¯†åˆ«ç»“æœã€‚(c) å’Œ (d) éƒ½æ˜¯åºåˆ—æ ‡æ³¨ä»»åŠ¡ï¼Œè¿™ç±»åˆ™åœ¨å¤šä¸ªtokençš„ç‰¹å¾åºåˆ—é€å…¥å…¨è¿æ¥å±‚ï¼Œè·å–å„è‡ªçš„æ ‡æ³¨ç»“æœã€‚å¯ä»¥çœ‹åˆ°ï¼Œç›®å‰åªæœ‰ç”Ÿæˆå¼ä»»åŠ¡è¿˜æ²¡æœ‰è¢«koã€‚ p.s. å¤§åé¼é¼çš„GLUEä»»åŠ¡é›†åˆ™åŒ…å«äº†MultiNLIã€QQPã€QNLIã€STS-Bã€MRPCã€RTEã€WNLI(ä¹Ÿæ˜¯è¯†åˆ«è•´å«)ã€SST-2ã€CoLAã€‚ é¢„è®­ç»ƒæ–¹æ³•å¸¸è§çš„é¢„è®­ç»ƒæ–¹æ³•ä¸€èˆ¬æ˜¯ç»™å‰é¢çš„åºåˆ—å»é¢„æµ‹ä¸‹ä¸€ä¸ªtokenï¼ˆåƒæ˜¯GPTï¼‰ã€‚è€ŒBERTå°±æå‡ºäº†ä¸¤ä¸ªæ¯”è¾ƒæœ‰æ„æ€çš„è®­ç»ƒä»»åŠ¡ â€”â€” Masked LM å’Œ Next Sentence Predictionã€‚ Masked LMä¸ºäº†å®ç°æ¨¡å‹çš„åŒå‘ï¼Œå°±ä¸èƒ½ä¸€ç›´ç»™å®šå‰é¢é¢„æµ‹åé¢ï¼Œäºæ˜¯ä½œè€…æå‡ºäº†ä¸€ä¸ªtrickã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œéšæœºmaskæ‰15%çš„tokenï¼Œå³æŠŠç›¸åº”ä½ç½®çš„tokenæ›¿æ¢æˆä¸€ä¸ª[MASK]æ ‡è¯†ï¼Œè€Œä»»åŠ¡çš„ç›®æ ‡å°±æ˜¯è¦å»æ¢å¤è¿™ä¸ªå¥å­ï¼ˆåŒ…å«MASKçš„è¯ï¼‰ï¼Œè€ŒæŸå¤±å‡½æ•°åªè€ƒè™‘äº†MASKä½ç½®çš„é¢„æµ‹å€¼ï¼Œå¿½è§†æ‰émaskedçš„å€¼ã€‚è¿™æ ·ï¼ŒMASKçš„è¯å¯å‰å¯åï¼Œå°±å®ç°äº†æ¨¡å‹çš„åŒå‘æ€§ã€‚ ç”±æ­¤ä¹Ÿè¡ç”Ÿå‡ºäº†ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯åœ¨å®é™…é¢„æµ‹çš„æ—¶å€™æ˜¯ä¸ä¼šç¢°åˆ°[MASK]çš„ï¼Œç”¨äº†å¤ªå¤š[MASK]å°±å®¹æ˜“å½±å“åˆ°æ¨¡å‹ã€‚æ‰€ä»¥ä½œè€…åˆç”¨äº†ä¸ªå°æŠ€å·§ï¼Œé€‰ä¸­äº†è¦maskçš„tokenåï¼Œå…¶ä¸­10%çš„tokenä¼šè¢«æ›¿ä»£æˆå…¶ä»–tokenï¼Œ10%çš„tokenä¸æ›¿æ¢ï¼Œå‰©ä¸‹çš„80%æ‰è¢«æ›¿æ¢ä¸º[MASK]ã€‚ Next Sentence Predictionç”±äºnlpä¸­å­˜åœ¨éœ€è¦è¾“å…¥ä¸¤ä¸ªå¥å­çš„å¥å­å…³ç³»åˆ¤æ–­ä»»åŠ¡ï¼Œæ‰€ä»¥éœ€è¦å¢è®¾ä¸€ä¸ªè®©æ¨¡å‹ç†è§£å¥å­ä¹‹é—´å…³ç³»çš„ä»»åŠ¡ï¼Œäºæ˜¯Next Sentence Predictionåº”è¿è€Œç”Ÿã€‚å…·ä½“è€Œè¨€ï¼Œå°±æ˜¯è¾“å…¥ä¸¤ä¸ªå¥å­ï¼Œç”±æ¨¡å‹æ¥åˆ¤æ–­è¿™ä¸¤ä¸ªå¥å­æ˜¯ä¸æ˜¯è¿ç»­çš„ä¸Šä¸‹å¥ã€‚å…¶ä¸­ï¼Œä¸ºäº†ä¿æŒæ ·æœ¬å¹³è¡¡æ€§ï¼Œé€‰äº†50%çš„è¿ç»­çš„æ­£æ ·æœ¬ï¼Œå†éšæœºé€‰50%çš„æ— å…³çš„è´Ÿæ ·æœ¬ã€‚å…¶å®è¿™ä¸ªä»»åŠ¡å’Œseq2seqçš„ä»»åŠ¡æœ‰ç‚¹å¼‚æ›²åŒå·¥ä¹‹å¦™ï¼Œåªæ˜¯ä»å•è¯çº§åˆ«å˜åˆ°äº†å¥å­çº§åˆ«ã€‚ä¸¾ä¸ªä¾‹å­ï¼šæ­£æ ·æœ¬ï¼šä»Šå¤©[MASK]ï¼ˆå¤©æ°”ï¼‰çœŸå¥½ï¼Œæ­£å¥½æˆ‘ä»¬[MASK]ï¼ˆå‡ºå»ï¼‰åƒé¥­å§ã€‚è´Ÿæ ·æœ¬ï¼šä»Šå¤©[MASK]ï¼ˆå¤©æ°”ï¼‰çœŸå¥½ï¼Œ[MASK]ï¼ˆæˆ‘ï¼‰åƒé¥±äº†ã€‚ æ€»ç»“å…¶å®BERTæ¨¡å‹é™¤äº†æå‡ºè¿™ä¸¤ç§è®­ç»ƒæ–¹æ³•å¤–ï¼Œå¤§é‡çš„æ•°æ®è‚¯å®šå¯¹è¿™ä¸ªé¢„è®­ç»ƒæ¨¡å‹æœ‰å¾ˆå¼ºçš„ä½œç”¨ï¼Œä¸è¿‡ä¸€èˆ¬äººæ²¡è¿™ç§è®¡ç®—èµ„æºâ€¦æ‰€ä»¥è¿˜æ˜¯å¾ˆæ„Ÿè°¢è°·æ­Œå¼€æºå‡ºæ¥çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿çš„ä½¿ç”¨å¹¶è¾¾åˆ°éå¸¸å¥½çš„æ•ˆæœã€‚åœ¨ä½¿ç”¨æ—¶ï¼Œå¦‚æœéœ€è¦ç”¨åˆ°è‡ªå·±çš„æ•°æ®åº“ä¸Šï¼Œè¦ä¹ˆå°±æ˜¯å®Œå…¨è‡ªå·±å†™ç„¶åå¯¼å…¥BERTæ¨¡å‹ï¼Œè¦ä¹ˆå¯ä»¥ç›´æ¥ä½¿ç”¨å®˜æ–¹çš„ä»£ç ï¼Œå¦‚run_glue.pyï¼Œåªéœ€è¦ä¿®æ”¹æ•°æ®çš„é¢„å¤„ç†ï¼Œå®šä¹‰å¥½æ–°çš„ç±»ï¼Œç„¶åæŒ‡å®šç±»åˆ«æ•°ç­‰å‚æ•°ï¼Œå°±å¯ä»¥ç›´æ¥ä½¿ç”¨äº†ã€‚ å‚è€ƒæ–‡çŒ®https://www.cnblogs.com/rucwxb/p/10277217.htmlhttps://zhuanlan.zhihu.com/p/46652512","categories":[{"name":"æ·±åº¦å­¦ä¹ æ¨¡å‹","slug":"æ·±åº¦å­¦ä¹ æ¨¡å‹","permalink":"http://weiquanfan.xyz/categories/æ·±åº¦å­¦ä¹ æ¨¡å‹/"}],"tags":[{"name":"BERT","slug":"BERT","permalink":"http://weiquanfan.xyz/tags/BERT/"},{"name":"Transformer","slug":"Transformer","permalink":"http://weiquanfan.xyz/tags/Transformer/"},{"name":"GLUE","slug":"GLUE","permalink":"http://weiquanfan.xyz/tags/GLUE/"}]},{"title":"Transfomerä»¥åŠSelf-Attentionè®²è§£","slug":"transfomer","date":"2020-05-05T12:23:39.000Z","updated":"2020-06-20T07:02:34.144Z","comments":true,"path":"2020/05/05/transfomer/","link":"","permalink":"http://weiquanfan.xyz/2020/05/05/transfomer/","excerpt":"","text":"å‰è¨€è¿™ä¸€ç¯‡ä¸»è¦è®²è§£è°·æ­Œå‘è¡¨çš„Attention Is All You Needã€‚è¿™ç¯‡è®ºæ–‡æå‡ºäº†é©°åçš„ä¸€ç§æ³¨æ„åŠ›æœºåˆ¶ â€”â€” self-attention æ¨¡å—ï¼Œå¹¶è¿›ä¸€æ­¥æå‡ºäº† Transformer æ¶æ„ï¼Œä»è€Œå°†ä»¥å¾€ç”¨çš„è®¡ç®—ä»£ä»·è¾ƒå¤§çš„RNNæ›¿æ¢æ‰äº†ã€‚ç›®å‰ï¼Œnlpä»»åŠ¡ä¸­æ•ˆæœéå¸¸å¥½çš„BERTæ¨¡å‹å°±æ˜¯å¤§é‡åº”ç”¨äº†Transformeræ¶æ„çš„Encoderã€‚ ä¸‹è¾¹æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ä½¿ç”¨Transformerè¿›è¡Œæœºå™¨ç¿»è¯‘ä»»åŠ¡çš„ä¾‹å­ã€‚åœ¨é¢„æµ‹è¿‡ç¨‹ä¸­ï¼Œç¼–ç é˜¶æ®µï¼Œè¾“å…¥çš„â€œI arrived at theâ€ä¸­çš„æ¯ä¸ªå•è¯éƒ½ä¼šè®¡ç®—ä¸æ‰€æœ‰å•è¯çš„æ³¨æ„åŠ›æƒé‡ï¼Œå¹¶åŠ æƒæ±‚å’Œå¾—å‡ºæ–°çš„è‡ªå·±çš„è¡¨ç¤ºï¼Œé€å±‚ç¼–ç ã€‚è§£ç é˜¶æ®µï¼Œè¾“å…¥ç”±encoderå‡ºæ¥çš„æ‰€æœ‰å•è¯çš„è¡¨ç¤ºå’Œä¸Šä¸€ä¸ªä½ç½®è¾“å‡ºçš„embeddingï¼Œç»è¿‡ç±»ä¼¼çš„æ³¨æ„åŠ›æ“ä½œå¾—åˆ°è¿™ä¸€ä¸ªä½ç½®çš„è¾“å‡ºï¼Œæ˜¯ä¸€ç§éšç€é¢„æµ‹ä½ç½®ç§»åŠ¨çš„è¿­ä»£è¿‡ç¨‹ã€‚æˆ³æˆ‘çœ‹ä¾‹å­ æ€»ä½“æ¡†æ¶ä¸æµç¨‹æ¡†æ¶å¯¹ç…§ç€ä»¥ä¸Šä¾‹å­ï¼Œçœ‹ä¸‹è¾¹çš„Transfomeræ€»ä½“æ¡†æ¶å›¾ã€‚å·¦è¾¹ä¸ºç¼–ç å™¨ï¼Œå³è¾¹ä¸ºè§£ç å™¨ã€‚ç¼–ç å™¨å’Œè§£ç å™¨ä¸­éƒ½åŒ…å«äº†Positional Encodingæ¨¡å—ï¼ŒMulti-Head Attentionæ¨¡å—ï¼ŒFeed-Forwardæ¨¡å—ã€‚ä¸‹ä¸€ç« èŠ‚ä¼šå¯¹æ­¤ç€é‡è®²è§£ã€‚ æµç¨‹å®šä¹‰ä¸€ä¸‹ç¬¦å·ã€‚ emb_dimï¼šåµŒå…¥çš„å°ºå¯¸ input_lengthï¼šè¾“å…¥åºåˆ—çš„é•¿åº¦ target_lengthï¼šç›®æ ‡åºåˆ—çš„é•¿åº¦+1ã€‚+1æ˜¯å› ä¸ºè¦ç§»ä½ã€‚ vocab_sizeï¼šç›®æ ‡è¯æ±‡è¡¨ä¸­çš„å•è¯æ•°é‡ã€‚ åˆ™Transformerçš„æµç¨‹å¯è¡¨ç¤ºä¸ºï¼š è¯¥æ¨¡å‹å°†æ¯ä¸ªtokenè¡¨ç¤ºä¸ºç»´åº¦emb_dimçš„å‘é‡ã€‚ç„¶åï¼Œå¯¹äºç‰¹å®šçš„è¾“å…¥åºåˆ—ï¼Œæˆ‘ä»¬æœ‰äº†å°ºå¯¸ä¸ºï¼ˆinput_lengthï¼‰xï¼ˆemb_dimbï¼‰çš„çŸ©é˜µã€‚ ç„¶åæ·»åŠ ä½ç½®ä¿¡æ¯ï¼ˆä½ç½®ç¼–ç ï¼‰ã€‚ä¸ä¸Šä¸€æ­¥ä¸€æ ·ï¼Œæ­¤æ­¥éª¤å°†è¿”å›å°ºå¯¸ä¸ºï¼ˆinput_lengthï¼‰xï¼ˆemb_dimï¼‰çš„çŸ©é˜µã€‚ æ•°æ®é€šè¿‡N=6ä¸ªç¼–ç å™¨å—ã€‚ä¹‹åï¼Œæˆ‘ä»¬è·å¾—å°ºå¯¸ä¸ºï¼ˆinput_lengthï¼‰xï¼ˆemb_dimï¼‰çš„çŸ©é˜µã€‚ ç›®æ ‡åºåˆ—ç»è¿‡ç­‰åŒäº1å’Œ2çš„æ“ä½œï¼Œå¹¶è¿›è¡Œmaskå±è”½ã€‚è¾“å‡ºçš„å°ºå¯¸ä¸ºï¼ˆtarget_lengthï¼‰xï¼ˆemb_dimï¼‰ã€‚ 4çš„ç»“æœç»è¿‡N=6ä¸ªè§£ç å™¨å—ã€‚åœ¨æ¯ä¸ªè¿­ä»£ä¸­ï¼Œè§£ç å™¨éƒ½ä½¿ç”¨ç¼–ç å™¨çš„è¾“å‡º3ï¼‰ã€‚è¿™åœ¨æ€»æ¡†å›¾ä¸­ç”±ä»ç¼–ç å™¨åˆ°è§£ç å™¨çš„ç®­å¤´è¡¨ç¤ºã€‚è¾“å‡ºçš„å°ºå¯¸ä¸ºï¼ˆtarget_lengthï¼‰xï¼ˆemb_dimï¼‰ã€‚ æœ€åï¼Œé€è¡Œä½¿ç”¨å…¨è¿æ¥å±‚å’Œsoftmaxã€‚è¾“å‡ºçš„å°ºå¯¸ä¸ºï¼ˆtarget_lengthï¼‰xï¼ˆvocab_sizeï¼‰ã€‚ ç¼–ç å™¨å¯¹äºè®­ç»ƒé˜¶æ®µå’Œæµ‹è¯•é˜¶æ®µæ˜¯ä¸€æ ·çš„ç¼–ç è¿‡ç¨‹ï¼Œè€Œè§£ç å™¨çš„æµç¨‹åˆ™æœ‰æ‰€ä¸åŒï¼Œå› æ­¤å…ˆè®²è§£ä¸€ä¸‹è§£ç å™¨çš„è®­ç»ƒå’Œæµ‹è¯•ã€‚åœ¨æµ‹è¯•é˜¶æ®µï¼Œç”±äºæ²¡æœ‰groundtruthï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦ä»é›¶å¼€å§‹ä¸æ–­è¿­ä»£ä¸€ä¸ªè¯ä¸€ä¸ªè¯åœ°ç”Ÿæˆã€‚å…·ä½“æ“ä½œå¦‚ä¸‹ï¼š è®¡ç®—è¾“å…¥åºåˆ—çš„åµŒå…¥è¡¨ç¤ºã€‚ ä½¿ç”¨èµ·å§‹tokenä¾‹å¦‚â€™â€˜ï¼Œä½œä¸ºç¬¬ä¸€ä¸ªç›®æ ‡åºåˆ—ã€‚è¯¥æ¨¡å‹å°†é¢„æµ‹è¾“å‡ºä¸€ä¸ªtokenã€‚ å°†æœ€åä¸€ä¸ªé¢„æµ‹tokenæ·»åŠ åˆ°ç›®æ ‡åºåˆ—ï¼Œå¹¶ä½¿ç”¨å®ƒç”Ÿæˆæ–°çš„é¢„æµ‹ã€‚ é‡å¤æ‰§è¡Œæ­¥éª¤3ï¼Œæ¯æ¬¡çš„è¾“å…¥tokenå’Œè¾“å‡ºtokenéƒ½å¢åŠ ï¼Œç›´åˆ°é¢„æµ‹çš„tokenæ˜¯è¡¨ç¤ºåºåˆ—ç»“æŸçš„tokenï¼Œä¾‹å¦‚ã€‚ åœ¨è®­ç»ƒé˜¶æ®µä¸­ï¼Œç”±äºæˆ‘ä»¬äº‹å…ˆæœ‰roundtruthï¼Œå› æ­¤æˆ‘ä»¬å°†ç›´æ¥ä¸ºæ¨¡å‹æä¾›æ•´ä¸ªå·²ç§»ä½ç›®æ ‡åºåˆ—ï¼Œå¹¶è¦æ±‚å…¶é¢„æµ‹æœªç§»ä½ç›®æ ‡ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œç›®æ ‡æ˜¯å°†å¥å­ä»è‹±è¯­ç¿»è¯‘æˆè¥¿ç­ç‰™è¯­ï¼šX = [â€˜Helloâ€™ï¼Œâ€™ï¼Œâ€™ï¼Œâ€™howâ€™ï¼Œâ€™areâ€™ï¼Œâ€™youâ€™ï¼Œâ€™ï¼Ÿâ€™]ï¼ˆè¾“å…¥åºåˆ—ï¼‰Y = [â€˜Holaâ€™ï¼Œâ€™ï¼Œâ€™ï¼Œâ€™comoâ€™ï¼Œâ€™estasâ€™ï¼Œ â€˜ï¼Ÿâ€™]ï¼ˆç›®æ ‡åºåˆ—ï¼‰åœ¨å‰é¢çš„ç¤ºä¾‹ä¹‹åï¼Œæˆ‘ä»¬å°†ç»™è§£ç å™¨è¾“å…¥ï¼š[â€˜â€˜ï¼Œâ€™Holaâ€™ï¼Œâ€™ï¼Œâ€™ï¼Œâ€™comoâ€™ï¼Œâ€™estasâ€™ï¼Œâ€™ï¼Ÿâ€™]é¢„æœŸçš„é¢„æµ‹å°†æ˜¯ï¼š[â€˜Holaâ€™ï¼Œâ€™ï¼Œâ€™ï¼Œâ€™comoâ€™ï¼Œâ€™estasâ€™ï¼Œâ€™ï¼Ÿâ€™ï¼Œâ€™â€˜] å› æ­¤å¯ä»¥çœ‹åˆ°ï¼Œè§£ç å™¨åœ¨è®­ç»ƒæ—¶ç›´æ¥ä»target_length-&gt;target_lengthï¼Œè€Œæµ‹è¯•æ—¶åˆ™æ˜¯ä»1-&gt;1 2-&gt;2 3-&gt;3 â€¦ target_length-&gt;target_lengthçš„è¿‡ç¨‹ï¼Œæœ€åé¢„æµ‹çš„æ˜¯æ¯æ¬¡è¿­ä»£ä¸­æœ€åä¸€ä¸ªé¢„æµ‹çš„tokenä¸²è”èµ·æ¥ã€‚ Positional EncodingTransformeræŠ›å¼ƒäº†RNNï¼Œè€ŒRNNæœ€å¤§çš„ä¼˜ç‚¹å°±æ˜¯åœ¨æ—¶é—´åºåˆ—ä¸Šå¯¹æ•°æ®çš„æŠ½è±¡ï¼Œæ‰€ä»¥æ–‡ç« ä¸­ä½œè€…æå‡ºä¸¤ç§Positional Encodingçš„æ–¹æ³•ï¼Œå°†encodingåçš„æ•°æ®ä¸embeddingæ•°æ®æ±‚å’Œï¼ŒåŠ å…¥äº†ç›¸å¯¹ä½ç½®ä¿¡æ¯ã€‚ ç”¨ä¸åŒé¢‘ç‡çš„sineå’Œcosineå‡½æ•°ç›´æ¥è®¡ç®— å­¦ä¹ å‡ºä¸€ä»½positional embeddingå®éªŒåå‘ç°ä¸¤è€…ç»“æœä¸€æ ·ï¼Œæ‰€ä»¥ç”¨äº†ç¬¬ä¸€ç§æ–¹æ³•ï¼Œä¼˜ç‚¹æ˜¯ä¸éœ€è¦è®­ç»ƒå‚æ•°ï¼Œè€Œä¸”å³ä½¿åœ¨è®­ç»ƒé›†ä¸­æ²¡æœ‰å‡ºç°è¿‡çš„å¥å­é•¿åº¦ä¸Šä¹Ÿèƒ½ç”¨ å¯¹äºè¾“å…¥åºåˆ—ï¼Œç»è¿‡word embeddingåï¼ŒåŠ ä¸Špositional embeddingåå³å¯å¾—åˆ°è¯¥åºåˆ—çš„ representationï¼Œåºåˆ—ä¸­çš„æ¯ä¸ªtokenéƒ½è½¬æ¢æˆåŒ…å« word çš„ç‰¹å¾å’Œ word åœ¨å¥å­ä¸­çš„ä½ç½®ä¿¡æ¯çš„å‘é‡ã€‚ Multi-Head AttentionMulti-Head Attentionå…¶å®å°±æ˜¯å¤šä¸ªSelf-Attentionç»“æ„çš„ç»“åˆã€‚å› æ­¤ï¼Œé¦–å…ˆæˆ‘ä»¬éœ€è¦ç€é‡å­¦ä¹ è®ºæ–‡çš„é‡ç‚¹Self-Attentionã€‚ Self-Attentionä»ä¸€ä¸ªæ¯”è¾ƒçŸ¥åçš„ä¾‹å­è®²èµ·ã€‚å‡å¦‚æˆ‘ä»¬è¦ç¿»è¯‘ä¸€ä¸ªè¯ç»„Thinking Machinesï¼Œå…¶ä¸­Thinkingçš„è¾“å…¥çš„embedding vectorç”¨x1è¡¨ç¤ºï¼ŒMachinesçš„embedding vectorç”¨x2è¡¨ç¤ºã€‚å½“æˆ‘ä»¬å¤„ç†Thinkingè¿™ä¸ªè¯æ—¶ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—å¥å­ä¸­æ‰€æœ‰è¯ä¸å®ƒçš„Attention Scoreï¼Œè¿™å°±åƒå°†å½“å‰è¯ä½œä¸ºæœç´¢çš„queryï¼Œå»å’Œå¥å­ä¸­æ‰€æœ‰è¯ï¼ˆåŒ…å«è¯¥è¯æœ¬èº«ï¼‰çš„keyå»åŒ¹é…ï¼ˆç‚¹ä¹˜ï¼‰ï¼Œçœ‹çœ‹ç›¸å…³åº¦æœ‰å¤šé«˜ã€‚ç›¸å…³åº¦è¿›è¡Œå°ºåº¦ç¼©æ”¾ä¸softmaxå½’ä¸€åŒ–å¯ä»¥å¾—åˆ°æ³¨æ„åŠ›æƒé‡ï¼Œæ³¨æ„åŠ›ä¸ç›¸åº”çš„valueåŠ æƒæ±‚å’Œå°±å¾—åˆ°æ–°çš„è¡¨è¾¾ã€‚ å¦‚æœå°†è¾“å…¥çš„æ‰€æœ‰å‘é‡åˆå¹¶ä¸ºçŸ©é˜µå½¢å¼ï¼Œåˆ™æ‰€æœ‰query, key, valueå‘é‡ä¹Ÿå¯ä»¥åˆå¹¶ä¸ºçŸ©é˜µå½¢å¼è¡¨ç¤º åˆ™ä¸Šè¿°æ“ä½œå¯ç®€åŒ–ä¸ºçŸ©é˜µå½¢å¼ è¿™å°±æ˜¯è‘—åçš„æ³¨æ„åŠ›å…¬å¼ï¼š Multi-Head AttentionåŸºäºä¸Šè¾¹çš„Self-Attentionï¼Œ æˆ‘ä»¬è¿›ä¸€æ­¥æ‹“å±•ï¼Œå¯¹è¾“å…¥åºåˆ—ä½¿ç”¨ä¸åŒçš„Qï¼ŒKï¼ŒVè¿›è¡Œå¤šæ¬¡ä»¥ä¸Šæ“ä½œï¼Œè€Œåæ‹¼æ¥èµ·æ¥ï¼Œå†è½¬æ¢æˆæœ€ç»ˆçš„è¡¨ç¤ºã€‚è¿™æ ·æ¯ä¸ªheadå¯ä»¥å­¦ä¹ åˆ°åœ¨ä¸åŒè¡¨ç¤ºç©ºé—´ä¸­çš„ç‰¹å¾ã€‚ å¯è§†åŒ–å¦‚ä¸‹ï¼š Masked Multi-Head Attentionåœ¨è®­ç»ƒè¿‡ç¨‹çš„è§£ç å™¨ä¸­ï¼Œéœ€è¦å¯¹è¾“å…¥çš„æ³¨æ„åŠ›çŸ©é˜µï¼ˆå³ä¸Šè¾¹QKç»è¿‡softmaxçš„çŸ©é˜µï¼‰è¿›è¡Œmaskedæ“ä½œï¼Œä»è€Œä¸ç»™æ¨¡å‹çœ‹è§æœªæ¥ä¿¡æ¯ï¼Œè§£å†³äº†ä¿¡æ¯æ³„éœ²é—®é¢˜ã€‚ä¸¾ä¾‹æ¥è¯´ï¼Œå¯¹äºç›®æ ‡åºåˆ—ï¼ˆI have a dreamï¼‰ï¼ŒIä½œä¸ºç¬¬ä¸€ä¸ªå•è¯ï¼Œåªèƒ½æœ‰å’Œè‡ªèº«çš„attentionã€‚haveä½œä¸ºç¬¬äºŒä¸ªå•è¯ï¼Œæœ‰å’ŒI, have ä¸¤ä¸ªattentionã€‚ a ä½œä¸ºç¬¬ä¸‰ä¸ªå•è¯ï¼Œæœ‰å’ŒI,have,a å‰é¢ä¸‰ä¸ªå•è¯çš„attentionã€‚åˆ°äº†æœ€åä¸€ä¸ªå•è¯dreamçš„æ—¶å€™ï¼Œæ‰æœ‰å¯¹æ•´ä¸ªå¥å­4ä¸ªå•è¯çš„attentionã€‚ å…¶å®ƒæ“ä½œå’Œä¸Šè¿°çš„Multi-Head Attentionä¸€è‡´ã€‚ Encoder-Decoder Multi-Head Attentionåœ¨è§£ç å™¨çš„ç¬¬äºŒå±‚attentioné‡Œï¼Œéœ€è¦æ•´åˆencoderçš„è¾“å…¥åºåˆ—å’Œdecoderçš„ç›®æ ‡åºåˆ—çš„ä¿¡æ¯ï¼Œç®—å‡ºç›¸äº’ä¹‹é—´çš„æ³¨æ„åŠ›ã€‚ä¸Multi-Head Attentionçš„ä¸åŒç‚¹åœ¨äºï¼ŒEncoder-Decoder Multi-Head Attentionçš„QçŸ©é˜µæ¥è‡ªdecoderï¼Œè€ŒKå’ŒVæ¥è‡ªencoderã€‚å…¶å®ä¹Ÿå¾ˆå¥½ç†è§£ï¼Œå°±æ˜¯æ³¨æ„åŠ›çŸ©é˜µæ˜¯ç”±æ¥è‡ªè§£ç å™¨çš„Queryå’Œæ¥è‡ªç¼–ç å™¨çš„Keyä¹‹é—´è®¡ç®—å¾—æ¥ï¼Œå…¶å®ƒæ“ä½œéƒ½ç›¸åŒã€‚ Feed-Forwardè¿™ä¸ªå°±å¾ˆç®€å•äº†ï¼Œå°±æ˜¯ç®€å•çš„æ˜ å°„å±‚ã€‚ Produce Output Probabilitiesè¿™ä¸ªå…¶å®ä¹Ÿæ˜¯æ™®é€šçš„æ˜ å°„å±‚ï¼Œå®ƒå°†æ¯ä¸€ä¸ªç›®æ ‡åºåˆ—çš„tokenç”±emb_dimæ˜ å°„åˆ°vocab_sizeï¼Œå› æ­¤å°±å¯å¾—åˆ°å„ä¸ªtokenï¼Œä¸²æˆç›®æ ‡åºåˆ—äº†ã€‚ æ€»ç»“ä¸å¾—ä¸è¯´ï¼Œè¿™ç¡®å®æ˜¯ä¸€ç¯‡å¾ˆç»å…¸çš„è®ºæ–‡ï¼Œå°†seq2seqæ¨¡å‹æ¨åˆ°äº†ä¸€ä¸ªæ–°é«˜åº¦ï¼Œé¿å…äº†RNNçš„å¤§é‡è®¡ç®—ä»£ä»·ï¼Œä»æ­¤ç”¨CNNæ“ä½œåºåˆ—ä¿¡å·å°±æœ‰å¾ˆå¥½çš„æ•ˆæœäº†ã€‚å¦å¤–ï¼ŒSelf-Attentionè¿˜è·¨ç•Œåœ¨cvè¡Œä¸šä¹Ÿæœ‰äº†éå¸¸å¤šçš„ç ”ç©¶ã€‚å¯ä»¥è¯´cvå’Œnlpæ˜¯åŒæºçš„ï¼Œåªéœ€è¦å°†å›¾åƒçš„é•¿å®½æ‹‰æˆä¸€åˆ—ï¼ˆç©ºé—´ä¿¡æ¯ï¼‰ç±»æ¯”æˆåºåˆ—ä¿¡å·çš„åºåˆ—ï¼Œå›¾åƒçš„é€šé“ç±»æ¯”æˆåºåˆ—ä¿¡å·çš„embeddingå³å¯ã€‚å› æ­¤ï¼ŒSelf-Attentionæ¨¡å—çš„è¾“å…¥åœ¨nlpä¸Šæ˜¯time Ã— embeddingï¼Œåœ¨cvä¸Šæ˜¯spatial Ã— channelã€‚æ­¤å¤–ï¼Œå½“ä¸‹æ¨ªæ‰«nlpçš„BERTæ¨¡å‹ä¹Ÿæ˜¯åŸºäºTransfomerçš„encoderï¼Œè¿™ä¹Ÿè¡¨æ˜è¿™ä¸ªæ¨¡å‹çš„é‡è¦æ€§äº†ã€‚ å‚è€ƒæ–‡çŒ® https://medium.com/dissecting-bert/dissecting-bert-appendix-the-decoder-3b86f66b0e5f https://zhuanlan.zhihu.com/p/80986272 https://zhuanlan.zhihu.com/p/44121378 https://zhuanlan.zhihu.com/p/39034683 https://zhuanlan.zhihu.com/p/47282410","categories":[{"name":"æ·±åº¦å­¦ä¹ æ¨¡å‹","slug":"æ·±åº¦å­¦ä¹ æ¨¡å‹","permalink":"http://weiquanfan.xyz/categories/æ·±åº¦å­¦ä¹ æ¨¡å‹/"}],"tags":[{"name":"Transformer","slug":"Transformer","permalink":"http://weiquanfan.xyz/tags/Transformer/"},{"name":"attention","slug":"attention","permalink":"http://weiquanfan.xyz/tags/attention/"}]},{"title":"å¸¸è§çš„æ¢¯åº¦ä¸‹é™ç®—æ³•åŸç†","slug":"gradient-descent","date":"2020-05-04T04:58:54.000Z","updated":"2020-06-20T06:41:47.220Z","comments":true,"path":"2020/05/04/gradient-descent/","link":"","permalink":"http://weiquanfan.xyz/2020/05/04/gradient-descent/","excerpt":"","text":"å‰è¨€æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼ˆGradient Descent Optimizationï¼‰æ˜¯ç¥ç»ç½‘ç»œæ¨¡å‹è®­ç»ƒæœ€å¸¸ç”¨çš„ä¼˜åŒ–ç®—æ³•ã€‚å¯¹äºæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ŒåŸºæœ¬éƒ½æ˜¯é‡‡ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•æ¥è¿›è¡Œä¼˜åŒ–è®­ç»ƒçš„ã€‚æ¢¯åº¦ä¸‹é™ç®—æ³•èƒŒåçš„åŸç†ï¼šç›®æ ‡å‡½æ•° $J(\\theta)$ å…³äºå‚æ•° $\\theta$ çš„æ¢¯åº¦å°†æ˜¯æŸå¤±å‡½æ•°ï¼ˆloss functionï¼‰ä¸Šå‡æœ€å¿«çš„æ–¹å‘ã€‚è€Œæˆ‘ä»¬è¦æœ€å°åŒ–lossï¼Œåªéœ€è¦å°†å‚æ•°æ²¿ç€æ¢¯åº¦ç›¸åçš„æ–¹å‘å‰è¿›ä¸€ä¸ªæ­¥é•¿ï¼Œå°±å¯ä»¥å®ç°ç›®æ ‡å‡½æ•°ï¼ˆloss functionï¼‰çš„ä¸‹é™ã€‚è¿™ä¸ªæ­¥é•¿ $\\eta$ åˆç§°ä¸ºå­¦ä¹ é€Ÿç‡ã€‚ åŸå§‹çš„æ¢¯åº¦ä¸‹é™Batch gradient descent æ‰¹æ¢¯åº¦ä¸‹é™ï¼Œå¯¹æ‰€æœ‰çš„æ ·æœ¬è®¡ç®—æ¢¯åº¦åæ±‚å¹³å‡ï¼Œå¹¶æ›´æ–°å‚æ•°ã€‚ å› ä¸ºåœ¨æ‰§è¡Œæ¯æ¬¡æ›´æ–°æ—¶ï¼Œæˆ‘ä»¬éœ€è¦åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šè®¡ç®—æ‰€æœ‰çš„æ¢¯åº¦ï¼Œæ‰€ä»¥æ‰¹æ¢¯åº¦ä¸‹é™æ³•çš„é€Ÿåº¦ä¼šå¾ˆæ…¢ï¼ŒåŒæ—¶ï¼Œæ‰¹æ¢¯åº¦ä¸‹é™æ³•æ— æ³•å¤„ç†è¶…å‡ºå†…å­˜å®¹é‡é™åˆ¶çš„æ•°æ®é›†ã€‚æ‰¹æ¢¯åº¦ä¸‹é™æ³•åŒæ ·ä¹Ÿä¸èƒ½åœ¨çº¿æ›´æ–°æ¨¡å‹ï¼Œå³åœ¨è¿è¡Œçš„è¿‡ç¨‹ä¸­ï¼Œä¸èƒ½å¢åŠ æ–°çš„æ ·æœ¬ã€‚ å¯¹äºå‡¸è¯¯å·®å‡½æ•°ï¼Œæ‰¹æ¢¯åº¦ä¸‹é™æ³•èƒ½å¤Ÿä¿è¯æ”¶æ•›åˆ°å…¨å±€æœ€å°å€¼ï¼Œå¯¹äºéå‡¸å‡½æ•°ï¼Œåˆ™æ”¶æ•›åˆ°ä¸€ä¸ªå±€éƒ¨æœ€å°å€¼ã€‚ SGD éšæœºæ¢¯åº¦ä¸‹é™ï¼Œå¯¹æ¯ä¸ªæ ·æœ¬è®¡ç®—æ¢¯åº¦ï¼Œå¹¶æ›´æ–°ä¸€æ¬¡å‚æ•°ã€‚ SGDçš„è¿è¡Œé€Ÿåº¦æ›´å¿« å¯ä»¥ç”¨äºåœ¨çº¿å­¦ä¹  SGDä»¥é«˜æ–¹å·®é¢‘ç¹åœ°æ›´æ–°ï¼Œå¯¼è‡´ç›®æ ‡å‡½æ•°å‡ºç°å‰§çƒˆæ³¢åŠ¨ã€‚ ä¸æ‰¹æ¢¯åº¦ä¸‹é™æ³•çš„æ”¶æ•›ä¼šä½¿å¾—æŸå¤±å‡½æ•°é™·å…¥å±€éƒ¨æœ€å°ç›¸æ¯”ï¼Œç”±äºSGDçš„æ³¢åŠ¨æ€§ï¼Œä¸€æ–¹é¢ï¼Œæ³¢åŠ¨æ€§ä½¿å¾—SGDå¯ä»¥è·³åˆ°æ–°çš„å’Œæ½œåœ¨æ›´å¥½çš„å±€éƒ¨æœ€ä¼˜ã€‚å¦ä¸€æ–¹é¢ï¼Œè¿™ä½¿å¾—æœ€ç»ˆæ”¶æ•›åˆ°ç‰¹å®šæœ€å°å€¼çš„è¿‡ç¨‹å˜å¾—å¤æ‚ï¼Œå› ä¸ºSGDä¼šä¸€ç›´æŒç»­æ³¢åŠ¨ã€‚ç„¶è€Œï¼Œå·²ç»è¯æ˜å½“æˆ‘ä»¬ç¼“æ…¢å‡å°å­¦ä¹ ç‡ï¼ŒSGDä¸æ‰¹æ¢¯åº¦ä¸‹é™æ³•å…·æœ‰ç›¸åŒçš„æ”¶æ•›è¡Œä¸ºï¼Œå¯¹äºéå‡¸ä¼˜åŒ–å’Œå‡¸ä¼˜åŒ–ï¼Œå¯ä»¥åˆ†åˆ«æ”¶æ•›åˆ°å±€éƒ¨æœ€å°å€¼å’Œå…¨å±€æœ€å°å€¼ã€‚ Mini-batch GD å°æ‰¹é‡æ¢¯åº¦ä¸‹é™æ³•æœ€ç»ˆç»“åˆäº†ä¸Šè¿°ä¸¤ç§æ–¹æ³•çš„ä¼˜ç‚¹ï¼Œåœ¨æ¯æ¬¡æ›´æ–°æ—¶ä½¿ç”¨ä¸ªå°æ‰¹é‡è®­ç»ƒæ ·æœ¬ å‡å°‘å‚æ•°æ›´æ–°çš„æ–¹å·®ï¼Œè¿™æ ·å¯ä»¥å¾—åˆ°æ›´åŠ ç¨³å®šçš„æ”¶æ•›ç»“æœ å¯ä»¥åˆ©ç”¨æœ€æ–°çš„æ·±åº¦å­¦ä¹ åº“ä¸­é«˜åº¦ä¼˜åŒ–çš„çŸ©é˜µä¼˜åŒ–æ–¹æ³•ï¼Œé«˜æ•ˆåœ°æ±‚è§£æ¯ä¸ªå°æ‰¹é‡æ•°æ®çš„æ¢¯åº¦ã€‚ å°ç»“åŸå§‹çš„æ¢¯åº¦ä¸‹é™æ–¹æ³•æœ‰ä»¥ä¸‹é—®é¢˜ï¼š åœ¨æ¢¯åº¦å¹³ç¼“çš„ç»´åº¦ä¸‹é™éå¸¸æ…¢ï¼Œåœ¨æ¢¯åº¦é™©å³»çš„ç»´åº¦å®¹æ˜“æŠ–åŠ¨ å®¹æ˜“é™·å…¥å±€éƒ¨æå°å€¼æˆ–éç‚¹ã€‚Zero gradient,gradient descent gets stuck ï¼ˆåœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œéç‚¹æ¯”å±€éƒ¨æå°å€¼æ›´å®¹æ˜“å‡ºç°ï¼‰-é€‰æ‹©ä¸€ä¸ªåˆé€‚çš„å­¦ä¹ ç‡å¯èƒ½æ˜¯å›°éš¾çš„ã€‚å­¦ä¹ ç‡å¤ªå°ä¼šå¯¼è‡´æ”¶æ•›çš„é€Ÿåº¦å¾ˆæ…¢ï¼Œå­¦ä¹ ç‡å¤ªå¤§ä¼šå¦¨ç¢æ”¶æ•›ï¼Œå¯¼è‡´æŸå¤±å‡½æ•°åœ¨æœ€å°å€¼é™„è¿‘æ³¢åŠ¨ç”šè‡³åç¦»æœ€å°å€¼-å­¦ä¹ ç‡è°ƒæ•´è¯•å›¾åœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­é€šè¿‡ä¾‹å¦‚é€€ç«çš„æ–¹æ³•è°ƒæ•´å­¦ä¹ ç‡ï¼Œå³æ ¹æ®é¢„å®šä¹‰çš„ç­–ç•¥æˆ–è€…å½“ç›¸é‚»ä¸¤ä»£ä¹‹é—´çš„ä¸‹é™å€¼å°äºæŸä¸ªé˜ˆå€¼æ—¶å‡å°å­¦ä¹ ç‡ã€‚ç„¶è€Œï¼Œç­–ç•¥å’Œé˜ˆå€¼éœ€è¦é¢„å…ˆè®¾å®šå¥½ï¼Œå› æ­¤æ— æ³•é€‚åº”æ•°æ®é›†çš„ç‰¹ç‚¹-å¯¹æ‰€æœ‰çš„å‚æ•°æ›´æ–°ä½¿ç”¨åŒæ ·çš„å­¦ä¹ ç‡ã€‚å¦‚æœæ•°æ®æ˜¯ç¨€ç–çš„ï¼ŒåŒæ—¶ï¼Œç‰¹å¾çš„é¢‘ç‡å·®å¼‚å¾ˆå¤§æ—¶ï¼Œæˆ‘ä»¬ä¹Ÿè®¸ä¸æƒ³ä»¥åŒæ ·çš„å­¦ä¹ ç‡æ›´æ–°æ‰€æœ‰çš„å‚æ•°ï¼Œå¯¹äºå‡ºç°æ¬¡æ•°è¾ƒå°‘çš„ç‰¹å¾ï¼Œæˆ‘ä»¬å¯¹å…¶æ‰§è¡Œæ›´å¤§çš„å­¦ä¹ ç‡ å¸¦å†²é‡çš„æ¢¯åº¦ä¸‹é™Momentum optimizationå†²é‡æ¢¯åº¦ä¸‹é™ç®—æ³•æ˜¯Boris Polyakåœ¨1964å¹´æå‡ºçš„ï¼Œå…¶åŸºäºè¿™æ ·ä¸€ä¸ªç‰©ç†äº‹å®ï¼šå°†ä¸€ä¸ªå°çƒä»å±±é¡¶æ»šä¸‹ï¼Œå…¶åˆå§‹é€Ÿç‡å¾ˆæ…¢ï¼Œä½†åœ¨åŠ é€Ÿåº¦ä½œç”¨ä¸‹é€Ÿç‡å¾ˆå¿«å¢åŠ ï¼Œå¹¶æœ€ç»ˆç”±äºé˜»åŠ›çš„å­˜åœ¨è¾¾åˆ°ä¸€ä¸ªç¨³å®šé€Ÿç‡ã€‚å¯¹äºå†²é‡æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼Œå…¶æ›´æ–°æ–¹ç¨‹å¦‚ä¸‹ï¼š å¯ä»¥çœ‹åˆ°ï¼Œå‚æ•°æ›´æ–°æ—¶ä¸ä»…è€ƒè™‘å½“å‰æ¢¯åº¦å€¼ï¼Œè€Œä¸”åŠ ä¸Šäº†ä¸€ä¸ªç§¯ç´¯é¡¹ï¼ˆå†²é‡ï¼‰ï¼Œä½†å¤šäº†ä¸€ä¸ªè¶…å‚ï¼Œä¸€èˆ¬å–æ¥è¿‘1çš„å€¼å¦‚0.9ã€‚ç›¸æ¯”åŸå§‹æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼Œå†²é‡æ¢¯åº¦ä¸‹é™ç®—æ³•æœ‰åŠ©äºåŠ é€Ÿæ”¶æ•›ã€‚å½“æ¢¯åº¦ä¸å†²é‡æ–¹å‘ä¸€è‡´æ—¶ï¼Œå†²é‡é¡¹ä¼šå¢åŠ ï¼Œè€Œç›¸åæ—¶ï¼Œå†²é‡é¡¹å‡å°‘ï¼Œå› æ­¤å†²é‡æ¢¯åº¦ä¸‹é™ç®—æ³•å¯ä»¥å‡å°‘è®­ç»ƒçš„éœ‡è¡è¿‡ç¨‹ã€‚ Nesterov Accelerated Gradient (NAG)NAGç®—æ³•æ˜¯Yurii Nesterovåœ¨1983å¹´æå‡ºçš„å¯¹å†²é‡æ¢¯åº¦ä¸‹é™ç®—æ³•çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œå…¶é€Ÿåº¦æ›´å¿«ã€‚å…¶å˜åŒ–ä¹‹å¤„åœ¨äºè®¡ç®—â€œè¶…å‰æ¢¯åº¦â€æ›´æ–°å†²é‡é¡¹ï¼Œå…·ä½“å…¬å¼å¦‚ä¸‹ï¼š å­¦ä¹ ç‡è‡ªé€‚åº”çš„æ¢¯åº¦ä¸‹é™AdaGradAdaGradæ˜¯Duchiåœ¨2011å¹´æå‡ºçš„ä¸€ç§å­¦ä¹ é€Ÿç‡è‡ªé€‚åº”çš„æ¢¯åº¦ä¸‹é™ç®—æ³•ã€‚åœ¨è®­ç»ƒè¿­ä»£è¿‡ç¨‹ï¼Œå…¶å­¦ä¹ é€Ÿç‡æ˜¯é€æ¸è¡°å‡çš„ï¼Œç»å¸¸æ›´æ–°çš„å‚æ•°å…¶å­¦ä¹ é€Ÿç‡è¡°å‡æ›´å¿«ï¼Œè¿™æ˜¯ä¸€ç§è‡ªé€‚åº”ç®—æ³•ã€‚ å…¶æ›´æ–°è¿‡ç¨‹å¦‚ä¸‹ï¼š æŠŠæ¯ä¸€ç»´åº¦çš„æ¢¯åº¦^2å’Œè®°å½•ä¸‹æ¥ï¼Œæ¯æ¬¡å­¦ä¹ ç‡éƒ½é™¤ä»¥è¿™ä¸ªå’Œ æ¯ä¸€ç»´åº¦çš„å­¦ä¹ ç‡ä¸ä¸€æ ·ï¼Œä¸”éƒ½åœ¨ä¸æ–­å‡å° åœ¨æ¢¯åº¦å¤§çš„ç»´åº¦ï¼Œå‡å°ä¸‹é™é€Ÿåº¦ï¼›åœ¨æ¢¯åº¦å°çš„ç»´åº¦ï¼ŒåŠ å¿«ä¸‹é™é€Ÿåº¦ è®©å­¦ä¹ ç‡é€‚åº”å‚æ•°ï¼Œå¯¹äºå‡ºç°æ¬¡æ•°è¾ƒå°‘çš„ç‰¹å¾ï¼Œæˆ‘ä»¬å¯¹å…¶é‡‡ç”¨æ›´å¤§çš„å­¦ä¹ ç‡ï¼Œå¯¹äºå‡ºç°æ¬¡æ•°è¾ƒå¤šçš„ç‰¹å¾ï¼Œæˆ‘ä»¬å¯¹å…¶é‡‡ç”¨è¾ƒå°çš„å­¦ä¹ ç‡ã€‚å› æ­¤ï¼ŒAdagradéå¸¸é€‚åˆå¤„ç†ç¨€ç–æ•°æ®ã€‚ Adagradç®—æ³•çš„ä¸€ä¸ªä¸»è¦ä¼˜ç‚¹æ˜¯æ— éœ€æ‰‹åŠ¨è°ƒæ•´å­¦ä¹ ç‡ Adagradçš„ä¸€ä¸ªä¸»è¦ç¼ºç‚¹æ˜¯å®ƒåœ¨åˆ†æ¯ä¸­ç´¯åŠ æ¢¯åº¦çš„å¹³æ–¹ï¼šç”±äºæ¯å¢åŠ ä¸€ä¸ªæ­£é¡¹ï¼Œåœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œç´¯åŠ çš„å’Œä¼šæŒç»­å¢é•¿ã€‚è¿™ä¼šå¯¼è‡´å­¦ä¹ ç‡å˜å°ä»¥è‡³äºæœ€ç»ˆå˜å¾—æ— é™å°ï¼Œåœ¨å­¦ä¹ ç‡æ— é™å°æ—¶ï¼ŒAdagradç®—æ³•å°†æ— æ³•å–å¾—é¢å¤–çš„ä¿¡æ¯ã€‚ RMSpropRMSpropæ˜¯Hintonåœ¨ä»–çš„è¯¾ç¨‹ä¸Šè®²åˆ°çš„ï¼Œå…¶ç®—æ˜¯å¯¹Adagradç®—æ³•çš„æ”¹è¿›ï¼Œä¸»è¦æ˜¯è§£å†³å­¦ä¹ é€Ÿç‡è¿‡å¿«è¡°å‡çš„é—®é¢˜ã€‚å…¶å®æ€è·¯å¾ˆç®€å•ï¼Œç±»ä¼¼Momentumæ€æƒ³ï¼Œå¼•å…¥ä¸€ä¸ªè¶…å‚æ•°ï¼Œåœ¨ç§¯ç´¯æ¢¯åº¦å¹³æ–¹é¡¹è¿›è¡Œè¡°å‡ï¼š æ­¤æ—¶å¯ä»¥çœ‹åˆ°sæ˜¯æ¢¯åº¦å¹³æ–¹çš„æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡å€¼ï¼Œå…¶ä¸­\\gammaä¸€èˆ¬å–å€¼0.9ï¼Œæ­¤æ—¶sæ›´å¹³ç¨³ï¼Œå‡å°‘äº†å‡ºç°çš„çˆ†ç‚¸æƒ…å†µï¼Œå› æ­¤æœ‰åŠ©äºé¿å…å­¦ä¹ é€Ÿç‡å¾ˆå¿«ä¸‹é™çš„é—®é¢˜ã€‚åŒæ—¶Hintonä¹Ÿå»ºè®®å­¦ä¹ é€Ÿç‡è®¾ç½®ä¸º0.001ã€‚ Adaptive moment estimation (Adam)Adamæ˜¯Kingmaç­‰åœ¨2015å¹´æå‡ºçš„ä¸€ç§æ–°çš„ä¼˜åŒ–ç®—æ³•ï¼Œå…¶ç»“åˆäº†Momentumå’ŒRMSpropç®—æ³•çš„æ€æƒ³ã€‚ç›¸æ¯”Momentumç®—æ³•ï¼Œå…¶å­¦ä¹ é€Ÿç‡æ˜¯è‡ªé€‚åº”çš„ï¼Œè€Œç›¸æ¯”RMSpropï¼Œå…¶å¢åŠ äº†å†²é‡é¡¹ã€‚æ‰€ä»¥ï¼ŒAdamæ˜¯ä¸¤è€…çš„ç»“åˆä½“ï¼š å¯ä»¥çœ‹åˆ°å‰ä¸¤é¡¹å’ŒMomentumå’ŒRMSpropæ˜¯éå¸¸ä¸€è‡´çš„ï¼Œ ç”±äºå’Œçš„åˆå§‹å€¼ä¸€èˆ¬è®¾ç½®ä¸º0ï¼Œåœ¨è®­ç»ƒåˆæœŸå…¶å¯èƒ½è¾ƒå°ï¼Œç¬¬ä¸‰å’Œç¬¬å››é¡¹ä¸»è¦æ˜¯ä¸ºäº†æ”¾å¤§å®ƒä»¬ã€‚æœ€åä¸€é¡¹æ˜¯å‚æ•°æ›´æ–°ã€‚å…¶ä¸­è¶…å‚æ•°çš„å»ºè®®å€¼æ˜¯ æ€»ç»“æœ¬æ–‡æ²¿ç€æ¢¯åº¦ä¸‹é™çš„å‘å±•å¤§è‡´ä»‹ç»äº†å„ç§å¸¸ç”¨çš„æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼Œç›®å‰æ¯”è¾ƒå¸¸ç”¨çš„åº”è¯¥ä»æ˜¯ Adam ï¼Œ ä¸è¿‡æˆ‘æ„Ÿè§‰å…¶å® SGD åŠ æ¢¯åº¦è¡°å‡ç­–ç•¥å¯èƒ½èƒ½å–å¾—æ›´å¥½çš„æ•ˆæœï¼Œå½“ç„¶è¿™éœ€è¦è®¾ç½®å¾—æ¯”è¾ƒåˆé€‚ã€‚ å½©è›‹","categories":[{"name":"æœºå™¨å­¦ä¹ ","slug":"æœºå™¨å­¦ä¹ ","permalink":"http://weiquanfan.xyz/categories/æœºå™¨å­¦ä¹ /"}],"tags":[]},{"title":"opensmile å·¥å…·çš„ä½¿ç”¨å’Œæ‰¹å¤„ç†","slug":"opensmile","date":"2020-05-02T12:32:13.000Z","updated":"2020-06-20T06:13:11.980Z","comments":true,"path":"2020/05/02/opensmile/","link":"","permalink":"http://weiquanfan.xyz/2020/05/02/opensmile/","excerpt":"","text":"å‰è¨€openSMILEæ˜¯ä¸€æ¬¾ä»¥å‘½ä»¤è¡Œå½¢å¼è¿è¡Œçš„å·¥å…·ï¼Œé€šè¿‡é…ç½®configæ–‡ä»¶æ¥æå–éŸ³é¢‘ç‰¹å¾ã€‚ä¸»è¦åº”ç”¨äºè¯­éŸ³è¯†åˆ«ã€æƒ…æ„Ÿè®¡ç®—ã€éŸ³ä¹ä¿¡æ¯è·å–ã€‚2.0ç‰ˆæœ¬ä¹‹åçš„openSMILEåŒ…æ‹¬äº†openCVåº“ï¼Œå¯ä»¥ç”¨äºè§†é¢‘å¤„ç†å’Œè§†é¢‘ç‰¹å¾æå–ã€‚å®˜ç½‘ä¸‹è½½æœ‰linuxå’Œwindowsç‰ˆæœ¬æä¾›ä¸‹è½½ï¼Œwindowså¯ä»¥ä¸ç¼–è¯‘ç›´æ¥ç”¨ï¼Œå»ºè®®åœ¨å‘½ä»¤è¡Œé‡ŒæŒ‡æ˜ openSMILE ç»å¯¹è·¯å¾„ã€‚ openSMILEçš„è¾“å…¥è¾“å‡ºæ ¼å¼æ–‡ä»¶è¾“å…¥æ ¼å¼ RIFF-WAVE (PCM) (for MP3, MP4, OGG, etc. a converter needs to be used) Comma Separated Value (CSV) HTK parameter files WEKAâ€™s ARFF format.ï¼ˆç”±htkå·¥å…·äº§ç”Ÿï¼‰ Video streams via openCV.ï¼ˆopencväº§ç”Ÿçš„è§†é¢‘æµæ•°æ®ï¼‰ æ–‡ä»¶è¾“å‡ºæ ¼å¼ RIFF-WAVE (PCM uncompressed audio) Comma Separated Value (CSV) HTK parameter file WEKA ARFF file LibSVM feature file format Binary float matrix format åˆ†ç±»å™¨å’Œå…¶ä»–ç»„ä»¶openSMILEè¿˜æä¾›äº†è®¸å¤šVADç®—æ³•ï¼Œç”¨äºåˆ¤æ–­å„æ—¶é—´ç‚¹æœ‰æ²¡æœ‰è¯´è¯ã€‚ Voice Activity Detection based on Fuzzy Logic Voice Activity Detection based on LSTM-RNN with pre-trained models Turn-/Speech-segment detector LibSVM (on-line) LSTM-RNN (Neural Network) classifier which can load RNNLIB and CURRENNT nets GMM (experimental implementation from eNTERFACEâ€™12 project, to be release soon) SVM sink (for loading linear kernel WEKA SMO models) Speech Emotion recognition pre-trained models (openEAR) openSMILEä½¿ç”¨æµç¨‹ç®€ä»‹ å…ˆåˆ‡æ¢åˆ°å¤„ç†æ–‡ä»¶SMILExtract.exeæ‰€åœ¨çš„ç›®å½• é€šè¿‡å¦‚ä¸‹è¯­å¥æå–ï¼šwindowsä¸‹ï¼šSMILExtract_Release -C â€œé…ç½®æ–‡ä»¶â€ -I â€œè¦å¤„ç†çš„éŸ³é¢‘â€ -O â€œè¦ä¿å­˜ç‰¹å¾å‘é‡çš„è·¯å¾„åŠæ–‡ä»¶åâ€linuxä¸‹ï¼šSMILExtract -C â€œé…ç½®æ–‡ä»¶â€ -I â€œè¦å¤„ç†çš„éŸ³é¢‘â€ -O â€œè¦ä¿å­˜ç‰¹å¾å‘é‡çš„è·¯å¾„åŠæ–‡ä»¶åâ€ å®˜æ–¹é…ç½®æ–‡ä»¶å®˜æ–¹æä¾›äº†è®¸å¤šå¸¸è§ç‰¹å¾é›†çš„é…ç½®æ–‡ä»¶ï¼Œå¦‚MFCCï¼ŒPLPï¼Œä»¥åŠå„å¤§è¯­éŸ³æ¯”èµ›ä¸­æ•ˆæœå¥½çš„ç‰¹å¾é›†ã€‚ MFCCç‰¹å¾ä¸ºäº†æå–MFCCç‰¹å¾ï¼ˆå…¼å®¹HTKï¼‰ï¼Œæä¾›äº†ä»¥ä¸‹å››ä¸ªæ–‡ä»¶ï¼ˆå®ƒä»¬æ˜¯ä»¥å®ƒä»¬æ‰€ä»£è¡¨çš„ç›¸åº”çš„HTKå‚æ•°ç±»å‹å‘½åçš„ï¼‰ï¼šMFCC12_0_D_A.confæ­¤é…ç½®ä»25æ¯«ç§’çš„éŸ³é¢‘å¸§ä¸­æå–æ¢…å°”é¢‘ç‡å€’è°±ç³»æ•°ï¼ˆä»¥10æ¯«ç§’çš„é€Ÿç‡é‡‡æ ·ï¼‰ï¼ˆæ±‰æ˜çª—å£ï¼‰ã€‚ å®ƒç”±26ä¸ªMelé¢‘å¸¦è®¡ç®—13ä¸ªMFCCï¼ˆ0-12ï¼‰ç»„ï¼Œå¹¶åº”ç”¨äº†ä¸€ä¸ªæƒé‡å‚æ•°ä¸º22çš„å€’è°±æå‡æ»¤æ³¢å™¨ã€‚13ä¸ªä¸€é˜¶å’Œ13ä¸ªäºŒé˜¶ç³»æ•°è¢«é™„åŠ åˆ°MFCCåã€‚MFCC12_E_D_A.confæ­¤é…ç½®è·ŸMFCC12_0_D_A.confä¸€æ ·ï¼Œä½†å¯¹æ•°èƒ½é‡æ˜¯åªåŠ åœ¨MFCC1-12ä¸Šã€‚MFCC12_0_D_A_Z.confè¿™ä¸ªé…ç½®è·ŸMFCC12_0_D_A.confé…ç½®ä¸€æ ·ï¼Œé™¤äº†æ‰€æœ‰ç‰¹å¾æ˜¯å‚è€ƒæ•´ä¸ªè¾“å…¥åºåˆ—è¿›è¡Œäº†æ ‡å‡†åŒ–ã€‚MFCC12_E_D_A_Z.confè¿™ä¸ªé…ç½®è·ŸMFCC12_E_D_A.confé…ç½®ä¸€æ ·ï¼Œé™¤äº†æ‰€æœ‰ç‰¹å¾æ˜¯å‚è€ƒæ•´ä¸ªè¾“å…¥åºåˆ—è¿›è¡Œäº†æ ‡å‡†åŒ–ã€‚å¸§é•¿ä¸º25ms,å¸§ç§»ä¸º10msï¼Œä½¿ç”¨çš„æ±‰æ˜çª—ï¼Œé¢„å¢å¼ºå‚æ•°ä¸º0.97ã€‚ç”±26ä¸ªé€šè¿‡FFTåŠŸç‡è°±è®¡ç®—çš„mel-æ»¤æ³¢å™¨ç»„è®¡ç®—MFCC 0/1-12ã€‚MELé¢‘è°±çš„é¢‘ç‡èŒƒå›´ä¸º0-8kHzï¼ŒåŒæ—¶è¿™äº›é…ç½®æ–‡ä»¶æä¾›äº†-I,-Oé€‰é¡¹ã€‚è¾“å‡ºæ–‡ä»¶æ ¼å¼æ˜¯HTKå‚æ•°æ–‡ä»¶æ ¼å¼ã€‚å¦‚æœéœ€è¦è¾“å‡ºå…¶ä»–æ–‡ä»¶æ ¼å¼ï¼Œä½ å¿…é¡»åœ¨é…ç½®æ–‡ä»¶ä¸­æ›´æ”¹â€˜cHtkSinkâ€™ç»„ä»¶ç±»å‹ä¸ºä½ æƒ³è¦çš„ç±»å‹ã€‚å‘½ä»¤è¡Œç¤ºä¾‹å¦‚ä¸‹ï¼š SMILExtract -C config/MFCC12_E_D_A.conf -I input.wav -O output.mfcc.htk PLPç‰¹å¾ç”¨äºæå–PLPå€’è°±ç³»æ•°ï¼ˆPLP-CCï¼‰ï¼ˆä¸HTKå…¼å®¹ï¼‰ä»¥ä¸‹å››ä¸ªæ–‡ä»¶ï¼ˆå®ƒä»¬æ˜¯ä»¥å®ƒä»¬æ‰€ä»£è¡¨çš„ç›¸åº”çš„HTKå‚æ•°ç±»å‹å‘½åçš„ï¼‰ï¼šPLP_0_D_A.confè¯¥é…ç½®ä»25 msé•¿éŸ³é¢‘ï¼ˆä»¥10msçš„é€Ÿç‡é‡‡æ ·ï¼‰å¸§æå–Melé¢‘ç‡å€’è°±ç³»æ•°ï¼ˆæ±‰æ˜çª—å£ï¼‰ã€‚å®ƒä»26ä¸ªMelé¢‘å¸¦ï¼Œå¹¶ä½¿ç”¨é¢„æµ‹é˜¶æ•°ä¸º5è®¡ç®—6ä¸ªPLPï¼ˆ0-5ï¼‰ï¼Œå¹¶åº”ç”¨äº†ä¸€ä¸ªæƒé‡å‚æ•°ä¸º22çš„å€’è°±æå‡æ»¤æ³¢å™¨ã€‚6ä¸ªä¸€é˜¶å’Œ6ä¸ªäºŒé˜¶ç³»æ•°è¢«é™„åŠ åˆ°PLP-CCåã€‚PLP_E_D_A.confè¯¥é…ç½®ä¸PLP_0_D_A.confç›¸åŒï¼Œä½†å¯¹æ•°èƒ½é‡æ˜¯åªåŠ åœ¨PLP1-12ä¸Šã€‚PLP_0_D_A_Z.confæ­¤é…ç½®ä¸PLP_0_D_A.confç›¸åŒï¼Œé™¤äº†æ‰€æœ‰ç‰¹å¾æ˜¯å‚è€ƒæ•´ä¸ªè¾“å…¥åºåˆ—è¿›è¡Œäº†æ ‡å‡†åŒ–ã€‚PLP_E_D_Z.confæ­¤é…ç½®ä¸PLP_E_D_A.confç›¸åŒï¼Œé™¤äº†æ‰€æœ‰ç‰¹å¾æ˜¯å‚è€ƒæ•´ä¸ªè¾“å…¥åºåˆ—è¿›è¡Œäº†æ ‡å‡†åŒ–ã€‚å¸§é•¿ä¸º25ms,å¸§ç§»ä¸º10msï¼Œä½¿ç”¨çš„æ±‰æ˜çª—ï¼Œé¢„å¢å¼ºå‚æ•°ä¸º0.97ã€‚ç”±26ä¸ªé€šè¿‡FFTåŠŸç‡è°±è®¡ç®—çš„å¬è§‰mel-æ»¤æ³¢å™¨ç»„(å‹ç¼©ç³»æ•°ä¸º0.33)è®¡ç®—PLP 0/1-5ã€‚çº¿æ€§é¢„æµ‹å™¨çš„é¢„æµ‹é˜¶æ•°ä¸º5ã€‚MELé¢‘è°±çš„é¢‘ç‡èŒƒå›´ä¸º0-8kHzï¼ŒåŒæ—¶è¿™äº›é…ç½®æ–‡ä»¶æä¾›äº†-I,-Oé€‰é¡¹ã€‚è¾“å‡ºæ–‡ä»¶æ ¼å¼æ˜¯HTKå‚æ•°æ–‡ä»¶æ ¼å¼ã€‚å¦‚æœéœ€è¦è¾“å‡ºå…¶ä»–æ–‡ä»¶æ ¼å¼ï¼Œä½ å¿…é¡»åœ¨é…ç½®æ–‡ä»¶ä¸­æ›´æ”¹â€˜cHtkSinkâ€™ç»„ä»¶ç±»å‹ä¸ºä½ æƒ³è¦çš„ç±»å‹ã€‚å‘½ä»¤è¡Œç¤ºä¾‹å¦‚ä¸‹ï¼š SMILExtract -C config/PLP_E_D_A.conf -I input.wav -O output.plp.htk æƒ…æ„Ÿç‰¹å¾é›†è‡ªopenSMILEåœ¨openEARçš„é¡¹ç›®EWS09æƒ…æ„Ÿè¯†åˆ«ä¸­è¢«ä½¿ç”¨ï¼ŒopenSMILEæä¾›äº†å„ç§æƒ…æ„Ÿè¯†åˆ«çš„æ ‡å‡†ç‰¹å¾é›†ã€‚The INTERSPEECH 2009 Emotion Challenge feature setï¼ˆå‚è§[SSB09]ï¼‰ç”±é…ç½®æ–‡ä»¶config/emo IS09.confæä¾›ã€‚å®ƒåŒ…å«å¯¹LLDsåº”ç”¨ç»Ÿè®¡å‡½æ•°å¾—åˆ°çš„384ä¸ªç‰¹å¾ã€‚è¯¥ç‰¹å¾è¢«ä¿å­˜åœ¨Arffæ ¼å¼ï¼ˆé’ˆå¯¹WEKAï¼‰ï¼Œæ–°çš„å®ä¾‹ä¼šè¢«é™„åŠ åˆ°ä¸€ä¸ªå·²å­˜åœ¨æ–‡ä»¶ï¼ˆè¿™æ˜¯ç”¨äºæ‰¹å¤„ç†ï¼Œå…¶ä¸­openSMILEè¢«åå¤è°ƒç”¨ä»å¤šä¸ªæ–‡ä»¶æå–ç‰¹å¾åˆ°å•ä¸ªç‰¹å¾æ–‡ä»¶ï¼‰ã€‚ å‡ºç°åœ¨Arffæ–‡ä»¶ä¸­16ä¸ªä½çº§æè¿°ç¬¦ï¼ˆLLDsï¼‰çš„åç§°ï¼Œè§ä¸‹é¢çš„åˆ—è¡¨ï¼š pcm_RMSenergy ä¿¡å·å¸§å‡æ–¹æ ¹èƒ½é‡ mfcc æ¢…å°”é¢‘ç‡å€’è°±ç³»æ•°1-12 Pcm_zcr æ—¶é—´ä¿¡å·çš„è¿‡é›¶ç‡ï¼ˆåŸºäºå¸§ï¼‰ voiceProb ä»ACFè®¡ç®—çš„å‘å£°æ¦‚ç‡ã€‚ F0 ä»å€’è°±è®¡ç®—çš„åŸºé¢‘ é™„åŠ åˆ°ä½çº§æè¿°ç¬¦åç§°çš„åç¼€_smaè¡¨ç¤ºå®ƒä»¬æ˜¯é€šè¿‡çª—å£é•¿åº¦ä¸º3çš„ç§»åŠ¨å¹³å‡æ»¤æ³¢å™¨è¿›è¡Œå¹³æ»‘ã€‚é™„åŠ åˆ°smaçš„åç¼€_deè¡¨ç¤ºå½“å‰ç‰¹å¾æ˜¯ä½çº§æè¿°ç¬¦å¹³æ»‘åçš„ä¸€é˜¶deltaç³»æ•°ï¼ˆå¾®åˆ†ï¼‰ã€‚ max è½®å»“çš„æœ€å¤§å€¼ min è½®å»“çš„æœ€å°å€¼ range = max- min maxPos æœ€å¤§å€¼çš„ç»å¯¹ä½ç½®ï¼ˆä»¥å¸§ä¸ºå•ä½ï¼‰ minPos æœ€å°å€¼çš„ç»å¯¹ä½ç½®ï¼ˆä»¥å¸§ä¸ºå•ä½ï¼‰ amean è½®å»“çš„ç®—æœ¯å¹³å‡å€¼ linregc1 è½®å»“çº¿æ€§é€¼è¿‘çš„æ–œç‡ï¼ˆmï¼‰ linregc2 è½®å»“çº¿æ€§é€¼è¿‘çš„åç§»é‡ï¼ˆtï¼‰ linregerrQ è®¡ç®—çš„äºŒæ¬¡è¯¯å·®ä½œä¸ºçº¿æ€§è¿‘ä¼¼å€¼å’Œå®é™…è½®å»“çš„å·®å€¼ stddev è½®å»“ä¸Šçš„å€¼çš„æ ‡å‡†åå·® skewness ååº¦ï¼ˆ3é˜¶çŸ©ï¼‰ kurtosis å³°åº¦ï¼ˆ4é˜¶çŸ©ï¼‰ The INTERSPEECH 2010 Paralinguistic Challenge feature setï¼ˆè§2010å¹´INTERSPEECHä¼šè®®è®ºæ–‡é›†ï¼‰ç”±é…ç½®æ–‡ä»¶config/IS10_paraling.confæä¾›ã€‚è¯¥é›†åŒ…å«çš„1582ä¸ªç‰¹å¾æ˜¯ç”±34ä¸ªä½çº§æè¿°ç¬¦ï¼ˆLLDsï¼‰å’Œ34ä¸ªç›¸åº”çš„deltaä½œä¸º68ä¸ªLLDsè½®å»“å€¼ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šåº”ç”¨21ä¸ªå‡½æ•°å¾—åˆ°1428ä¸ªç‰¹å¾ï¼Œå¦å¤–ï¼Œå¯¹4ä¸ªåŸºäºéŸ³é«˜çš„LLDåŠå…¶4ä¸ªdeltaç³»æ•°åº”ç”¨äº†19ä¸ªå‡½æ•°å¾—åˆ°152ä¸ªç‰¹å¾ï¼Œæœ€åé™„åŠ éŸ³é«˜ï¼ˆä¼ªéŸ³èŠ‚ï¼‰çš„æ•°é‡å’Œæ€»æ•°è¾“å…¥çš„æŒç»­æ—¶é—´ï¼ˆ2ä¸ªç‰¹å¾ï¼‰ã€‚è¯¥ç‰¹å¾è¢«ä¿å­˜åœ¨Arffæ ¼å¼ï¼ˆé’ˆå¯¹WEKAï¼‰ï¼Œæ–°çš„å®ä¾‹ä¼šè¢«é™„åŠ åˆ°ä¸€ä¸ªå·²å­˜åœ¨æ–‡ä»¶ï¼ˆè¿™æ˜¯ç”¨äºæ‰¹å¤„ç†ï¼Œå…¶ä¸­openSMILEè¢«åå¤è°ƒç”¨ä»å¤šä¸ªæ–‡ä»¶æå–ç‰¹å¾åˆ°å•ä¸ªç‰¹å¾æ–‡ä»¶ï¼‰ã€‚ å‡ºç°åœ¨Arffæ–‡ä»¶ä¸­34ä¸ªä½çº§æè¿°ç¬¦ï¼ˆLLDsï¼‰çš„åç§°ï¼Œè§ä¸‹é¢çš„åˆ—è¡¨ï¼š pcm_loudness å½’ä¸€åŒ–å¼ºåº¦æé«˜åˆ°0.3çš„å¹‚çš„å“åº¦ mfcc ç¾å°”é¢‘ç‡å€’è°±ç³»æ•°0-14 logMelFreqBand æ¢…å°”é¢‘å¸¦çš„å¯¹æ•°åŠŸç‡0-7ï¼ˆåˆ†å¸ƒèŒƒå›´å†…ä»0åˆ°8 kHzï¼‰ lspFreq ä»8ä¸ªLPCç³»æ•°è®¡ç®—å‡ºçš„8ä¸ªçº¿è°±å¯¹é¢‘ç‡ã€‚ F0finEnv å¹³æ»‘çš„åŸºé¢‘è½®å»“çº¿ã€‚ voicingFinalUnclipped æœ€ç»ˆåŸºé¢‘å€™é€‰çš„å‘å£°æ¦‚ç‡ã€‚Unclippedçš„æ„æ€æ˜¯ï¼Œå½“å…¶ä½äºæµŠéŸ³é˜ˆå€¼æ—¶ï¼Œå®ƒä¸è¢«è®¾ç½®ä¸ºé›¶ã€‚ é™„åŠ åˆ°ä½çº§æè¿°ç¬¦åç§°çš„åç¼€_smaè¡¨ç¤ºå®ƒä»¬æ˜¯é€šè¿‡çª—å£é•¿åº¦ä¸º3çš„ç§»åŠ¨å¹³å‡æ»¤æ³¢å™¨è¿›è¡Œå¹³æ»‘ã€‚é™„åŠ åˆ°smaçš„åç¼€_deè¡¨ç¤ºå½“å‰ç‰¹å¾æ˜¯ä½çº§æè¿°ç¬¦å¹³æ»‘åçš„ä¸€é˜¶deltaç³»æ•°ï¼ˆå¾®åˆ†ï¼‰ã€‚å‡ºç°åœ¨Arffæ–‡ä»¶ä¸­çš„21ä¸ªå‡½æ•°çš„åå­—,å‡åœ¨ä»¥ä¸‹åˆ—è¡¨ä¸­ï¼š maxPos æœ€å¤§å€¼çš„ç»å¯¹ä½ç½®ï¼ˆä»¥å¸§ä¸ºå•ä½ï¼‰ minPos æœ€å°å€¼çš„ç»å¯¹ä½ç½®ï¼ˆä»¥å¸§ä¸ºå•ä½ï¼‰ amean è½®å»“çš„ç®—æœ¯å¹³å‡å€¼ linregc1 è½®å»“çº¿æ€§é€¼è¿‘çš„æ–œç‡ï¼ˆmï¼‰ linregc2 è½®å»“çº¿æ€§é€¼è¿‘çš„åç§»é‡ï¼ˆtï¼‰ linregerrA æŠŠçº¿æ€§è¯¯å·®è®¡ç®—ä½œä¸ºçº¿æ€§è¿‘ä¼¼å€¼å’Œå®é™…çš„è½®å»“çš„è¯¯å·® linregerrQ æŠŠäºŒæ¬¡è¯¯å·®è®¡ç®—ä½œä¸ºçº¿æ€§è¿‘ä¼¼å€¼å’Œå®é™…çš„è½®å»“çš„è¯¯å·® stddev è½®å»“ä¸­çš„å€¼çš„æ ‡å‡†åå·® skewness ååº¦ï¼ˆ3é˜¶çŸ©ï¼‰ã€‚ kurtosis å³°åº¦ï¼ˆ4é˜¶çŸ©ï¼‰ã€‚ quartile1 ç¬¬ä¸€å››åˆ†ä½æ•°ï¼ˆ25ï¼…ç™¾åˆ†ä½æ•°ï¼‰ quartile2 ç¬¬ä¸€å››åˆ†ä½æ•°ï¼ˆ50ï¼…ç™¾åˆ†ä½æ•°ï¼‰ quartile3 ç¬¬ä¸€å››åˆ†ä½æ•°ï¼ˆ75ï¼…ç™¾åˆ†ä½æ•°ï¼‰ iqr1-2 å››åˆ†ä½æ•°é—´è·ï¼šquartile2- quartile1 iqr2-3 å››åˆ†ä½æ•°é—´è·ï¼šquartile3- quartile2 iqr1-3 å››åˆ†ä½æ•°é—´è·ï¼šquartile3- quartile1 percentile1.0 è½®å»“çš„ç¦»ç¾¤å€¼é²æ£’æœ€å°å€¼ï¼ŒæŒ‰1ï¼…ç™¾åˆ†ä½æ•°è¡¨ç¤ºã€‚ percentile99.0 è½®å»“çš„ç¦»ç¾¤å€¼é²æ£’æœ€å¤§å€¼ï¼ŒæŒ‰99ï¼…ç™¾åˆ†ä½æ•°è¡¨ç¤ºã€‚ pctlrange0-1 ç”±1ï¼…å’Œ99ï¼…çš„ç™¾åˆ†ç‚¹çš„èŒƒå›´è¡¨ç¤ºçš„ç¦»ç¾¤å€¼é²æ£’ä¿¡å·èŒƒå›´â€œmax-minâ€ã€‚ upleveltime75 ä¿¡å·è¶…è¿‡ï¼ˆ75ï¼…*èŒƒå›´+minï¼‰çš„æ—¶é—´ç™¾åˆ†æ¯”ã€‚ upleveltime90 ä¿¡å·è¶…è¿‡ï¼ˆ90ï¼…*èŒƒå›´+minï¼‰çš„æ—¶é—´ç™¾åˆ†æ¯”ã€‚ å››ä¸ªéŸ³é«˜ç›¸å…³çš„LLDï¼ˆåŠç›¸åº”çš„deltaç³»æ•°ï¼‰å¦‚ä¸‹ï¼ˆæ¸…éŸ³åŒºåŸŸå‡ä¸º0ï¼Œå› æ­¤åŠŸèƒ½ä»…é€‚ç”¨äºè¿™äº›è½®å»“çš„æµŠéŸ³åŒºåŸŸï¼‰ï¼š F0final å¹³æ»‘çš„åŸºé¢‘é¢‘ç‡ jitterLocal æœ¬åœ°ï¼ˆå¸§åˆ°å¸§ï¼‰æŠ–åŠ¨ï¼ˆéŸ³è°ƒå‘¨æœŸé•¿åº¦åå·®ï¼‰ jitterDDP å·®åˆ†å¸§é—´æŠ–åŠ¨ï¼ˆâ€˜Jitter of the Jitterâ€™ï¼‰ shimmerLocal æœ¬åœ°ï¼ˆå¸§åˆ°å¸§ï¼‰é—ªçƒï¼ˆéŸ³è°ƒå‘¨æœŸå¹…åº¦åå·®ï¼‰ å¯¹è¿™4 + 4ä¸ªLLDåº”ç”¨äº†19ä¸ªå‡½æ•°ï¼Œå³ä¸Šè¿°21ä¸ªå‡½æ•°çš„é›†åˆæ²¡æœ‰æœ€å°å€¼ï¼ˆ1ï¼…ç™¾åˆ†ä½æ•°ï¼‰å’ŒèŒƒå›´ã€‚ The INTERSPEECH 2011 Speaker State Challenge feature setï¼ˆè§2011å¹´INTERSPEECHä¼šè®®è®ºæ–‡é›†ï¼‰ç”±é…ç½®æ–‡ä»¶config/IS11_speake_state.confæä¾›ã€‚è¯¥é›†åŒ…å«çš„4368ä¸ªç‰¹å¾æ˜¯ç”±4ä¸ªèƒ½é‡ç›¸å…³+50ä¸ªé¢‘è°±ç›¸å…³çš„ä½çº§æè¿°ç¬¦ï¼ˆLLDsï¼‰å’Œ54ä¸ªç›¸åº”çš„deltaä½œä¸º108ä¸ªLLDsï¼Œåœ¨æ­¤åŸºç¡€ä¸Šåº”ç”¨33ä¸ªåŸºæœ¬å‡½æ•°+å¹³å‡å€¼ã€æœ€å°å€¼ã€æœ€å¤§å€¼ã€æ ‡å‡†å·®å¾—åˆ°3996ä¸ªç‰¹å¾ï¼›5ä¸ªå£°éŸ³ç›¸å…³å’Œ5ä¸ªå¯¹åº”çš„deltaä½œä¸º10ä¸ªLLDsï¼Œåœ¨æ­¤åŸºç¡€ä¸Šåº”ç”¨33ä¸ªåŸºæœ¬å‡½æ•°+äºŒæ¬¡å¹³å‡ã€ä¸Šå‡æ—¶é•¿ã€ä¸‹é™æ—¶é•¿å¾—åˆ°360ä¸ªç‰¹å¾ï¼›6ä¸ªF0åŸºæœ¬å‡½æ•°å’Œå¯¹åº”çš„deltaï¼Œ12ä¸ªç‰¹å¾ã€‚ The INTERSPEECH 2012 Speaker Trait Challenge feature setï¼ˆè§2012å¹´INTERSPEECHä¼šè®®è®ºæ–‡é›†ï¼‰ç”±é…ç½®æ–‡ä»¶config/IS12_speake_trait.confæä¾›ã€‚è¯¥é›†åŒ…å«çš„6125ä¸ªç‰¹å¾ã€‚ The INTERSPEECH 2013 ComParE Challenge feature set ï¼ˆè§2013å¹´INTERSPEECHä¼šè®®è®ºæ–‡é›†ï¼‰ç”±é…ç½®æ–‡ä»¶config/IS13_ComParE.confæä¾›ã€‚è¯¥é›†åŒ…å«çš„6373ä¸ªç‰¹å¾ï¼ŒLLDåŒ…æ‹¬èƒ½é‡ï¼Œé¢‘è°±ï¼Œå€’è°±ï¼ˆMFCCï¼‰ã€å£°éŸ³ã€å¯¹æ•°è°æ³¢å™ªå£°æ¯”ï¼ˆHNRï¼‰ï¼Œé¢‘è°±è°åº¦å’Œå¿ƒç†å£°å­¦é¢‘è°±æ¸…æ™°åº¦ã€‚ The MediaEval 2012 TUM feature set for violent video scenes detection é’ˆå¯¹å¥½è±åæµè¡Œç”µå½±çš„æš´åŠ›è¿›è¡Œæ£€æµ‹çš„ç‰¹å¾é›†åœ¨config/mediaeval2012_tum_affect/ï¼Œé‡Œé¢æœ‰ä¸åŒçš„è®¾ç½®ï¼Œå‚è€ƒæ–‡ç« ï¼šFlorian Eyben, Felix Weninger, Nicolas Lehment, Gerhard Rigoll, BjÃ¶rn Schuller: â€Violent Scenes Detection with Large, Brute-forced Acoustic and Visual Feature Setsâ€, Proc. MediaEval 2012 Workshop, Pisa, Italy, 04.-05.10.2012. MediaEval Audio IS12based subwin2.confåŒ…å«çš„æ˜¯ä»2sçš„å­çª—ä¸­æå–éŸ³é¢‘ç‰¹å¾çš„é…ç½®ã€‚MediaEval Audio IS12based subwin2 step0.5.confæå–ä¸€æ ·çš„ç‰¹å¾ï¼Œä½†æ˜¯2så­çª—çš„åç§»ä¸º0.5sã€‚MediaEval VideoFunctionals.confç”¨äºè§†é¢‘ç‰¹å¾æå–ï¼Œå¦‚æ–‡ç« ä½¿ç”¨æ–¹æ³•ï¼Œéœ€è¦ä¸€ä¸ªåŒ…å«LLDsçš„CSVæ–‡ä»¶ï¼ˆç”±openCVæå–ï¼‰ä½œä¸ºè¾“å…¥å’Œè¾“å‡ºï¼ŒARFFæ–‡ä»¶ä½œä¸ºè§†é¢‘ç‰¹å¾ã€‚ The openSMILE/openEAR â€˜emobaseâ€™ setæ—©æœŸçš„åŸºçº¿é›†ï¼ˆå‚ç…§â€emobase2â€é›†ä½œä¸ºæ–°çš„åŸºçº¿é›†ï¼‰ï¼Œæ‹¥æœ‰æƒ…æ„Ÿè¯†åˆ«çš„998ä¸ªå£°å­¦ç‰¹å¾ï¼ŒåŒ…å«ä»¥ä¸‹ä½çº§æè¿°ç¬¦ï¼ˆLLDsï¼‰ï¼šå¼ºåº¦ï¼Œå“åº¦ï¼Œ12 MFCCï¼ŒéŸ³é«˜ï¼ˆF0ï¼‰ï¼ŒæµŠéŸ³æ¦‚ç‡ï¼ŒF0åŒ…ç»œçº¿ï¼Œ8 LSFï¼ˆçº¿é¢‘è°±é¢‘ç‡ï¼‰ï¼Œè¿‡é›¶ç‡ï¼Œ ä»¥åŠè¿™äº›LLDçš„Deltaå›å½’ç³»æ•°ã€‚ä»¥ä¸‹å‡½æ•°è¢«åº”ç”¨äºä¸Šè¿°LLDsåŠå…¶Deltaç³»æ•°ã€‚ï¼šMax./Minã€‚è¾“å…¥çš„ç›¸å¯¹ä½ç½®å’ŒèŒƒå›´ï¼ŒèŒƒå›´ï¼Œç®—æœ¯å¹³å‡å€¼ï¼Œ2çº¿æ€§å›å½’ç³»æ•°ï¼Œçº¿æ€§å’ŒäºŒæ¬¡è¯¯å·®ï¼Œæ ‡å‡†å·®ï¼Œååº¦ï¼Œå³°åº¦ï¼Œå››åˆ†ä½æ•°1-3å’Œä¸‰ä½å››åˆ†ä½æ•°èŒƒå›´ã€‚ The large openSMILE emotion feature setç”¨äºæå–æ›´å¤šçš„LLDså’Œæ›´å¤šçš„å‡½æ•°(6552ä¸ªç‰¹å¾)ï¼Œé…ç½®æ–‡ä»¶ä¸ºconfig/emo_large.confã€‚ The openSMILE â€˜emobase2010â€™ reference set æ˜¯åŸºäºthe INTERSPEECH 2010 Paralinguistic Challenge feature setï¼Œé…ç½®æ–‡ä»¶ä¸ºconfig/emobase2010.confã€‚å¯¹æŒç»­æ—¶é—´å’Œä½ç½®ç‰¹å¾çš„è§„èŒƒåŒ–è¿›è¡Œäº†ä¸€äº›è°ƒæ•´ã€‚è¿™ä¸ªç‰¹æ€§é›†åŒ…å«äº†ä¸€å¥—å¤§å¤§å¢å¼ºçš„ä½çº§æè¿°ç¬¦(LLDs)ï¼Œä»¥åŠä¸€å¥—â€œemobaseâ€ç›¸æ¯”æ›´åŠ ç²¾ç»†åŒ–é€‰æ‹©çš„å‡½æ•°åˆ—è¡¨ã€‚å»ºè®®ä½¿ç”¨æ­¤ç‰¹å¾é›†ä½œä¸ºæ¯”è¾ƒæ–°çš„æƒ…æ„Ÿè¯†åˆ«ç‰¹å¾é›†å’Œæ–¹æ³•çš„å‚è€ƒï¼Œå› ä¸ºå®ƒä»£è¡¨å½“å‰æœ€å…ˆè¿›çš„æƒ…æ„Ÿå’Œè¯­è¨€è¯†åˆ«åŠŸèƒ½ã€‚è¯¥é›†åˆåŒ…å«1582ä¸ªç‰¹å¾ï¼ˆä¸INTERSPEECH 2010 Paralinguistic æŒ‘æˆ˜é›†ç›¸åŒè®¾ç½®ï¼‰ï¼Œå…¶ç”±34ä¸ªä½çº§æè¿°ç¬¦ï¼ˆLLDsï¼‰å’Œ34ä¸ªç›¸åº”çš„deltaä½œä¸º68ä¸ªLLDsè½®å»“å€¼ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šåº”ç”¨21ä¸ªå‡½æ•°å¾—åˆ°1 428ä¸ªç‰¹å¾ï¼Œå¦å¤–ï¼Œå¯¹4ä¸ªåŸºäºéŸ³é«˜çš„LLDåŠå…¶4ä¸ªdeltaç³»æ•°åº”ç”¨äº†19ä¸ªå‡½æ•°å¾—åˆ°152ä¸ªç‰¹å¾ï¼Œæœ€åé™„åŠ éŸ³é«˜ï¼ˆä¼ªéŸ³èŠ‚ï¼‰çš„æ•°é‡å’Œæ€»æ•°è¾“å…¥çš„æŒç»­æ—¶é—´ï¼ˆ2ä¸ªç‰¹å¾ï¼‰ã€‚å”¯ä¸€çš„åŒºåˆ«æ˜¯INTERSPEECH 2010 paralinguisticæŒ‘æˆ˜é›†æ ‡å‡†åŒ–çš„æ˜¯æ˜¯â€œmaxPosâ€å’Œâ€œminPosâ€ç‰¹å¾ï¼Œæœ¬é…ç½®è¢«æ ‡å‡†åŒ–ä¸ºæ®µé•¿åº¦ã€‚ pythonæ‰¹å¤„ç†æå–openSMILEç‰¹å¾æ‰€æœ‰æ”¯æŒæ ‡å‡†æ•°æ®è¾“å‡ºæ ¼å¼çš„é…ç½®æ–‡ä»¶éƒ½å¯ä»¥åœ¨WINDOWSçš„æ‰¹ç‰¹å¾æå–GUIï¼ˆä½¿ç”¨VS10 C#ç¼–å†™ï¼Œä½äºprogsrc/openSMILEbatchGUI/ï¼‰ã€‚è¿™ä¸ªå·¥å…·å…è®¸openSMILEè‡ªåŠ¨çš„æ‰§è¡Œæ–‡ä»¶å¤¹ä¸­çš„è‹¥å¹²æ–‡ä»¶ã€‚å®ƒå¯ä»¥åœ¨å›¾å½¢ç•Œé¢ä¸­é€‰æ‹©éŸ³é¢‘æ–‡ä»¶å’ŒæŒ‡å®šè¾“å‡ºç±»å‹ã€‚openSMILEæœ¬èº«æä¾›æ‰¹å¤„ç†GUIï¼ˆä½¿ç”¨VS10 C#ç¼–å†™ï¼Œä½äºprogsrc/openSMILEbatchGUI/ï¼‰ï¼Œä½†è‹¥è¯­éŸ³æ•°æ®çš„ç›®å½•ç»“æ„è¾ƒå¤æ‚ï¼Œè¿˜å¯ä»¥åˆ©ç”¨pythonæ¥è¿›è¡Œæ‰¹å¤„ç†ã€‚ç¤ºä¾‹ä»£ç å¦‚ä»¥ä¸‹ï¼š import os from subprocess import call def excute_CMD(path_ExcuteFile, path_Config, path_Audio, path_Output): cmd = path_ExcuteFile + &quot; -C &quot; + path_Config + &quot; -I &quot; + path_Audio + &quot; -O &quot; + path_Output call(cmd, shell=True) def batch_extract_features(path_Config, path_Input_Root, path_Output): path_ExcuteFile = &quot;SMILExtract_Release&quot; filename = os.listdir(path_Input_Root) for i in range(len(filename)): print(&#39;Extracting features of %s&#39; % filename[i]) path_Input = path_Input_Root + &#39;/&#39; + filename[i] + &#39;.wav&#39; excute_CMD(path_ExcuteFile, path_Config, path_Input, path_Output) path_Config = &quot;./config/IS13_ComParE.conf&quot; path_Input_Root = &#39;root_path_to_audio/&#39; path_Output = &#39;features.csv&#39; batch_extract_features(path_Config, path_Input_Root, path_Output) è¾“å‡ºæ•°æ®æ ¼å¼æ§åˆ¶å¯¹äºä¸åŒ…å«ç»Ÿè®¡å‡½æ•°çš„é…ç½®æ–‡ä»¶ï¼Œé€‰é¡¹å®šä¹‰åœ¨config/shared/standard_data_output_lldonly.conf.inc ==============================LLD only============================= ================================CSV================================ -csvoutput &lt;filename&gt; é»˜è®¤è¾“å‡ºé€‰é¡¹. CSVæ ¼å¼ï¼Œå­˜æ”¾å¸§å‘LLD -appendcsv &lt;0/1&gt; è®¾ä¸º1ä»£è¡¨æ·»åŠ åˆ°å·²æœ‰CSVæ–‡ä»¶æ–‡æœ«ï¼Œé»˜è®¤0 -timestampcsv &lt;0/1&gt; è®¾ä¸º0ç¦æ­¢æŠŠæ—¶é—´æ­¥è¾“å‡ºåˆ°CSVç¬¬äºŒåˆ—ï¼Œé»˜è®¤ä¸º1 -headercsv &lt;0/1&gt; è®¾ä¸º0ç¦æ­¢æŠŠæ ‡é¢˜è¾“å…¥åˆ°CSVï¼Œé»˜è®¤ä¸º1 ================================HTK================================ -output &lt;filename&gt; è¾“å‡ºç‰¹å¾æ±‡æ€»ï¼ˆå‡½æ•°ï¼‰åˆ°HTKæ ¼å¼æ–‡ä»¶ ================================ARFF=============================== -arffoutput &lt;filename&gt; é»˜è®¤è¾“å‡ºé€‰é¡¹. ARFFæ ¼å¼ï¼Œå­˜æ”¾å¸§å‘LLD -appendarff &lt;0/1&gt; è®¾ä¸º0ä»£è¡¨ä¸æ·»åŠ åˆ°å·²æœ‰ARFFæ–‡ä»¶æ–‡æœ«ï¼Œé»˜è®¤1æ·»åŠ  -timestamparff &lt;0/1&gt; è®¾ä¸º0ç¦æ­¢æŠŠæ—¶é—´æ­¥è¾“å‡ºåˆ°ARFFç¬¬äºŒåˆ—ï¼Œé»˜è®¤ä¸º1 arfftargetsfile &lt;file&gt;æŒ‡å®šé…ç½®åŒ…å«å®šä¹‰ç›®æ ‡åŸŸï¼ˆç±»ï¼‰çš„æ–‡ï¼Œé»˜è®¤ä¸º:shared/arff_targets_conf.inc å¯¹äºåŒ…å«ç»Ÿè®¡å‡½æ•°çš„é…ç½®æ–‡ä»¶ï¼Œå¦‚å…¨éƒ¨çš„INTERSPEECHå’ŒAVECæŒ‘æˆ˜é›†ï¼Œé€‰é¡¹å®šä¹‰åœ¨config/shared/standard_data_output.conf.inc =============================LLD and func ========================= -instname &lt;string&gt; é€šå¸¸æ˜¯è¾“å…¥æ–‡ä»¶çš„åç§°ä¿å­˜åœ¨CSVå’ŒARFFè¾“å‡ºçš„é¦–åˆ—ã€‚é»˜è®¤æ˜¯&quot;unknow&quot; ================================ARFF=============================== -lldarffoutput, -D &lt;filename&gt; å¯åŠ¨LLDå¸§å‘è¾“å‡ºåˆ°ARFFæ ¼å¼æ–‡ä»¶ -appendarfflld &lt;0/1&gt; è®¾ä¸º1ä»£è¡¨æ·»åŠ åˆ°å·²æœ‰ARFFæ–‡ä»¶æ–‡æœ«ï¼Œé»˜è®¤0è¦†ç›– -timestamparfflld &lt;0/1&gt; è®¾ä¸º0ç¦æ­¢æŠŠæ—¶é—´æ­¥è¾“å‡ºåˆ°ARFFç¬¬äºŒåˆ—ï¼Œé»˜è®¤ä¸º1 -lldarfftargetsfile &lt;file&gt; æŒ‡å®šé…ç½®åŒ…å«å®šä¹‰ç›®æ ‡åŸŸï¼ˆç±»ï¼‰çš„æ–‡ï¼Œé»˜è®¤ä¸º: shared/arff_targets_conf.inc ================================CSV================================ -lldcsvoutput, -D &lt;filename&gt; å¯åŠ¨LLDå¸§å‘è¾“å‡ºåˆ°CSVæ ¼å¼æ–‡ä»¶ -appendcsvlld &lt;0/1&gt; è®¾ä¸º1ä»£è¡¨æ·»åŠ åˆ°å·²æœ‰CSVæ–‡ä»¶æ–‡æœ«ï¼Œé»˜è®¤0è¦†ç›– -timestampcsvlld &lt;0/1&gt; è®¾ä¸º0ç¦æ­¢æŠŠæ—¶é—´æ­¥è¾“å‡ºåˆ°CSVç¬¬äºŒåˆ—ï¼Œé»˜è®¤ä¸º1 -headercsvlld &lt;0/1&gt; è®¾ä¸º0ç¦æ­¢æŠŠæ ‡é¢˜è¾“å…¥åˆ°CSVï¼Œé»˜è®¤ä¸º1 ================================HTK================================ -lldhtkoutput &lt;filename&gt; å¯åŠ¨LLDå¸§å‘è¾“å‡ºåˆ°HTKæ ¼å¼æ–‡ä»¶ ================================ARFF=============================== -output, -O &lt;filename&gt; é»˜è®¤è¾“å‡ºé€‰é¡¹. ARFFæ ¼å¼ï¼Œå­˜æ”¾ç‰¹å¾æ±‡æ€» -appendarff &lt;0/1&gt; è®¾ä¸º0ä»£è¡¨ä¸æ·»åŠ åˆ°å·²æœ‰ARFFæ–‡ä»¶æ–‡æœ«ï¼Œé»˜è®¤1æ·»åŠ  -timestamparff &lt;0/1&gt; è®¾ä¸º1æŠŠæ—¶é—´æ­¥è¾“å‡ºåˆ°ARFFç¬¬äºŒåˆ—ï¼Œé»˜è®¤ä¸º0 -arfftargetsfile &lt;file&gt;æŒ‡å®šé…ç½®åŒ…å«å®šä¹‰ç›®æ ‡åŸŸï¼ˆç±»ï¼‰çš„æ–‡ï¼Œé»˜è®¤ä¸º: shared/arff_targets_conf.inc ================================CSV================================ -csvoutput &lt;filename&gt; é»˜è®¤è¾“å‡ºé€‰é¡¹. CSVæ ¼å¼ï¼Œå­˜æ”¾ç‰¹å¾æ±‡æ€» -appendcsv &lt;0/1&gt; è®¾ä¸º0ä»£è¡¨ä¸æ·»åŠ åˆ°å·²æœ‰CSVæ–‡ä»¶æ–‡æœ«ï¼Œé»˜è®¤1 -timestampcsv &lt;0/1&gt; è®¾ä¸º0ç¦æ­¢æŠŠæ—¶é—´æ­¥è¾“å‡ºåˆ°CSVç¬¬äºŒåˆ—ï¼Œé»˜è®¤ä¸º1 -headercsv &lt;0/1&gt; è®¾ä¸º0ç¦æ­¢æŠŠæ ‡é¢˜è¾“å…¥åˆ°CSVï¼Œé»˜è®¤ä¸º1 ================================HTK================================ -htkoutput &lt;filename&gt; è¾“å‡ºç‰¹å¾æ±‡æ€»ï¼ˆå‡½æ•°ï¼‰åˆ°HTKæ ¼å¼æ–‡ä»¶ å¦‚ä¸‹ä¸ºlldcsvoutputçš„å®šä¹‰ã€‚æ³¨ï¼šä»2.2ç‰ˆæœ¬èµ·ï¼Œå¯ä»¥æŒ‡å®šä¸€ä¸ªâ€œ?â€æ›¿ä»£æ–‡ä»¶åã€‚å®ƒä¼šç¦æ­¢ç›¸åº”çš„è¾“å‡ºç»„ä»¶ï¼Œå³å®ƒä¸ä¼šäº§ç”Ÿè¾“å‡ºæ–‡ä»¶ï¼Œåœ¨æ ‡å‡†è¾“å‡ºæ¥å£ç•Œé¢ï¼Œçœ‹åˆ°çš„æ‰€æœ‰çš„æ–‡ä»¶åé»˜è®¤éƒ½æ˜¯â€?â€ [lldsink:cCsvSink] reader.dmLevel = lld;lld_de filename=\\cm[lldcsvoutput(D){?}:output csv file for LLD, disabled by default ?, only written if filename given] instanceName=\\cm[instname(N){unknown}:instance name] append = \\cm[appendcsvlld{0}:set to 1 to append to the LLD output csv file, default is not to append] timestamp = \\cm[timestampcsvlld{1}:set to 0 to suppress timestamp column, default is 1, i.e. to show timestamp in second column] number = 0 printHeader = \\cm[headercsvlld{1}:set to 0 to suppress header line with feature names, default is 1, i.e. to show header line] errorOnNoOutput = 1 é‚£ä¹ˆï¼Œå½“éœ€è¦åŒæ—¶è¾“å‡ºlldå’Œfuncæ—¶ï¼Œå¯ç”¨å¦‚ä¸‹å‘½ä»¤ SMILExtract -C config/IS13_ComParE.conf -I input.wav -lldcsvoutput lld_output.csv -csvoutput func_output.csv æœ€åä¸€ç‚¹è¯å…¶å®å¦‚æœåªæ˜¯ç”¨å®˜æ–¹é…ç½®æç‰¹å¾é‚£ä¹ˆåªçœ‹æ‰¹å¤„ç†é‚£é‡Œä¹Ÿå¤Ÿäº†ã€‚å®˜æ–¹é…ç½®æ–‡ä»¶å¯ä»¥æ ¹æ®éœ€æ±‚æ—¶å†çœ‹éœ€è¦å“ªä¸ªæ–‡ä»¶ï¼Œä¹Ÿå¯è‡ªå·±æŒ‰ç€è¿™ä¸ªæ ¼å¼è‡ªå®šä¹‰ç¼–å†™é…ç½®æ–‡ä»¶ã€‚å¦å¤–è¾“å‡ºæ ¼å¼æ§åˆ¶æ„Ÿè§‰æœ€å¥½ä¹Ÿæ˜¯å…ˆçœ‹ä¸€ä¸‹ï¼Œæˆ‘ä¸€å¼€å§‹éƒ½æ˜¯ç›´æ¥ç”¨ -O è¾“å‡ºç»Ÿè®¡ç‰¹å¾ï¼Œä½†æƒ³è¾“å‡ºlldæ—¶è·‘å»æºä»£ç é‡Œä¸€é˜µæ£é¼“ï¼Œåæ¥æ‰å‘ç°å®ƒå·²ç»å°è£…å¥½äº†ç›´æ¥ä¸€ä¸ªå‚æ•°å°±å¯ä»¥äº†ã€‚ å½©è›‹","categories":[{"name":"è¯­éŸ³ç‰¹å¾","slug":"è¯­éŸ³ç‰¹å¾","permalink":"http://weiquanfan.xyz/categories/è¯­éŸ³ç‰¹å¾/"}],"tags":[]},{"title":"è¯­è°±å›¾çš„matlabæå–å’Œpythonæå–","slug":"specgram","date":"2020-05-02T08:43:28.000Z","updated":"2020-06-20T06:01:56.655Z","comments":true,"path":"2020/05/02/specgram/","link":"","permalink":"http://weiquanfan.xyz/2020/05/02/specgram/","excerpt":"","text":"å‰è¨€è¯­è°±å›¾ï¼ˆspectrogramæˆ–specgramï¼‰ï¼Œä¹Ÿå«å£°è°±å›¾ï¼Œå¯ä»¥ç®€å•çœ‹åšä¸€ä¸ªäºŒç»´çŸ©é˜µï¼Œå…¶çºµè½´è¡¨ç¤ºé¢‘ç‡ï¼Œæ¨ªè½´è¡¨ç¤ºæ—¶é—´ï¼ŒçŸ©é˜µçš„å€¼è¡¨ç¤ºèƒ½é‡å¼ºå¼±ã€‚ç”±äºå®ƒæ‹¥æœ‰ç€é¢‘ç‡å’Œæ—¶é—´ä¸¤ä¸ªç»´åº¦çš„ä¿¡æ¯ï¼Œæ‰€ä»¥æ˜¯æ¯”è¾ƒç»¼åˆåœ°è¡¨ç¤ºåŸè¯­éŸ³ä¿¡æ¯çš„ä¸€ç§ç‰¹å¾ã€‚å¦å¤–ï¼Œæˆ‘å°†å…¶çœ‹åšè¯­éŸ³å’Œå›¾åƒçš„ä¸€ç§è¿æ¥ï¼Œå› ä¸ºå›¾åƒé¢†åŸŸçš„æ¨¡å‹å‘å±•å¾—è¾ƒå¿«ï¼Œæ‰€ä»¥é€šè¿‡è¿™ç§æ–¹å¼æŠŠè¯­éŸ³è½¬æ¢æˆä¸€ç§ç‰¹æ®Šçš„å›¾åƒå†è¿›ä¸€æ­¥å¤„ç†ã€‚ è¯­è°±å›¾æµç¨‹ç®€ä»‹1. å°†è¯­éŸ³å¯äº¤å‰åœ°åˆ†æˆå¤šå¸§ï¼ˆç”±äºè¯­éŸ³çš„çŸ­æ—¶å¹³ç¨³æ€§ï¼‰ 2. å„å¸§åŠ çª— 3. å„å¸§é€šè¿‡å¿«é€Ÿå‚…é‡Œå¶å˜åŒ–ï¼ˆfftï¼‰å¾—åˆ°é¢‘è°±å‘é‡ 4. æ²¿ç€æ—¶é—´è½´å¹¶è”å„é¢‘è°±å‘é‡å¾—åˆ°è¯­è°±å›¾ è¯­è°±å›¾çš„æå–è¯­è°±å›¾çš„matlabæå–å…ˆçœ‹ä¸€æ®µéå®˜æ–¹ä»£ç ï¼Œç»“åˆä¸Šè¿°æ­¥éª¤è¿›è¡Œç†è§£ã€‚ [x,Fs,nBits]=wavread(&#39;audio.wav&#39;); s=length(x); % ä¿¡å·é•¿åº¦ w=256; % çª—é•¿ n=w; % nfftï¼Œè¡¨ç¤ºåšfftå˜æ¢éœ€è¦çš„ç‚¹æ•°ï¼Œä¸€èˆ¬ä¸ºåˆšå¤§äºwçš„2çš„å¹‚ã€‚ä¸¾ä¾‹ï¼Œw=250ï¼Œåˆ™nä¸€èˆ¬è®¾ä¸º256 ov=w/2; % åˆ†å¸§çš„äº¤å‰ç¨‹åº¦ï¼Œå¸¸è§è®¾ä¸ºçª—é•¿çš„äºŒåˆ†ä¹‹ä¸€æˆ–å››åˆ†ä¹‹ä¸€ h=w-ov; % ä¸é‡å ç‚¹æ•° win=hamming(n)&#39;;% é€‰äº†å¸¸è§çš„æ±‰æ˜çª—ï¼Œå¹¶è®¾ç½®nfft c=1; % æŒ‡å‘å½“å‰å¸§çš„æŒ‡é’ˆ ncols=1+fix((s-n)/h); % è®¡ç®—æ€»å…±æœ‰å¤šå°‘å¸§ d=zeros((1+n/2),ncols); % è¯­è°±å›¾åˆå§‹åŒ– for b=0:h:(s-n) % ä»¥ä¸‹å¤„ç†å„å¸§ u=win.*x((b+1):(b+n)); % å„å¸§åŠ çª— t=fft(u,n); % å„å¸§è¿›è¡Œfftï¼Œå†…å®¹ä¸ºuï¼Œnfft=nã€‚å¯¹äºfftï¼Œè¾“å…¥nä¸ªæ—¶åŸŸç‚¹ï¼Œè¾“å‡ºnä¸ªé¢‘åŸŸç‚¹ d(:,c)=t(1:(1+n/2))&#39;; % å¹¶è”é¢‘è°±å‘é‡ï¼Œæ³¨æ„åªå–1+n/2ï¼Œå› ä¸ºè´Ÿé¢‘ç‡æ— æ„ä¹‰ï¼Œåªç•™ä¸‹0å’Œæ­£é¢‘ç‡ c=c+1; % ç§»åŠ¨æŒ‡é’ˆ end tt=[0:h:(s-n)]/Fs; % æ—¶é—´è½´ ff=[0:(n/2)]*Fs/n; % é¢‘ç‡è½´ imagesc(tt/1000,ff/1000,20*log10(abs(d))); % ç»˜åˆ¶ colormap(hot); axis xy xlabel(&#39;æ—¶é—´/s&#39;); ylabel(&#39;é¢‘ç‡/kHz&#39;); ç„¶è€Œï¼Œmatlabå…¶å®æœ‰å°è£…å¥½çš„å‡½æ•°å¯ä»¥ç›´æ¥è°ƒç”¨ã€‚ [S,F,T]=specgram(x,nfft,Fs,windows_length,overlap_length) % x ä¸ºæ•´æ®µè¯­éŸ³ % nfft ä¸ºfftå˜æ¢ç‚¹æ•°ï¼Œå…¶å®å¯ä»¥ç›´æ¥ç”¨é»˜è®¤çš„åˆšå¤§äºçª—é•¿çš„2çš„å¹‚ã€‚ä¹Ÿå¯è‡ªå®šä¹‰ä¸ºå¤§äºçª—é•¿çš„æ•´æ•°ï¼Œä¼šå¯¹å¸§è¿›è¡Œè¡¥é›¶æ“ä½œ % Fs è¯­éŸ³é‡‡æ ·é¢‘ç‡ % windows_length çª—é•¿ % overlap_length äº¤å‰é•¿åº¦ % S è¯­è°±å›¾ % F é¢‘ç‡å€¼ï¼Œå°ºåº¦ä¸º1+n/2 % T æ—¶é—´å€¼ï¼Œå°ºåº¦ä¸º1+fix((s-n)/h) è¯­è°±å›¾çš„pythonæå–æœ‰äº†åˆšæ‰çš„åŸºç¡€ï¼Œpythonçš„ä»£ç å°±å®¹æ˜“ç†è§£å•¦ã€‚é¦–å…ˆåŒæ ·çœ‹ä¸€ä¸‹ä¸ç›´æ¥è°ƒç”¨å‡½æ•°çš„å†™æ³•ã€‚ import numpy as np from scipy.io import wavfile import matplotlib.pyplot as plt Fs, x = wavfile.read(&#39;audio.wav&#39;) wave = np.array(x[:,0], dtype = &quot;float&quot;) frame_len = 1000 frame_off = frame_len // 2 # éé‡å ç‚¹æ•° specg_len = 1024 # å¯ä»¥æƒ³è±¡1æ˜¯ä»£è¡¨ç¬¬ä¸€å¸§ï¼Œç„¶åç¬¬äºŒå¸§ç»“å°¾è¶…å‡ºç¬¬ä¸€å¸§frame_offä¸ªç‚¹ï¼Œç¬¬ä¸‰å¸§å†è¶…å‡ºç¬¬äºŒå¸§frame_offä¸ªç‚¹ï¼Œæ€»å…±ç¬¬äºŒå¸§åˆ°æœ€åä¸€å¸§å…±æœ‰(wave.size - frame_len) // frame_off å¸§ frame_num = (wave.size - frame_len) // frame_off + 1 # ç”Ÿæˆæ±‰æ˜çª— hamwindow = np.hamming(frame_len) specg = np.zeros((frame_num, specg_len // 2 + 1)) z = np.zeros(specg_len - frame_len) for idx in range(frame_num): base = idx * frame_off frame = wave[base: base + frame_len] # åˆ†å¸§ frame = np.append(frame * hamwindow, z) # åŠ çª— specg[idx:] = np.log10(np.abs(np.fft.rfft(frame))) # FFTï¼Œè¿”å›å¹…åº¦è°± specg = np.transpose(specg) io.savemat(&#39;specgram.mat&#39;, {&#39;specg&#39;:specg}) # aspectè®¾ä¸ºautoå³å¯è‡ªåŠ¨æ‹‰å®½å›¾ plt.imshow(specg, origin=&quot;lower&quot;, cmap = &quot;jet&quot;, aspect = &quot;auto&quot;, interpolation = &quot;none&quot;) plt.show() plt.xticks([]) plt.yticks([]) plt.savefig(&#39;specgram.png&#39;,bbox_inches=&#39;tight&#39;,pad_inches=0.0) plt.close() å†çœ‹çœ‹å·²ç»å°è£…å¥½çš„ç‰ˆæœ¬ã€‚ from scipy import io from scipy.io import wavfile import matplotlib.pyplot as plt Fs, x = wavfile.read(&#39;audio.wav&#39;) # è¯»å–éŸ³é¢‘ specg = plt.specgram(x, Fs = Fs, pad_to = 256, NFFT = 256, noverlap = 128) # æå–è¯­è°±å›¾ï¼Œä¸€é”®æ“ä½œï¼ io.savemat(&#39;specgram.mat&#39;, {&#39;specg&#39;:specg[0]}) # ä¿å­˜è¯­è°±å›¾ ## ç…§ä¾‹è§£é‡Šä¸‹å‚æ•° # xï¼ŒFså’Œä¸Šè¾¹ä¸€æ · # pad_toä¸ºä¸Šè¾¹çš„nfft # NFFTä¸ºä¸Šè¾¹çš„windows_lengthï¼ˆä¸ºä»€ä¹ˆnfftä¸è®¾ç½®ä¸ºä¸Šè¾¹çš„nfftå‘¢ï¼Œè¿·æƒ‘ï¼‰ # noverlapä¸ºä¸Šè¾¹çš„overlap_length è¡¥å……ä¸€ä¸ªlibrosaç‰ˆæœ¬librosaæå–çš„æ˜¯æ¢…å°”é¢‘è°±å›¾ï¼Œå³åœ¨é¢‘è°±å›¾åŸºç¡€ä¸Šå†è¿›ä¸€æ­¥å°†å„å¸§é€šè¿‡æ¢…å°”æ»¤æ³¢å™¨(è¿˜å¯åŠ å¯¹æ•°æ“ä½œ)ã€‚å¦å¤–è‹¥æ˜¯åœ¨æ­¤åŸºç¡€ä¸Šå†è¿›è¡Œå€’è°±å³è·å¾—MFCCã€‚è¿˜è¦æ³¨æ„åˆ°ï¼Œæ¢…å°”é¢‘è°±å›¾çš„è¾“å‡ºå°ºå¯¸ï¼Œé¢‘ç‡ç­‰äºæ¢…å°”æ»¤æ³¢å™¨çš„ä¸ªæ•°n_mels, æ—¶é—´åˆ™åªå–å†³äºçª—ç§»(éé‡å æ•°)hop_length(è¿˜æ²¡æƒ³æ˜ç™½ï¼Œæ¨æµ‹å¯èƒ½æ˜¯è¿›è¡Œäº†å¡«å……ï¼Œæ‰€ä»¥å°ºå¯¸ä¸Šå¿½è§†äº†çª—é•¿çš„å½±å“)ã€‚æ­¤å¤–ï¼Œè¿˜å¯é€šè¿‡è®¾ç½®powerå‚æ•°æ¥ç¡®å®šè¦è®¡ç®—æ¢…å°”é¢‘è°±å›¾(è®¾ç½®ä¸º1)è¿˜æ˜¯æ¢…å°”åŠŸç‡å›¾(è®¾ç½®ä¸º2)ã€‚ from matplotlib import pyplot as plt import librosa import librosa.display # Load a wav file y, sr = librosa.load(&#39;./test.wav&#39;, sr=None) # plot a wavform plt.figure() librosa.display.waveplot(y, sr) # plt.plot(y) plt.title(&#39;wavform&#39;) plt.show() # extract mel spectrogram feature melspec = librosa.feature.melspectrogram(y, sr, n_fft=1024, win_length=1024, hop_length=512, n_mels=128, power=2.0) # convert to log scale logmelspec = librosa.power_to_db(melspec) # plot mel spectrogram plt.figure() librosa.display.specshow(logmelspec, sr=sr, x_axis=&#39;time&#39;, y_axis=&#39;mel&#39;) plt.title(&#39;spectrogram&#39;) plt.show() # aspectè®¾ä¸ºautoå³å¯è‡ªåŠ¨æ‹‰å®½å›¾ plt.imshow(logmelspec, origin=&quot;lower&quot;, cmap = &quot;jet&quot;, aspect = &quot;auto&quot;, interpolation = &quot;none&quot;) plt.show() plt.xticks([]) plt.yticks([]) plt.savefig(&#39;specgram.png&#39;,bbox_inches=&#39;tight&#39;,pad_inches=0.0) plt.close() ä¸‹å›¾ä¸­ï¼Œç¬¬ä¸€å¼ æ˜¯æ¢…å°”é¢‘è°±å›¾ï¼Œç¬¬äºŒå¼ æ˜¯æ¢…å°”åŠŸç‡å›¾ï¼ŒåŠŸç‡å›¾çš„å£°éŸ³å’Œå™ªå£°åŒºåˆ†æ›´æ˜æ˜¾ã€‚è€Œä¸¤è€…éƒ½æ¯”æ²¡æœ‰æ¢…å°”æ»¤æ³¢å™¨çš„é¢‘è°±å›¾æœ‰æ›´ç‹¬ç‰¹æ˜æ˜¾çš„èƒ½é‡æ˜¾ç¤ºã€‚ è¯­è°±å›¾çš„ä¸€äº›å¯èƒ½æœ‰çš„å°ç–‘æƒ‘ å…³äºnfftnfftæ—¢è¡¨ç¤ºæ—¶åŸŸçš„ç‚¹æ•°ä¹Ÿå…³è”é¢‘åŸŸçš„ç‚¹æ•°ã€‚è¯¥æ•°ä¸º2çš„å¹‚æ•°æ—¶æ›´é«˜æ•ˆï¼Œä½†ä¸æ˜¯ä¹Ÿæ²¡é—®é¢˜ã€‚nfftéœ€è¦æ¯”çª—é•¿çš„å€¼æ›´å¤§ï¼Œç„¶ååŠ çª—åçš„å¸§ä¼šè¢«è¡¥é›¶åˆ°nffté•¿åº¦å†è¿›è¡Œfftã€‚ å…³äºé¢‘ç‡åˆ†è¾¨ç‡é¢‘ç‡è½´ä¸Šæ¯ä¸€ä¸ªç‚¹å¯¹åº”fs/nfftçš„é¢‘ç‡ã€‚å¦å¤–ç”±äºè¾“å‡ºnfft/2+1ä¸ªé¢‘ç‡ç‚¹ï¼Œæ‰€ä»¥è¾“å‡ºçš„é¢‘ç‡èŒƒå›´ä¸º0åˆ°nfft/2Ã—fs/nfft=fs/2ã€‚ å…³äºè‡ªå®šä¹‰è¾“å‡ºè¯­è°±å›¾çš„å°ºå¯¸é—®é¢˜æ—¶é—´è½´å°ºå¯¸ä¸º1+fix((s-n)/h)ï¼Œ ç”±windows_lengthå’Œoverlap_lengthå†³å®šã€‚å®é™…åº”ç”¨æ—¶ç”±äºå„è¯­éŸ³é•¿åº¦ä¸åŒï¼Œæ—¶é—´å°ºå¯¸ä¸€èˆ¬éƒ½è¦è¿›è¡Œæˆªæ–­æˆ–è¡¥é›¶åˆ°ä¸€ä¸ªå›ºå®šå€¼ã€‚æˆªæ–­çš„è¯å¯ä»¥æˆªä¸€æ®µï¼ˆèµ·å§‹ä¿¡æ¯ï¼Œä¸­é—´ä¿¡æ¯ï¼‰ï¼Œä¹Ÿå¯ä»¥æˆªå¤šæ®µï¼ˆäº¤å‰ä¸äº¤å‰éƒ½è¡Œï¼‰ã€‚é¢‘ç‡è½´å°ºå¯¸ä¸º1+n/2ï¼Œä»…å†³å®šäºnfftï¼ˆpythonä¸­çš„pad_toå‚æ•°ï¼‰ï¼Œæ‰€ä»¥å¯ä»¥é€šè¿‡è®¾ç½®è¯¥å€¼æ§åˆ¶é¢‘ç‡è½´å°ºå¯¸ã€‚ä½†æ˜¯ä¹Ÿä¸è¦æ¯”çª—é•¿å¤§å¤ªå¤šï¼Œå¦åˆ™è¡¥é›¶å¤ªå¤šå¯èƒ½å°±æ²¡ä»€ä¹ˆä¿¡æ¯äº†ã€‚nfftè°ƒå¤§æ—¶ï¼Œçª—é•¿å¯ä»¥è·Ÿç€è°ƒå¤§ï¼Œä¸ºäº†é˜²æ­¢å¯¼è‡´çš„æ—¶é—´è½´å¤ªçŸ­å¯ä»¥è°ƒé«˜overlap_lengthã€‚å¦å¤–ï¼Œå…¶ä»–å‚æ•°ä¸å˜æ—¶ï¼Œä»…å˜æ¢nfftï¼Œå¯è§†åŒ–å‡ºæ¥æ—¶å¯èƒ½è‚‰çœ¼çœ‹èµ·æ¥ä¸€æ ·ï¼Œä½†å®é™…åˆ†è¾¨ç‡ä»ç„¶æ˜¯ä¸åŒçš„ã€‚è¿™ä¹Ÿå¯¼è‡´äº†ä¸€ä¸ªé—®é¢˜ï¼Œé€å…¥ç½‘ç»œçš„æ˜¯è¦ç”¨å•é€šé“çš„ç›´æ¥è®¡ç®—å‡ºæ¥çš„è¯­è°±å›¾ï¼Œè¿˜æ˜¯ç”¨å¯è§†åŒ–å‡½æ•°ç»˜åˆ¶å‡ºæ¥çš„ä¸‰é€šé“çš„è¯­è°±å›¾ï¼Œè¿™å°±æ ¹æ®å®é™…æƒ…å†µå»å°è¯•äº†ã€‚ å½©è›‹ å¸Œæœ›ç–«æƒ…æ—©ç‚¹è¿‡å»","categories":[{"name":"è¯­éŸ³ç‰¹å¾","slug":"è¯­éŸ³ç‰¹å¾","permalink":"http://weiquanfan.xyz/categories/è¯­éŸ³ç‰¹å¾/"}],"tags":[]},{"title":"å·ç§¯å½“ä¸­çš„è¡¥é›¶æ“ä½œ","slug":"padding","date":"2020-05-02T08:43:28.000Z","updated":"2020-06-26T02:45:42.701Z","comments":true,"path":"2020/05/02/padding/","link":"","permalink":"http://weiquanfan.xyz/2020/05/02/padding/","excerpt":"","text":"å·ç§¯è¾“å…¥è¾“å‡ºå°ºå¯¸å…¬å¼ è¿™æ˜¯ä¸€æ¡æ¯”è¾ƒå®Œæ•´çš„è¾“å‡ºå°ºå¯¸å…¬å¼ï¼Œè€ƒè™‘åˆ°äº†stride, padding, dilation, è¿™é‡Œçš„æ‹¬å·è¡¨ç¤ºçš„æ˜¯å‘ä¸‹å–æ•´ï¼Œè¿™å®é™…ä¸Šæ˜¯å·ç§¯å›¾çš„è¾¹è¾¹å‰©ä¸‹çš„éƒ¨åˆ†æ¯”å·ç§¯æ ¸å°ï¼Œæ‰€ä»¥æŠ›å¼ƒäº†è¿™æ¬¡å·ç§¯çš„ç»“æœã€‚å…¶å®ï¼Œè‹¥ç”¨å¦ä¸€ç§è§†è§’çœ‹ï¼Œå¯ä»¥æŠŠç©ºæ´å·ç§¯å½“æˆæ›´æ”¹äº†å·ç§¯æ ¸å°ºå¯¸Kçš„å€¼ï¼ŒK -&gt; d Ã— (K-1) +1ï¼Œå› æ­¤è¯¥å…¬å¼å¯ä»¥æ›´ç®€æ´çš„è¢«è¡¨ç¤ºä¸ºOut = floor((In + 2P âˆ’ K)/S+1) tensorflow ç‰ˆæœ¬tensorflow ç‰ˆæœ¬çš„paddingæ˜¯é€šè¿‡ç›´æ¥é€‰æ¨¡å¼å‚æ•°è¿›è¡Œçš„ï¼Œå¯é€‰â€™SAMEâ€™,â€™VALIDâ€™.å‰è€…æ˜¯é€šè¿‡paddingåœ¨å‰åå·¦å³è¡¥é›¶ï¼Œä½¿å¾—è¾“å‡ºå°ºå¯¸ä¿æŒä¸å˜ï¼ˆæˆ–ä»¥æ­¥é•¿å€æ•°ç¼©å°ï¼‰ï¼Œéå¸¸å¸¸ç”¨ï¼Œåè€…åˆ™æ˜¯ä¸è¿›è¡Œpaddingï¼Œå®é™…ä¸Šåº”è¯¥æ˜¯ç­‰ä»·äºä¸Šè¾¹æ€»å…¬å¼P=0çš„æƒ…å†µã€‚SAME: Out = ceil(In/S)VALID: Out = ceil((In âˆ’ K + 1)/S) pytorch ç‰ˆæœ¬pytorchä¸­paddingæ˜¯éœ€è¦è‡ªå·±è®¾ç½®å€¼çš„ï¼Œå› æ­¤è¾“å‡ºå°ºå¯¸å°±æŒ‰ç…§ä¸€å¼€å§‹çš„å…¬å¼æ¥å³å¯ã€‚ä»¥ä¸‹å†çœ‹ä¸€äº›ä¾‹å­ã€‚ &gt;&gt;&gt; m = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3) &gt;&gt;&gt; input = torch.randn(20,3,24,24) &gt;&gt;&gt; m(input).shape torch.Size([20, 64, 12, 12]) &gt;&gt;&gt; input = torch.randn(20,3,25,25) &gt;&gt;&gt; m(input).shape torch.Size([20, 64, 13, 13]) &gt;&gt;&gt; input = torch.randn(20,3,24,24) &gt;&gt;&gt; m = nn.Conv2d(3, 64, kernel_size=6, stride=2, padding=3) &gt;&gt;&gt; m(input).shape torch.Size([20, 64, 13, 13]) &gt;&gt;&gt; m = nn.Conv2d(3, 64, kernel_size=6, stride=2, padding=2) &gt;&gt;&gt; m(input).shape torch.Size([20, 64, 12, 12]) &gt;&gt;&gt; input = torch.randn(20,3,25,25) &gt;&gt;&gt; m = nn.Conv2d(3, 64, kernel_size=6, stride=2, padding=3) &gt;&gt;&gt; m(input).shape torch.Size([20, 64, 13, 13]) &gt;&gt;&gt; m = nn.Conv2d(3, 64, kernel_size=6, stride=2, padding=2) &gt;&gt;&gt; m(input).shape torch.Size([20, 64, 12, 12]) è¿™é‡Œå¯ä»¥è§‚å¯Ÿåˆ°ï¼š è‹¥æ˜¯éœ€è¦ä¿æŒ å¯¹äºå¥‡æ•°å·ç§¯æ ¸ï¼Œé€šè¿‡è®©padding=(k-1)/2ï¼Œå³å¯å®ç°SAMEçš„æ•ˆæœã€‚å³è¾“å‡ºå°ºå¯¸ä¿æŒä¸å˜æˆ–ä»¥æ­¥é•¿å€æ•°ç¼©å°ï¼ˆå¯¹äºå¥‡æ•°è¾“å…¥å°ºå¯¸åˆ™å‘ä¸Šå–æ•´ï¼‰ å¯¹äºå¶æ•°å·ç§¯æ ¸ï¼Œè‹¥æ˜¯å¶æ•°è¾“å…¥å°ºå¯¸ï¼Œåˆ™padding=floor((k-1)/2)å¯å®ç°SAMEçš„æ•ˆæœ å¯¹äºå¶æ•°å·ç§¯æ ¸ï¼Œè‹¥æ˜¯å¥‡æ•°è¾“å…¥å°ºå¯¸ï¼Œåˆ™padding=ceil((k-1)/2)å¯å®ç°SAMEçš„æ•ˆæœ å› æ­¤ï¼Œå»ºè®®ä¸è¦ç”¨å¶æ•°å·ç§¯æ ¸ã€‚ã€‚ã€‚ç„¶åè®°ä½padding=(k-1)/2ï¼Œå³å¯å®ç°tfä¸­SAMEçš„æ•ˆæœäº†ã€‚æŠŠpaddingå¸¦å…¥ä¸€å¼€å§‹çš„æ€»å…¬å¼ï¼Œå¯ä»¥å¾—åˆ°Out = floor((In âˆ’ 1)/S+1)ï¼Œè¿™å®é™…ä¸Šä¸SAMEå…¬å¼ç­‰æ•ˆï¼Œå¯ä»¥çœ‹ä¸‹è¾¹ä»£ç çš„æš´åŠ›éªŒè¯ã€‚ &gt;&gt;&gt; a = lambda x:np.ceil(x/5) &gt;&gt;&gt; b = lambda x:np.floor((x-1)/5+1) &gt;&gt;&gt; c = [np.random.randint(6,100) for i in range(10)] &gt;&gt;&gt; [a(rand)==b(rand) for rand in c] [True, True, True, True, True, True, True, True, True, True] æ€»ç»“è™½ç„¶æƒ³äº†åŠå¤©è¿™ä¸ªå…¬å¼ï¼Œä½†å®é™…ä½¿ç”¨æ—¶å¥½åƒä¹Ÿå°±SAMEåŠŸèƒ½ç”¨å¾—æ¯”è¾ƒå¤šï¼Œå› æ­¤è®°ä½æ ¸å¿ƒï¼š ç”¨å¥‡æ•°å·ç§¯æ ¸ padding=(k-1)/2 è‹¥æ˜¯ç©ºæ´å·ç§¯ï¼Œåˆ™ä»£å…¥K -&gt; d Ã— (K-1) +1","categories":[],"tags":[{"name":"å·ç§¯","slug":"å·ç§¯","permalink":"http://weiquanfan.xyz/tags/å·ç§¯/"}]}],"categories":[{"name":"è¯­éŸ³ç‰¹å¾","slug":"è¯­éŸ³ç‰¹å¾","permalink":"http://weiquanfan.xyz/categories/è¯­éŸ³ç‰¹å¾/"},{"name":"å·¥å…·ä½¿ç”¨","slug":"å·¥å…·ä½¿ç”¨","permalink":"http://weiquanfan.xyz/categories/å·¥å…·ä½¿ç”¨/"},{"name":"è¯­éŸ³é¢„å¤„ç†","slug":"è¯­éŸ³é¢„å¤„ç†","permalink":"http://weiquanfan.xyz/categories/è¯­éŸ³é¢„å¤„ç†/"},{"name":"è¯­éŸ³è¯†åˆ«","slug":"è¯­éŸ³è¯†åˆ«","permalink":"http://weiquanfan.xyz/categories/è¯­éŸ³è¯†åˆ«/"},{"name":"ç•Œé¢","slug":"ç•Œé¢","permalink":"http://weiquanfan.xyz/categories/ç•Œé¢/"},{"name":"å¼ºåŒ–å­¦ä¹ ","slug":"å¼ºåŒ–å­¦ä¹ ","permalink":"http://weiquanfan.xyz/categories/å¼ºåŒ–å­¦ä¹ /"},{"name":"çˆ¬è™«","slug":"çˆ¬è™«","permalink":"http://weiquanfan.xyz/categories/çˆ¬è™«/"},{"name":"æ·±åº¦å­¦ä¹ æ¨¡å‹","slug":"æ·±åº¦å­¦ä¹ æ¨¡å‹","permalink":"http://weiquanfan.xyz/categories/æ·±åº¦å­¦ä¹ æ¨¡å‹/"},{"name":"æœºå™¨å­¦ä¹ ","slug":"æœºå™¨å­¦ä¹ ","permalink":"http://weiquanfan.xyz/categories/æœºå™¨å­¦ä¹ /"}],"tags":[{"name":"å·¥å…·ä½¿ç”¨","slug":"å·¥å…·ä½¿ç”¨","permalink":"http://weiquanfan.xyz/tags/å·¥å…·ä½¿ç”¨/"},{"name":"è¯­éŸ³é¢„å¤„ç†","slug":"è¯­éŸ³é¢„å¤„ç†","permalink":"http://weiquanfan.xyz/tags/è¯­éŸ³é¢„å¤„ç†/"},{"name":"ç«¯ç‚¹æ£€æµ‹","slug":"ç«¯ç‚¹æ£€æµ‹","permalink":"http://weiquanfan.xyz/tags/ç«¯ç‚¹æ£€æµ‹/"},{"name":"è¯­éŸ³è¯†åˆ«","slug":"è¯­éŸ³è¯†åˆ«","permalink":"http://weiquanfan.xyz/tags/è¯­éŸ³è¯†åˆ«/"},{"name":"ç•Œé¢","slug":"ç•Œé¢","permalink":"http://weiquanfan.xyz/tags/ç•Œé¢/"},{"name":"å¼ºåŒ–å­¦ä¹ ","slug":"å¼ºåŒ–å­¦ä¹ ","permalink":"http://weiquanfan.xyz/tags/å¼ºåŒ–å­¦ä¹ /"},{"name":"attention","slug":"attention","permalink":"http://weiquanfan.xyz/tags/attention/"},{"name":"BERT","slug":"BERT","permalink":"http://weiquanfan.xyz/tags/BERT/"},{"name":"Transformer","slug":"Transformer","permalink":"http://weiquanfan.xyz/tags/Transformer/"},{"name":"GLUE","slug":"GLUE","permalink":"http://weiquanfan.xyz/tags/GLUE/"},{"name":"å·ç§¯","slug":"å·ç§¯","permalink":"http://weiquanfan.xyz/tags/å·ç§¯/"}]}