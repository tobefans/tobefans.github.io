<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[opensmile 工具的使用和批处理]]></title>
    <url>%2F2020%2F05%2F02%2Fopensmile%2F</url>
    <content type="text"><![CDATA[前言openSMILE是一款以命令行形式运行的工具，通过配置config文件来提取音频特征。主要应用于语音识别、情感计算、音乐信息获取。2.0版本之后的openSMILE包括了openCV库，可以用于视频处理和视频特征提取。官网下载有linux和windows版本提供下载，windows可以不编译直接用，建议在命令行里指明 openSMILE 绝对路径。 openSMILE的输入输出格式文件输入格式 RIFF-WAVE (PCM) (for MP3, MP4, OGG, etc. a converter needs to be used) Comma Separated Value (CSV) HTK parameter files WEKA’s ARFF format.（由htk工具产生） Video streams via openCV.（opencv产生的视频流数据） 文件输出格式 RIFF-WAVE (PCM uncompressed audio) Comma Separated Value (CSV) HTK parameter file WEKA ARFF file LibSVM feature file format Binary float matrix format 分类器和其他组件openSMILE还提供了许多VAD算法，用于判断各时间点有没有说话。 Voice Activity Detection based on Fuzzy Logic Voice Activity Detection based on LSTM-RNN with pre-trained models Turn-/Speech-segment detector LibSVM (on-line) LSTM-RNN (Neural Network) classifier which can load RNNLIB and CURRENNT nets GMM (experimental implementation from eNTERFACE’12 project, to be release soon) SVM sink (for loading linear kernel WEKA SMO models) Speech Emotion recognition pre-trained models (openEAR) openSMILE使用流程简介 先切换到处理文件SMILExtract.exe所在的目录 通过如下语句提取：windows下：SMILExtract_Release -C “配置文件” -I “要处理的音频” -O “要保存特征向量的路径及文件名”linux下：SMILExtract -C “配置文件” -I “要处理的音频” -O “要保存特征向量的路径及文件名” python批处理提取openSMILE特征所有支持标准数据输出格式的配置文件都可以在WINDOWS的批特征提取GUI（使用VS10 C#编写，位于progsrc/openSMILEbatchGUI/）。这个工具允许openSMILE自动的执行文件夹中的若干文件。它可以在图形界面中选择音频文件和指定输出类型。openSMILE本身提供批处理GUI（使用VS10 C#编写，位于progsrc/openSMILEbatchGUI/），但若语音数据的目录结构较复杂，还可以利用python来进行批处理。示例代码如以下： import os from subprocess import call def excute_CMD(path_ExcuteFile, path_Config, path_Audio, path_Output): cmd = path_ExcuteFile + &quot; -C &quot; + path_Config + &quot; -I &quot; + path_Audio + &quot; -O &quot; + path_Output call(cmd, shell=True) def batch_extract_features(path_Config, path_Input_Root, path_Output): path_ExcuteFile = &quot;SMILExtract_Release&quot; filename = os.listdir(path_Input_Root) for i in range(len(filename)): print(&#39;Extracting features of %s&#39; % filename[i]) path_Input = path_Input_Root + &#39;/&#39; + filename[i] + &#39;.wav&#39; excute_CMD(path_ExcuteFile, path_Config, path_Input, path_Output) path_Config = &quot;./config/IS13_ComParE.conf&quot; path_Input_Root = &#39;root_path_to_audio&#39; path_Output = &#39;features.csv&#39; batch_extract_features(path_Config, path_Input_Root, path_Output) 官方配置文件官方提供了许多常见特征集的配置文件，如MFCC，PLP，以及各大语音比赛中效果好的特征集。 输出数据格式控制对于不包含统计函数的配置文件，选项定义在config/shared/standard_data_output_lldonly.conf.inc ==============================LLD only============================= ================================CSV================================ -csvoutput &lt;filename&gt; 默认输出选项. CSV格式，存放帧向LLD -appendcsv &lt;0/1&gt; 设为1代表添加到已有CSV文件文末，默认0 -timestampcsv &lt;0/1&gt; 设为0禁止把时间步输出到CSV第二列，默认为1 -headercsv &lt;0/1&gt; 设为0禁止把标题输入到CSV，默认为1 ================================HTK================================ -output &lt;filename&gt; 输出特征汇总（函数）到HTK格式文件 ================================ARFF=============================== -arffoutput &lt;filename&gt; 默认输出选项. ARFF格式，存放帧向LLD -appendarff &lt;0/1&gt; 设为0代表不添加到已有ARFF文件文末，默认1添加 -timestamparff &lt;0/1&gt; 设为0禁止把时间步输出到ARFF第二列，默认为1 arfftargetsfile &lt;file&gt;指定配置包含定义目标域（类）的文，默认为:shared/arff_targets_conf.inc 对于包含统计函数的配置文件，如全部的INTERSPEECH和AVEC挑战集，选项定义在config/shared/standard_data_output.conf.inc =============================LLD and func ========================= -instname &lt;string&gt; 通常是输入文件的名称保存在CSV和ARFF输出的首列。默认是&quot;unknow&quot; ================================ARFF=============================== -lldarffoutput, -D &lt;filename&gt; 启动LLD帧向输出到ARFF格式文件 -appendarfflld &lt;0/1&gt; 设为1代表添加到已有ARFF文件文末，默认0覆盖 -timestamparfflld &lt;0/1&gt; 设为0禁止把时间步输出到ARFF第二列，默认为1 -lldarfftargetsfile &lt;file&gt; 指定配置包含定义目标域（类）的文，默认为: shared/arff_targets_conf.inc ================================CSV================================ -lldcsvoutput, -D &lt;filename&gt; 启动LLD帧向输出到CSV格式文件 -appendcsvlld &lt;0/1&gt; 设为1代表添加到已有CSV文件文末，默认0覆盖 -timestampcsvlld &lt;0/1&gt; 设为0禁止把时间步输出到CSV第二列，默认为1 -headercsvlld &lt;0/1&gt; 设为0禁止把标题输入到CSV，默认为1 ================================HTK================================ -lldhtkoutput &lt;filename&gt; 启动LLD帧向输出到HTK格式文件 ================================ARFF=============================== -output, -O &lt;filename&gt; 默认输出选项. ARFF格式，存放特征汇总 -appendarff &lt;0/1&gt; 设为0代表不添加到已有ARFF文件文末，默认1添加 -timestamparff &lt;0/1&gt; 设为1把时间步输出到ARFF第二列，默认为0 -arfftargetsfile &lt;file&gt;指定配置包含定义目标域（类）的文，默认为: shared/arff_targets_conf.inc ================================CSV================================ -csvoutput &lt;filename&gt; 默认输出选项. CSV格式，存放特征汇总 -appendcsv &lt;0/1&gt; 设为0代表不添加到已有CSV文件文末，默认1 -timestampcsv &lt;0/1&gt; 设为0禁止把时间步输出到CSV第二列，默认为1 -headercsv &lt;0/1&gt; 设为0禁止把标题输入到CSV，默认为1 ================================HTK================================ -htkoutput &lt;filename&gt; 输出特征汇总（函数）到HTK格式文件 如下为lldcsvoutput的定义。注：从2.2版本起，可以指定一个“?”替代文件名。它会禁止相应的输出组件，即它不会产生输出文件，在标准输出接口界面，看到的所有的文件名默认都是”?” [lldsink:cCsvSink] reader.dmLevel = lld;lld_de filename=\cm[lldcsvoutput(D){?}:output csv file for LLD, disabled by default ?, only written if filename given] instanceName=\cm[instname(N){unknown}:instance name] append = \cm[appendcsvlld{0}:set to 1 to append to the LLD output csv file, default is not to append] timestamp = \cm[timestampcsvlld{1}:set to 0 to suppress timestamp column, default is 1, i.e. to show timestamp in second column] number = 0 printHeader = \cm[headercsvlld{1}:set to 0 to suppress header line with feature names, default is 1, i.e. to show header line] errorOnNoOutput = 1 那么，当需要同时输出lld和func时，可用如下命令 SMILExtract -C config/IS13_ComParE.conf -I input.wav -lldcsvoutput lld_output.csv -csvoutput func_output.csv 未完待续]]></content>
  </entry>
  <entry>
    <title><![CDATA[语谱图的matlab提取和python提取]]></title>
    <url>%2F2020%2F05%2F02%2Fspecgram%2F</url>
    <content type="text"><![CDATA[前言语谱图（spectrogram或specgram），也叫声谱图，可以简单看做一个二维矩阵，其纵轴表示频率，横轴表示时间，矩阵的值表示能量强弱。由于它拥有着频率和时间两个维度的信息，所以是比较综合地表示原语音信息的一种特征。另外，我将其看做语音和图像的一种连接，因为图像领域的模型发展得较快，所以通过这种方式把语音转换成一种特殊的图像再进一步处理。 语谱图流程简介1. 将语音可交叉地分成多帧（由于语音的短时平稳性） 2. 各帧加窗 3. 各帧通过快速傅里叶变化（fft）得到频谱向量 4. 沿着时间轴并联各频谱向量得到语谱图 语谱图的提取语谱图的matlab提取先看一段非官方代码，结合上述步骤进行理解。 [x,Fs,nBits]=wavread(&#39;audio.wav&#39;); s=length(x); % 信号长度 w=256; % 窗长 n=w; % nfft，表示做fft变换需要的点数，一般为刚大于w的2的幂。举例，w=250，则n一般设为256 ov=w/2; % 分帧的交叉程度，常见设为窗长的二分之一或四分之一 h=w-ov; % 不重叠点数 win=hamming(n)&#39;;% 选了常见的汉明窗，并设置nfft c=1; % 指向当前帧的指针 ncols=1+fix((s-n)/h); % 计算总共有多少帧 d=zeros((1+n/2),ncols); % 语谱图初始化 for b=0:h:(s-n) % 以下处理各帧 u=win.*x((b+1):(b+n)); % 各帧加窗 t=fft(u,n); % 各帧进行fft，内容为u，nfft=n。对于fft，输入n个时域点，输出n个频域点 d(:,c)=t(1:(1+n/2))&#39;; % 并联频谱向量，注意只取1+n/2，因为负频率无意义，只留下0和正频率 c=c+1; % 移动指针 end tt=[0:h:(s-n)]/Fs; % 时间轴 ff=[0:(n/2)]*Fs/n; % 频率轴 imagesc(tt/1000,ff/1000,20*log10(abs(d))); % 绘制 colormap(hot); axis xy xlabel(&#39;时间/s&#39;); ylabel(&#39;频率/kHz&#39;); 然而，matlab其实有封装好的函数可以直接调用。 [S,F,T]=specgram(x,nfft,Fs,windows_length,overlap_length) % x 为整段语音 % nfft 为fft变换点数，其实可以直接用默认的刚大于窗长的2的幂。也可自定义为大于窗长的整数，会对帧进行补零操作 % Fs 语音采样频率 % windows_length 窗长 % overlap_length 交叉长度 % S 语谱图 % F 频率值，尺度为1+n/2 % T 时间值，尺度为1+fix((s-n)/h) 语谱图的python提取有了刚才的基础，python的代码就容易理解啦。 from scipy import io from scipy.io import wavfile import matplotlib.pyplot as plt Fs, x = wavfile.read(&#39;audio.wav&#39;) # 读取音频 specg = plt.specgram(x, Fs = Fs, pad_to = 256, NFFT = 256, noverlap = 128) # 提取语谱图，一键操作！ io.savemat(&#39;specgram.mat&#39;, {&#39;specg&#39;:specg[0]}) # 保存语谱图 ## 照例解释下参数 # x，Fs和上边一样 # pad_to为上边的nfft # NFFT为上边的windows_length（为什么nfft不设置为上边的nfft呢，迷惑） # noverlap为上边的overlap_length 语谱图的一些可能有的小疑惑 关于nfftnfft既表示时域的点数也关联频域的点数。该数为2的幂数时更高效，但不是也没问题。nfft需要比窗长的值更大，然后加窗后的帧会被补零到nfft长度再进行fft。 关于频率分辨率频率轴上每一个点对应fs/nfft的频率。另外由于输出nfft/2+1个频率点，所以输出的频率范围为0到nfft/2×fs/nfft=fs/2。 关于自定义输出语谱图的尺寸问题时间轴尺寸为1+fix((s-n)/h)， 由windows_length和overlap_length决定。实际应用时由于各语音长度不同，时间尺寸一般都要进行截断或补零到一个固定值。截断的话可以截一段（起始信息，中间信息），也可以截多段（交叉不交叉都行）。频率轴尺寸为1+n/2，仅决定于nfft（python中的pad_to参数），所以可以通过设置该值控制频率轴尺寸。但是也不要比窗长大太多，否则补零太多可能就没什么信息了。nfft调大时，窗长可以跟着调大，为了防止导致的时间轴太短可以调高overlap_length。另外，其他参数不变时，仅变换nfft，可视化出来时可能肉眼看起来一样，但实际分辨率仍然是不同的。这也导致了一个问题，送入网络的是要用单通道的直接计算出来的语谱图，还是用可视化函数绘制出来的三通道的语谱图，这就根据实际情况去尝试了。 彩蛋 盆友们你们有在看吗！好无聊…]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用Github Pages和Hexo搭建自己的独立博客]]></title>
    <url>%2F2019%2F08%2F11%2FHow-to-use-Hexo-to-build-your-blog%2F</url>
    <content type="text"><![CDATA[前言 Github Pages: Github Pages可以被认为是用户编写的、托管在github上的静态网页。 Hexo: Hexo是一个快速、简洁且高效的博客框架。 安装Node.js点击此处访问官网，按需下载相应版本，默认安装可以了。 安装Hexo$ sudo npm install -g hexo-cli 若报错，尝试： $ sudo npm install --unsafe-perm --verbose -g hexo 初始化，建立博客项目选定博客网站项目程序文件的存放位置，如/Users/tobefans/Documents/Blog/，Bash中cd进入该目录下，执行命令： $ hexo init 执行完毕后，该命令将在当前目录下生成一套标准的Hexo博客项目模板 命令$ hexo g 生成静态网站文件 $ hexo s 启动本地服务器 $ hexo d 发布博客到GitHub 发布博客创建github.io仓库在自己的GitHub中，创建新仓库，标准命名为GitHub用户名.github.io，例如我的：tobefans.github.io 配置SSH密钥只有配置好 SSH 密钥后，我们才可以通过 git 操作实现本地代码库与 Github 代码库同步，在你第一次新建的文件夹里输入以下命令： $ ssh-keygen -t rsa -C &quot;your email@example.com&quot; //引号里面填写你的邮箱地址，比如我的是weiquan.fan96@gmail.com 之后复制~/.ssh/id_rsa.pub的公钥，在Github账号中添加进该公钥。 Git 会根据用户的名字和邮箱来记录提交，GitHub 也是用这些信息来做权限的处理，输入以下命令进行个人信息的设置，把名称和邮箱替换成你自己的，名字可以不是 GitHub 的昵称，但为了方便记忆，建议与 GitHub 一致。 $ git config --global user.name &quot;此处填你的用户名&quot; $ git config --global user.email &quot;此处填你的邮箱&quot; 可通过ssh -T git@github.com测试是否添加成功。 将本地的 Hexo 文件更新到 Github 的库中打开创建的 Hexo 文件夹下的 _config.yml，修改如下的代码段，repo为github项目的地址。 deploy: type: git repo: git@github.com:tobefans/tobefans.github.io.git branch: master 如果此时报以下错误，说明你的 deployer 没有安装成功 ERROR Deployer not found: git 需要执行以下命令再安装一次： $ npm install hexo-deployer-git --save 再执行 hexo g -d，你的博客就会部署到 Github 上了 访问博客在github该项目的setting中打开Github pages的设置。 你的博客地址：https://你的用户名.http://github.io，比如我的是：https://tobefans.github.io ，现在每个人都可以通过此链接访问你的博客了。 为博客更换自己喜欢的主题点击此处进入 Hexo 官网的主题专栏，我们可以看见有许多的主题供我们选择。我们要做的就是把主题克隆过来，在此我们以主题 Aero-Dual 为例，点进去我们就可以看见该主题作者的博客，鼠标滑到底，我们可以看见 Theme By Levblanc 的字样（其他主题类似），点击作者 Levblanc ，页面就会跳转到该主题所有的相关文件在 Github 上的地址，下载该项目，放至Hexo文件夹中的themes目录。 然后打开 Hexo 文件夹下的配置文件 _config.yml ，找到关键字 theme，修改参数为：theme：hexo-theme-aero-dual （其他主题修改成相应名称即可），再次注意冒号后面有一个空格。再通过$ hexo g更新。 另推荐一款主题：Next 在Hexo中渲染MathJax数学公式更换Hexo的markdown渲染引擎，hexo-renderer-kramed引擎是在默认的渲染引擎hexo-renderer-marked的基础上修改了一些bug，两者比较接近，也比较轻量级。在Hexo文件夹位置命令： npm uninstall hexo-renderer-marked --save npm install hexo-renderer-kramed --save 接下来到博客根目录下，找到node_modules\kramed\lib\rules\inline.js，把第11行的escape变量的值做相应的修改，这一步是在原基础上取消了对\,{,}的转义(escape)。同时把第20行的em变量也要做相应的修改。 // escape: /^\\([\\`*{}\[\]()#$+\-.!_&gt;])/, escape: /^\\([`*\[\]()#$+\-.!_&gt;])/ // em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/ 进入到主题目录，找到_config.yml配置问题，把mathjax默认的false修改为true，具体如下： # MathJax Support mathjax: enable: true per_page: true 在文章的Front-matter里打开mathjax开关，如下： --- title: 使用Github Pages和Hexo搭建自己的独立博客 date: 2019-08-11 19:10:47 tags: mathjax: true --- 这里有常见数学公式。 绑定域名通过阿里云之类的获得域名后，先解析域名如下。 记录类型 主机记录 记录值 CNAME www 你的github用户名.github.io A @ 192.30.252.153 A @ 192.30.252.154 在Hexo文件夹的source文件夹中，创建一个CNAME文件，存储预备使用的个人域名，如：weiquanfan.xyz也可通过github项目上setting里映射个人域名。 清理Hexo缓存并更新Hexo静态网站 $ hexo clean &amp;&amp; hexo g $ hexo clean $ hexo g -d Valine——评论系统Valine 诞生于 2017 年 8 月 7 日，是一款基于 Leancloud 的快速、简洁且高效的无后端评论系统。 注册帐号创建应用:请先登录或注册 LeanCloud, 进入控制台后点击左下角创建应用，选用免费的开发版应用即可。 应用设置:进入应用。在 设置 -&gt; 安全中心 ，把文件上传、短信服务、推送服务、实时通信这几个服务全部关闭，因为用不到。在 Web 安全域名 里填入想要打开评论系统的域名，如weiquanfan.xyz在 设置 -&gt; 应用 Key 找到APP ID和APP Key。 配置 Hexo 参数:打开 Hexo 主题的配置文件_config.yml，搜索一下 Valine，打开enable，并填写APP ID 和 APP Key。 更新网站:运行hexo g -d推送到博客。 此外，还需要注意，如果博客还有除正文内容之外的页面存在，例如关于、分类、标签，要把他们的 Markdown 文件的 comments 属性设置为 false，否则这些页面在展示的时候也会有评论的功能出现。 --- title: 使用Github Pages和Hexo搭建自己的独立博客 date: 2019-08-11 19:10:47 tags: mathjax: true comments: false --- 统计阅读量阅读量分两种：不蒜子统计站点的总访问量，即统计浏览了多少次；有多少人访问，在footer显示。LeanCloud统计单篇博文的阅读量，即统计单篇博文的阅读量是多少。 单篇博文的阅读量通过Valine实现，其实和评论系统差不多。在 存储 中新建Class，Class名称必须为Counter。并相应更改主题配置文件的leancloud_visitors，打开enable，并填写APP ID 和 APP Key。 站点的总访问量通过不蒜子实现。找到站点的themes/next/layout/_partials/footer.swig文件。插入代码如下。 {% if theme.footer.theme.enable %} {# #}{{ __('footer.theme') }} &mdash; {# #}{# #}NexT.{{ theme.scheme }}{# #}{% if theme.footer.theme.version %} v{{ theme.version }}{% endif %}&lt;/div&gt; # 此位置插入以下代码 &lt;div&gt; &lt;script async src=&quot;https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt; 本站总访问量 &lt;span id=&quot;busuanzi_value_site_pv&quot;&gt;&lt;/span&gt; 次&amp;nbsp&amp;nbsp&amp;nbsp 本站访客数&lt;span id=&quot;busuanzi_value_site_uv&quot;&gt;&lt;/span&gt;人次 &lt;/div&gt; {% endif %} 彩蛋 喜大普奔，完成啦！！]]></content>
  </entry>
</search>
